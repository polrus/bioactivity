{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/30 12:29:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.appName(\"drug-to_target_biodata\").getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"drug-to_target_biodata_3\") \\\n",
    "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biodata only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+-----+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "| chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|  tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|\n",
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+-----+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|CHEMBL1000|  111185|   CHEMBL954102|     1|    LITERATURE|     Bioorg Med Chem|1.8448342E7|10.1016/j.bmc.200...|  165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|\n",
      "|CHEMBL1000|  111185|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|  165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|      31622.78|            nM|                =|          4.5|\n",
      "|CHEMBL1000|  111185|   CHEMBL829152|     1|    LITERATURE|Bioorg Med Chem Lett|1.5911273E7|10.1016/j.bmcl.20...|  165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|\n",
      "|CHEMBL1000|  111185|  CHEMBL2016084|     1|    LITERATURE|Bioorg Med Chem Lett|2.2406116E7|10.1016/j.bmcl.20...|12913|   Q02763|Tyrosine-protein ...|      CHEMBL4128|Homo sapiens|       90000.0|            nM|                =|         4.05|\n",
      "|CHEMBL1000|  111185|   CHEMBL766814|     1|    LITERATURE|Bioorg Med Chem Lett|1.2873512E7|10.1016/s0960-894...|  165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|\n",
      "|CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224926|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          63.1|            nM|                =|          7.2|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224922|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         31.62|            nM|                =|          7.5|\n",
      "|CHEMBL1000|  111185|   CHEMBL881222|     1|    LITERATURE|          J Med Chem|1.6220969E7|   10.1021/jm058225d|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|   CHEMBL880732|     1|    LITERATURE|Bioorg Med Chem Lett|1.5081022E7|10.1016/j.bmcl.20...|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224923|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         31.62|            nM|                =|          7.5|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224920|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         50.12|            nM|                =|          7.3|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224921|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         50.12|            nM|                =|          7.3|\n",
      "|CHEMBL1000|  111185|   CHEMBL830379|     1|    LITERATURE|Bioorg Med Chem Lett| 1.548293E7|10.1016/j.bmcl.20...|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224924|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         79.43|            nM|                =|          7.1|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224925|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|  127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          63.1|            nM|                =|          7.2|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937183|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...|   43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|        457.09|            nM|                =|         6.34|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937031|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...|   43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|         145.0|            nM|                =|         6.84|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937183|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...|   43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|         457.0|            nM|                =|         6.34|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937030|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...|   43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|       5623.41|            nM|                =|         5.25|\n",
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+-----+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of all drug-target pairs with pChEMBL: 93739\n"
     ]
    }
   ],
   "source": [
    "# Testset with all biodata\n",
    "biodata_all_in = \"./data/drug2target_bioactivities_chembl_33.csv\"\n",
    "\n",
    "biodata_all = spark.read.csv(biodata_all_in, header=True, inferSchema=True)\n",
    "biodata_all = biodata_all.drop('_c0')\n",
    "\n",
    "# Filter rows where there is pChEMBL\n",
    "biodata_all = biodata_all.filter(biodata_all['pchembl_value'] != 0)\n",
    "biodata_all.show()\n",
    "\n",
    "biodata_all_count = biodata_all.count()\n",
    "print(\"Number of all drug-target pairs with pChEMBL:\", biodata_all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|\n",
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|\n",
      "|  CHEMBL1000|  111185|   CHEMBL954102|     1|    LITERATURE|     Bioorg Med Chem|1.8448342E7|10.1016/j.bmc.200...|   165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|\n",
      "|CHEMBL100259|  161181|  CHEMBL3528990|     1|    LITERATURE|   Drug Metab Dispos|2.3388705E7|10.1124/dmd.112.0...|   175|   Q99808|Equilibrative nuc...|      CHEMBL1997|Homo sapiens|       51000.0|            nM|                =|         4.29|\n",
      "| CHEMBL10041|    6341|  CHEMBL5121196|     1|    LITERATURE|      Eur J Med Chem|3.4710747E7|10.1016/j.ejmech....|    19|   P03372|Estrogen receptor...|       CHEMBL206|Homo sapiens|          1.12|            nM|                =|         8.95|\n",
      "|CHEMBL100763|  163958|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|   P03372|Estrogen receptor...|       CHEMBL206|Homo sapiens|         3.304|            nM|                =|         8.48|\n",
      "|CHEMBL100763|  163958|   CHEMBL831659|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|   174|   Q92731|Estrogen receptor...|       CHEMBL242|Homo sapiens|         302.0|            nM|                =|         6.52|\n",
      "|  CHEMBL1008|  112651|  CHEMBL3436051|     1|    LITERATURE|      J Appl Toxicol|   2.2761E7|    10.1002/jat.2784|   169|   Q13936|Voltage-gated L-t...|      CHEMBL1940|Homo sapiens|        1400.0|            nM|                =|         5.85|\n",
      "|  CHEMBL1008|  112651|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|   165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|         22.91|            nM|                =|         7.64|\n",
      "|  CHEMBL1008|  112651|  CHEMBL3541093|     1|    LITERATURE|   Drug Metab Dispos|2.3033255E7|10.1124/dmd.112.0...|100611|   P51589| Cytochrome P450 2J2|      CHEMBL3491|Homo sapiens|       11500.0|            nM|                =|         4.94|\n",
      "|  CHEMBL1009|  112655|  CHEMBL1909206|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10140|   P06239|Tyrosine-protein ...|       CHEMBL258|Homo sapiens|        3729.0|            nM|                =|         5.43|\n",
      "|  CHEMBL1010|  112665|  CHEMBL4028924|     1|    LITERATURE|         Toxicol Sci|2.3956101E7|10.1093/toxsci/kf...|104069|   O15439|Multidrug resista...|   CHEMBL1743128|Homo sapiens|       24000.0|            nM|                =|         4.62|\n",
      "|CHEMBL101253|  165012|  CHEMBL1063702|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12840|   P07333|Macrophage colony...|      CHEMBL1844|Homo sapiens|          18.0|            nM|                =|         7.75|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|   P10721|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|\n",
      "|CHEMBL101253|  165012|   CHEMBL892951|     1|    LITERATURE|     Bioorg Med Chem|1.7416531E7|10.1016/j.bmc.200...|     9|   P00533|Epidermal growth ...|       CHEMBL203|Homo sapiens|         457.7|            nM|                =|         6.34|\n",
      "|CHEMBL101253|  165012|  CHEMBL1051257|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|100079|   P07949|Tyrosine-protein ...|      CHEMBL2041|Homo sapiens|        7600.0|            nM|                =|         5.12|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|   P42685|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908762|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101239|   O14578|Citron Rho-intera...|      CHEMBL5579|Homo sapiens|        8800.0|            nM|                =|         5.06|\n",
      "|CHEMBL101382|  164146|   CHEMBL836357|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|104682|   P03372|   Estrogen receptor|   CHEMBL2093866|Homo sapiens|          32.0|            nM|                =|          7.5|\n",
      "|  CHEMBL1016|  116848|  CHEMBL1909205|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   188|   P04626|Receptor protein-...|      CHEMBL1824|Homo sapiens|        5947.2|            nM|                =|         5.23|\n",
      "|  CHEMBL1016|  116848|  CHEMBL1909094|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|        3039.8|            nM|                =|         5.52|\n",
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of unique drug-target pairs with pChEMBL min: 29689\n"
     ]
    }
   ],
   "source": [
    "# Apply min activity value for each drug-target pair\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, concat_ws\n",
    "\n",
    "# Define window specification\n",
    "windowSpec = Window.partitionBy(\"chembl_id\", \"target_chembl_id\").orderBy(biodata_all[\"pchembl_value\"].desc())\n",
    "\n",
    "# Assign row number\n",
    "biodata_all_sort = biodata_all.withColumn(\"row_num\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to keep only rows with maximum pchembl_value for each chembl_id within each target_chembl_id\n",
    "biodata_all_min = biodata_all_sort.filter(biodata_all_sort.row_num == 1).drop(\"row_num\")\n",
    "\n",
    "biodata_all_min.show()\n",
    "\n",
    "print(\"Number of unique drug-target pairs with pChEMBL min:\", biodata_all_min.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biodata_all_min.repartition(1).write.csv(\"data/analysis/biodata_all_min\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But we need to know for this testset if each target for a drug is therapeutic or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evidence_path = \"data/evidence/sourceId=chembl\"\n",
    "evidence = spark.read.parquet(evidence_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 12:29:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-------------+-------------------+--------+----------+----+---------------------------+---------------------------+---------------------------------+--------------------------------+-----------------+-------------+----------+--------------------+--------+-------------+---------------------+--------------------+-----------------+--------+----------------+---------------+----------+--------+-------------------+----------+----------------+--------------------+-------------------+-------------------------+-------------------------------------+-------------------------------------+--------------+-------------+------------+-----------------+----------+----------------------------+-------------------+--------------+---------+--------------------------------+--------------------------------+--------------+--------------+--------+------+---------+----------------------+---------------+----------+------------+-------------+----+------------------------+-----------------+-------------------------+-------------------+----------+--------------------------------+-------+-------------+---------------+--------------+---------------+-------------------------+----------------+------------------+-------------+----------------------+------------------+----------------+-------------------+--------------------+----------------------------+-------------------------------------+------------------------------+-------------+---------+-----------+-------------+--------------------+-----+\n",
      "|datasourceId|       targetId|alleleOrigins|allelicRequirements|ancestry|ancestryId|beta|betaConfidenceIntervalLower|betaConfidenceIntervalUpper|biologicalModelAllelicComposition|biologicalModelGeneticBackground|biologicalModelId|biomarkerName|biomarkers|biosamplesFromSource|cellType|clinicalPhase|clinicalSignificances|      clinicalStatus|cohortDescription|cohortId|cohortPhenotypes|cohortShortName|confidence|contrast|crisprScreenLibrary|datatypeId|diseaseCellLines|   diseaseFromSource|diseaseFromSourceId|diseaseFromSourceMappedId|diseaseModelAssociatedHumanPhenotypes|diseaseModelAssociatedModelPhenotypes|drugFromSource|       drugId|drugResponse|geneticBackground|literature|log2FoldChangePercentileRank|log2FoldChangeValue|mutatedSamples|oddsRatio|oddsRatioConfidenceIntervalLower|oddsRatioConfidenceIntervalUpper|pValueExponent|pValueMantissa|pathways|pmcIds|projectId|publicationFirstAuthor|publicationYear|reactionId|reactionName|resourceScore| sex|significantDriverMethods|statisticalMethod|statisticalMethodOverview|statisticalTestTail|studyCases|studyCasesWithQualifyingVariants|studyId|studyOverview|studySampleSize|studyStartDate|studyStopReason|studyStopReasonCategories|targetFromSource|targetFromSourceId|targetInModel|targetInModelEnsemblId|targetInModelMgiId|targetModulation|textMiningSentences|                urls|variantAminoacidDescriptions|variantFunctionalConsequenceFromQtlId|variantFunctionalConsequenceId|variantHgvsId|variantId|variantRsId|    diseaseId|                  id|score|\n",
      "+------------+---------------+-------------+-------------------+--------+----------+----+---------------------------+---------------------------+---------------------------------+--------------------------------+-----------------+-------------+----------+--------------------+--------+-------------+---------------------+--------------------+-----------------+--------+----------------+---------------+----------+--------+-------------------+----------+----------------+--------------------+-------------------+-------------------------+-------------------------------------+-------------------------------------+--------------+-------------+------------+-----------------+----------+----------------------------+-------------------+--------------+---------+--------------------------------+--------------------------------+--------------+--------------+--------+------+---------+----------------------+---------------+----------+------------+-------------+----+------------------------+-----------------+-------------------------+-------------------+----------+--------------------------------+-------+-------------+---------------+--------------+---------------+-------------------------+----------------+------------------+-------------+----------------------+------------------+----------------+-------------------+--------------------+----------------------------+-------------------------------------+------------------------------+-------------+---------+-----------+-------------+--------------------+-----+\n",
      "|      chembl|ENSG00000077514|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          1.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|            Leukemia|               NULL|              EFO_0000565|                                 NULL|                                 NULL|          NULL|    CHEMBL803|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2007-03-01|           NULL|                     NULL|   CHEMBL2363042|            Q15054|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000565|0000919b15efa49dd...|  0.1|\n",
      "|      chembl|ENSG00000143105|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          3.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|  Multiple Sclerosis|               NULL|            MONDO_0005301|                                 NULL|                                 NULL|          NULL| CHEMBL354077|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2005-02-01|           NULL|                     NULL|   CHEMBL2362996|            Q16322|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0005301|00047b0ed6321bf14...|  0.7|\n",
      "|      chembl|ENSG00000169032|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          3.0|                 NULL|Active, not recru...|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|            Melanoma|               NULL|              EFO_0000756|                                 NULL|                                 NULL|          NULL|CHEMBL2103875|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2013-01-08|           NULL|                     NULL|   CHEMBL2111289|            Q02750|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000756|00085b1f8aa240094...|  0.7|\n",
      "|      chembl|ENSG00000104833|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          3.0|                 NULL|          Recruiting|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|T-cell Lymphoblas...|               NULL|            MONDO_0044917|                                 NULL|                                 NULL|          NULL|  CHEMBL90555|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2023-02-06|           NULL|                     NULL|   CHEMBL2095182|            P04350|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0044917|001798ed32ee5e498...|  0.7|\n",
      "|      chembl|ENSG00000117601|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          2.0|                 NULL|          Recruiting|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|Deep Venous Throm...|               NULL|              EFO_0003907|                                 NULL|                                 NULL|          NULL|CHEMBL1201476|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2022-05-11|           NULL|                     NULL|      CHEMBL1950|            P01008|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0003907|003e05bdc29b35649...|  0.2|\n",
      "|      chembl|ENSG00000147246|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|                NULL|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|       schizophrenia|               NULL|            MONDO_0005090|                                 NULL|                                 NULL|          NULL|CHEMBL3188993|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|          NULL|           NULL|                     NULL|       CHEMBL225|            P28335|         NULL|                  NULL|              NULL|            NULL|               NULL|[{DailyMed, https...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0005090|0041e556b431fbe0d...|  1.0|\n",
      "|      chembl|ENSG00000185313|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|      Unknown status|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|     Oral Hemorrhage|               NULL|               MP_0001914|                                 NULL|                                 NULL|          NULL|     CHEMBL79|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2013-12-01|           NULL|                     NULL|   CHEMBL2331043|            Q9Y5Y9|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|   MP_0001914|005465f9c428dc729...|  1.0|\n",
      "|      chembl|ENSG00000161509|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          1.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|                Pain|               NULL|              EFO_0003843|                                 NULL|                                 NULL|          NULL|    CHEMBL742|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2020-01-01|           NULL|                     NULL|   CHEMBL2094124|            Q14957|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0003843|005bfe8d42982b117...|  0.1|\n",
      "|      chembl|ENSG00000137285|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          1.0|                 NULL|Active, not recru...|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|Non-Hodgkin Lymphoma|               NULL|              EFO_0005952|                                 NULL|                                 NULL|          NULL|  CHEMBL90555|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2018-03-13|           NULL|                     NULL|   CHEMBL2095182|            Q9BVA1|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0005952|008658fa3cc565661...|  0.1|\n",
      "|      chembl|ENSG00000115159|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|                NULL|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|type 2 diabetes m...|               NULL|            MONDO_0005148|                                 NULL|                                 NULL|          NULL|   CHEMBL1431|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|          NULL|           NULL|                     NULL|   CHEMBL3391681|            P43304|         NULL|                  NULL|              NULL|            NULL|               NULL|[{DailyMed, https...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0005148|009b2e1f3679cb3e6...|  1.0|\n",
      "|      chembl|ENSG00000126895|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|Primary Nocturnal...|               NULL|            MONDO_0024290|                                 NULL|                                 NULL|          NULL|CHEMBL1200556|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2004-12-01|           NULL|                     NULL|   CHEMBL2363078|            P30518|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0024290|00de84d41d38b70ed...|  1.0|\n",
      "|      chembl|ENSG00000104833|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          2.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|            Lymphoma|               NULL|              EFO_0000574|                                 NULL|                                 NULL|          NULL| CHEMBL501867|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2000-05-01|           NULL|                     NULL|   CHEMBL2095182|            P04350|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000574|00e720f9be92d5f33...|  0.2|\n",
      "|      chembl|ENSG00000120907|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          1.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|Benign Prostatic ...|               NULL|              EFO_0000284|                                 NULL|                                 NULL|          NULL|    CHEMBL836|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2019-03-11|           NULL|                     NULL|   CHEMBL2094251|            P35348|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000284|00fc874991be06f56...|  0.1|\n",
      "|      chembl|ENSG00000116329|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|           Withdrawn|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|        Chronic Pain|               NULL|               HP_0012532|                                 NULL|                                 NULL|          NULL|     CHEMBL80|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2013-06-01|           NULL|                     NULL|   CHEMBL2095181|            P41143|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|   HP_0012532|0109b2de61ed2e9e1...|  1.0|\n",
      "|      chembl|ENSG00000101162|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          1.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|         Solid Tumor|               NULL|              EFO_0000616|                                 NULL|                                 NULL|          NULL|CHEMBL3545252|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2009-07-01|           NULL|                     NULL|   CHEMBL2095182|            Q9H4B7|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000616|012c56f426c5cc83b...|  0.1|\n",
      "|      chembl|ENSG00000065518|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|                NULL|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|                NULL|               NULL|            MONDO_0005148|                                 NULL|                                 NULL|          NULL|   CHEMBL1431|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|          NULL|           NULL|                     NULL|   CHEMBL2363065|            O95168|         NULL|                  NULL|              NULL|            NULL|               NULL|[{DailyMed, https...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|MONDO_0005148|0130d8030b27ef920...|  1.0|\n",
      "|      chembl|ENSG00000112038|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          3.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|          Acute Pain|               NULL|              EFO_0003843|                                 NULL|                                 NULL|          NULL|    CHEMBL658|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2008-01-01|           NULL|                     NULL|       CHEMBL233|            P35372|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0003843|0131b690cd70cb7f6...|  0.7|\n",
      "|      chembl|ENSG00000077097|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          3.0|                 NULL|          Recruiting|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|Extensive Stage S...|               NULL|              EFO_0000702|                                 NULL|                                 NULL|          NULL|  CHEMBL44657|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2022-11-18|           NULL|                     NULL|   CHEMBL2094255|            Q02880|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0000702|0134a72cb071bde1a...|  0.7|\n",
      "|      chembl|ENSG00000150594|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|                NULL|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|           analgesia|               NULL|              EFO_0003843|                                 NULL|                                 NULL|          NULL|    CHEMBL679|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|          NULL|           NULL|                     NULL|   CHEMBL2331074|            P08913|         NULL|                  NULL|              NULL|            NULL|               NULL|[{DailyMed, https...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0003843|0168c05d35500d293...|  1.0|\n",
      "|      chembl|ENSG00000112038|         NULL|               NULL|    NULL|      NULL|NULL|                       NULL|                       NULL|                             NULL|                            NULL|             NULL|         NULL|      NULL|                NULL|    NULL|          4.0|                 NULL|           Completed|             NULL|    NULL|            NULL|           NULL|      NULL|    NULL|               NULL|known_drug|            NULL|    Opiate Addiction|               NULL|              EFO_0005611|                                 NULL|                                 NULL|          NULL|    CHEMBL651|        NULL|             NULL|      NULL|                        NULL|               NULL|          NULL|     NULL|                            NULL|                            NULL|          NULL|          NULL|    NULL|  NULL|     NULL|                  NULL|           NULL|      NULL|        NULL|         NULL|NULL|                    NULL|             NULL|                     NULL|               NULL|      NULL|                            NULL|   NULL|         NULL|           NULL|    2009-04-01|           NULL|                     NULL|       CHEMBL233|            P35372|         NULL|                  NULL|              NULL|            NULL|               NULL|[{ClinicalTrials,...|                        NULL|                                 NULL|                          NULL|         NULL|     NULL|       NULL|  EFO_0005611|016b6abd247e50218...|  1.0|\n",
      "+------------+---------------+-------------+-------------------+--------+----------+----+---------------------------+---------------------------+---------------------------------+--------------------------------+-----------------+-------------+----------+--------------------+--------+-------------+---------------------+--------------------+-----------------+--------+----------------+---------------+----------+--------+-------------------+----------+----------------+--------------------+-------------------+-------------------------+-------------------------------------+-------------------------------------+--------------+-------------+------------+-----------------+----------+----------------------------+-------------------+--------------+---------+--------------------------------+--------------------------------+--------------+--------------+--------+------+---------+----------------------+---------------+----------+------------+-------------+----+------------------------+-----------------+-------------------------+-------------------+----------+--------------------------------+-------+-------------+---------------+--------------+---------------+-------------------------+----------------+------------------+-------------+----------------------+------------------+----------------+-------------------+--------------------+----------------------------+-------------------------------------+------------------------------+-------------+---------+-----------+-------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evidence.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'biodata_all_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m joined_df \u001b[39m=\u001b[39m biodata_all_min\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     evidence,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     (biodata_all_min\u001b[39m.\u001b[39mchembl_id \u001b[39m==\u001b[39m evidence\u001b[39m.\u001b[39mdrugId) \u001b[39m&\u001b[39m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     (biodata_all_min\u001b[39m.\u001b[39mtarget_chembl_id \u001b[39m==\u001b[39m evidence\u001b[39m.\u001b[39mtargetFromSource),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Create isMoA column based on whether drugId is not null after the join\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m biodata_all_min_with_isMoA \u001b[39m=\u001b[39m joined_df\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39misMoA\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     F\u001b[39m.\u001b[39mwhen(F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mdrugId\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39misNotNull(), \u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39motherwise(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y125sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'biodata_all_min' is not defined"
     ]
    }
   ],
   "source": [
    "joined_df = biodata_all_min.join(\n",
    "    evidence,\n",
    "    (biodata_all_min.chembl_id == evidence.drugId) & \n",
    "    (biodata_all_min.target_chembl_id == evidence.targetFromSource),\n",
    "    'left'\n",
    ")\n",
    "\n",
    "# Create isMoA column based on whether drugId is not null after the join\n",
    "biodata_all_min_with_isMoA = joined_df.withColumn(\n",
    "    \"isMoA\",\n",
    "    F.when(F.col(\"drugId\").isNotNull(), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# Select only columns from biodata_all_min and the new isMoA column\n",
    "final_biodata_all_min = biodata_all_min_with_isMoA.select(*biodata_all_min.columns, \"isMoA\").dropDuplicates(subset=biodata_all_min.columns)\n",
    "\n",
    "\n",
    "final_biodata_all_min.show()\n",
    "final_biodata_all_min.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After manual checking several pairs have MoA=False, but should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checking if these cases present in evidence\n",
    "\n",
    "targetFromSource = \"CHEMBL2508\"\n",
    "drugId = \"CHEMBL3301610\"\n",
    "\n",
    "row_exists = evidence.filter((evidence['targetFromSource'] == targetFromSource) & (evidence['drugId'] == drugId)).count() > 0\n",
    "\n",
    "if row_exists:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           id|     canonicalSmiles|            inchiKey|      drugType|blackBoxWarning|                name|yearOfFirstApproval|maximumClinicalTrialPhase|parentId|hasBeenWithdrawn|isApproved|          tradeNames|            synonyms|     crossReferences|      childChemblIds|      linkedDiseases|       linkedTargets|         description|\n",
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|CHEMBL1086582|Cc1cc(CN2CCN(c3c(...|UUGWPYPNRZQDFO-UH...|Small molecule|          false|       CHEMBL1086582|               NULL|                     NULL|    NULL|           false|      NULL|                  []|                  []|                NULL|                NULL|                NULL|                NULL|Small molecule drug.|\n",
      "|CHEMBL1173055|CNCc1ccc(-c2[nH]c...|HMABYWSNWIZPAG-UH...|Small molecule|          false|           RUCAPARIB|               2016|                      4.0|    NULL|           false|      true|                  []|[AG-014699, AG-14...|{DailyMed -> [ruc...|[CHEMBL2105733, C...|{[EFO_0003060, EF...|{[ENSG00000143799...|Small molecule dr...|\n",
      "|CHEMBL1200910|CC(=O)N(c1onc(C)c...|JFNWFXVFBDDWCX-UH...|Small molecule|          false|SULFISOXAZOLE ACETYL|               1953|                      4.0|    NULL|           false|      true|[Gantrisin, Gantr...|[Acetyl sulfafura...|{DailyMed -> [sul...|                NULL|                NULL|             {[], 0}|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|{[ENSG00000138435...|Small molecule dr...|\n",
      "|CHEMBL1201468|                NULL|                NULL|Small molecule|           true|ESTROGENS, ESTERI...|               1977|                      4.0|    NULL|           false|      true|[Amnestrogen, Est...|[Esterified estro...|{DailyMed -> [est...|                NULL|{[EFO_1000096, EF...|{[ENSG00000140009...|Small molecule dr...|\n",
      "|CHEMBL1201718|                NULL|                NULL|        Enzyme|          false|HYALURONIDASE (HU...|               2005|                      4.0|    NULL|           false|      true|[Cumulase, Hylene...|[Chemophase, Enha...|{DailyMed -> [hya...|                NULL|{[EFO_1000668, MO...|                NULL|Enzyme drug with ...|\n",
      "|CHEMBL1201772|CC(=O)Oc1cc2c(s1)...|DTGLZDAWLRGWQN-UH...|Small molecule|           true|           PRASUGREL|               2009|                      4.0|    NULL|           false|      true|            [Efient]|[LY-640315, NSC-7...|{DailyMed -> [pra...|     [CHEMBL1201773]|{[EFO_0003777, EF...|{[ENSG00000169313...|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|{[ENSG00000145675...|Small molecule dr...|\n",
      "|CHEMBL1408759|Cc1ccc(C(C)C)cc2c...|FWKQNCXZGNBPFD-UH...|Small molecule|          false|          GUAIAZULEN|               NULL|                     -1.0|    NULL|           false|     false|                  []|[Guaiazulen, Guai...|{PubChem -> [1704...|                NULL|  {[EFO_0003966], 1}|                NULL|Small molecule dr...|\n",
      "|   CHEMBL1423|O=c1[nH]c2ccccc2n...|YVUQSNJEYSNKRX-UH...|Small molecule|          false|            PIMOZIDE|               1984|                      4.0|    NULL|           false|      true|    [Orap, Pimozide]|[MCN-JR-6238, NSC...|{DailyMed -> [pim...|                NULL|{[MONDO_0005090, ...|{[ENSG00000149295...|Small molecule dr...|\n",
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets use Drug parquet from platform (molecule)\n",
    "# gsutil -m cp -r gs://open-targets-data-releases/23.09/output/etl/parquet/molecule\n",
    "\n",
    "molecule_path = \"data/molecule\"\n",
    "molecule = spark.read.parquet(molecule_path)\n",
    "molecule.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Checking if MoA is unknown for a drug\n",
    "\n",
    "given_id = 'CHEMBL207197'\n",
    "\n",
    "# Filter the DataFrame for the given id and check if linkedTargets is null\n",
    "result = molecule.filter(F.col('id') == given_id).select(F.col('linkedTargets').isNull().alias('is_linkedTargets_null')).collect()\n",
    "\n",
    "# Check if the result has rows and the first row's is_linkedTargets_null column is True\n",
    "if result and result[0].is_linkedTargets_null:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+\n",
      "|           id|     canonicalSmiles|            inchiKey|      drugType|blackBoxWarning|                name|yearOfFirstApproval|maximumClinicalTrialPhase|parentId|hasBeenWithdrawn|isApproved|          tradeNames|            synonyms|     crossReferences|      childChemblIds|      linkedDiseases|  linkedTargets|         description|\n",
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+\n",
      "|CHEMBL1086582|Cc1cc(CN2CCN(c3c(...|UUGWPYPNRZQDFO-UH...|Small molecule|          false|       CHEMBL1086582|               NULL|                     NULL|    NULL|           false|      NULL|                  []|                  []|                NULL|                NULL|                NULL|           NULL|Small molecule drug.|\n",
      "|CHEMBL1173055|CNCc1ccc(-c2[nH]c...|HMABYWSNWIZPAG-UH...|Small molecule|          false|           RUCAPARIB|               2016|                      4.0|    NULL|           false|      true|                  []|[AG-014699, AG-14...|{DailyMed -> [ruc...|[CHEMBL2105733, C...|{[EFO_0003060, EF...|ENSG00000143799|Small molecule dr...|\n",
      "|CHEMBL1173055|CNCc1ccc(-c2[nH]c...|HMABYWSNWIZPAG-UH...|Small molecule|          false|           RUCAPARIB|               2016|                      4.0|    NULL|           false|      true|                  []|[AG-014699, AG-14...|{DailyMed -> [ruc...|[CHEMBL2105733, C...|{[EFO_0003060, EF...|ENSG00000041880|Small molecule dr...|\n",
      "|CHEMBL1173055|CNCc1ccc(-c2[nH]c...|HMABYWSNWIZPAG-UH...|Small molecule|          false|           RUCAPARIB|               2016|                      4.0|    NULL|           false|      true|                  []|[AG-014699, AG-14...|{DailyMed -> [ruc...|[CHEMBL2105733, C...|{[EFO_0003060, EF...|ENSG00000129484|Small molecule dr...|\n",
      "|CHEMBL1200910|CC(=O)N(c1onc(C)c...|JFNWFXVFBDDWCX-UH...|Small molecule|          false|SULFISOXAZOLE ACETYL|               1953|                      4.0|    NULL|           false|      true|[Gantrisin, Gantr...|[Acetyl sulfafura...|{DailyMed -> [sul...|                NULL|                NULL|           NULL|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|ENSG00000138435|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|ENSG00000196811|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|ENSG00000170175|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|ENSG00000135902|Small molecule dr...|\n",
      "|CHEMBL1201248|COc1ccc(C[C@@H]2c...|YXSLJKQTIDHPOT-LJ...|Small molecule|          false|       CISATRACURIUM|               1995|                      4.0|    NULL|           false|      true|            [Nimbex]|[Cisatracurium, C...|{DailyMed -> [cis...|     [CHEMBL1200641]|  {[EFO_1000637], 1}|ENSG00000108556|Small molecule dr...|\n",
      "|CHEMBL1201468|                NULL|                NULL|Small molecule|           true|ESTROGENS, ESTERI...|               1977|                      4.0|    NULL|           false|      true|[Amnestrogen, Est...|[Esterified estro...|{DailyMed -> [est...|                NULL|{[EFO_1000096, EF...|ENSG00000140009|Small molecule dr...|\n",
      "|CHEMBL1201468|                NULL|                NULL|Small molecule|           true|ESTROGENS, ESTERI...|               1977|                      4.0|    NULL|           false|      true|[Amnestrogen, Est...|[Esterified estro...|{DailyMed -> [est...|                NULL|{[EFO_1000096, EF...|ENSG00000091831|Small molecule dr...|\n",
      "|CHEMBL1201718|                NULL|                NULL|        Enzyme|          false|HYALURONIDASE (HU...|               2005|                      4.0|    NULL|           false|      true|[Cumulase, Hylene...|[Chemophase, Enha...|{DailyMed -> [hya...|                NULL|{[EFO_1000668, MO...|           NULL|Enzyme drug with ...|\n",
      "|CHEMBL1201772|CC(=O)Oc1cc2c(s1)...|DTGLZDAWLRGWQN-UH...|Small molecule|           true|           PRASUGREL|               2009|                      4.0|    NULL|           false|      true|            [Efient]|[LY-640315, NSC-7...|{DailyMed -> [pra...|     [CHEMBL1201773]|{[EFO_0003777, EF...|ENSG00000169313|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000145675|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000051382|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000105851|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000121879|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000105647|Small molecule dr...|\n",
      "|CHEMBL1234354|COc1ccc(-c2cc3c(C...|XDLYKKIQACFMJG-WK...|Small molecule|          false|         PF-04691502|               NULL|                      2.0|    NULL|           false|     false|                  []|[PF-04691502, PF-...|{drugbank -> [DB1...|                NULL|{[EFO_0003869, MO...|ENSG00000171608|Small molecule dr...|\n",
      "+-------------+--------------------+--------------------+--------------+---------------+--------------------+-------------------+-------------------------+--------+----------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of rows with linkedTargets = NULL after explosion: 12166\n"
     ]
    }
   ],
   "source": [
    "# Explode molecule dataset with preserving unknown MoA\n",
    "\n",
    "from pyspark.sql.functions import explode_outer, col\n",
    "\n",
    "# Extract 'rows' from 'linkedTargets' and explode using explode_outer\n",
    "molecule_exploded = molecule.withColumn(\"linkedTargets\", explode_outer(col(\"linkedTargets.rows\")))\n",
    "\n",
    "molecule_exploded.show()\n",
    "\n",
    "\n",
    "# Count the number of rows where the exploded linkedTargets is NULL\n",
    "num_null_linkedTargets = molecule_exploded.filter(col(\"linkedTargets\").isNull()).count()\n",
    "\n",
    "print(f\"Number of rows with linkedTargets = NULL after explosion: {num_null_linkedTargets}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             id|approvedSymbol|       biotype|       transcriptIds| canonicalTranscript|      canonicalExons|     genomicLocation|alternativeGenes|        approvedName|                  go|           hallmarks|            synonyms|      symbolSynonyms|        nameSynonyms|functionDescriptions|subcellularLocations|         targetClass|     obsoleteSymbols|       obsoleteNames|          constraint| tep|          proteinIds|             dbXrefs|chemicalProbes|          homologues|        tractability|   safetyLiabilities|            pathways|\n",
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|                NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|                NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|                NULL|[{R-HSA-198933, I...|\n",
      "|ENSG00000015479|         MATR3|protein_coding|[ENST00000504311,...|{ENST00000394805,...|[139329345, 13933...|{5, 139293674, 13...|            NULL|            matrin 3|[{GO:0005515, PMI...|                NULL|[{Matrin-3, unipr...|[{MATR3, uniprot}...|[{Matrin-3, unipr...|[May play a role ...|[{Nucleus matrix,...|                NULL|      [{MPD2, HGNC}]|[{myopathy, dista...|[{syn, 0.014086, ...|NULL|[{P43243, uniprot...|[{6912, HGNC}, {I...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|                NULL|                NULL|\n",
      "|ENSG00000037280|          FLT4|protein_coding|[ENST00000619105,...|{ENST00000261937,...|[180601506, 18060...|{5, 180601506, 18...|            NULL|fms related recep...|[{GO:0048010, PMI...|{[{26735859, onco...|[{Vascular endoth...|[{FLT4, uniprot},...|[{Vascular endoth...|[Tyrosine-protein...|[{Cell membrane, ...|[{0, Tyrosine pro...|                  []|[{fms-related tyr...|[{syn, -1.7724, 3...|NULL|[{P35916, uniprot...|[{3767, HGNC}, {4...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|[{regulation of c...|[{R-HSA-195399, V...|\n",
      "|ENSG00000038427|          VCAN|protein_coding|[ENST00000503923,...|{ENST00000265077,...|[83537007, 835422...|{5, 83471618, 835...|            NULL|            versican|[{GO:0062023, PMI...|                NULL|[{Versican core p...|[{VCAN, uniprot},...|[{Versican core p...|[May play a role ...|[{Secreted, unipr...|                NULL|     [{CSPG2, HGNC}]|[{chondroitin sul...|[{syn, -0.17851, ...|NULL|[{P13611, uniprot...|[{2464, HGNC}, {D...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|                NULL|[{R-HSA-3000178, ...|\n",
      "|ENSG00000050730|         TNIP3|protein_coding|[ENST00000057513,...|{ENST00000057513,...|[121131408, 12113...|{4, 121131408, 12...|            NULL|TNFAIP3 interacti...|[{GO:0071222, PMI...|                NULL|[{TNFAIP3-interac...|[{TNIP3, uniprot}...|[{TNFAIP3-interac...|[Binds to zinc fi...|                  []|                NULL|                  []|                  []|[{syn, 0.71271, 7...|NULL|[{Q96KP6, uniprot...|[{19315, HGNC}, {...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|                NULL|[{R-HSA-5689896, ...|\n",
      "|ENSG00000073050|         XRCC1|protein_coding|[ENST00000594511,...|{ENST00000262887,...|[43546884, 435469...|{19, 43543311, 43...|            NULL|X-ray repair cros...|[{GO:1990599, GO_...|                NULL|[{DNA repair prot...|[{XRCC1, uniprot}...|[{DNA repair prot...|[Scaffold protein...|[{Nucleus, unipro...|                NULL|       [{RCC, HGNC}]|[{X-ray repair co...|[{syn, 0.88931, 1...|NULL|[{P18887, uniprot...|[{12828, HGNC}, {...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|                NULL|[{R-HSA-6782210, ...|\n",
      "|ENSG00000076864|       RAP1GAP|protein_coding|[ENST00000464457,...|{ENST00000374765,...|[21613176, 216132...|{1, 21596221, 216...|            NULL|RAP1 GTPase activ...|[{GO:0002250, Rea...|                NULL|[{Rap1 GTPase-act...|[{RAP1GAP, unipro...|[{Rap1 GTPase-act...|[GTPase activator...|[{Golgi apparatus...|                NULL|   [{RAP1GA1, HGNC}]|[{RAP1, GTPase ac...|[{syn, -0.36981, ...|NULL|[{P47736, uniprot...|[{9858, HGNC}, {1...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|                NULL|[{R-HSA-8853659, ...|\n",
      "|ENSG00000078114|          NEBL|protein_coding|[ENST00000493005,...|{ENST00000377122,...|[20808510, 208086...|{10, 20779973, 21...|            NULL|           nebulette|[{GO:0005515, PMI...|                NULL|[{Nebulette, unip...|[{NEBL, uniprot},...|[{Nebulette, unip...|[Binds to actin a...|[{[Isoform 2]: Cy...|                NULL| [{C10orf113, HGNC}]|[{chromosome 10 o...|[{syn, -1.2753, 1...|NULL|[{O76041, uniprot...|[{16932, HGNC}, {...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|                NULL|                NULL|\n",
      "|ENSG00000085552|         IGSF9|protein_coding|[ENST00000476102,...|{ENST00000368094,...|[159943397, 15994...|{1, 159927039, 15...|            NULL|immunoglobulin su...|[{GO:0007411, PMI...|                NULL|[{Protein turtle ...|[{IGSF9, uniprot}...|[{Protein turtle ...|[Functions in den...|[{Cell membrane, ...|                NULL|                  []|[{immunoglobulin ...|[{syn, 0.78784, 2...|NULL|[{Q9P2J2, uniprot...|[{18132, HGNC}, {...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|                NULL|                NULL|\n",
      "|ENSG00000089685|         BIRC5|protein_coding|[ENST00000586192,...|{ENST00000350051,...|[78214253, 782144...|{17, 78214186, 78...|            NULL|baculoviral IAP r...|[{GO:0005515, PMI...|                NULL|[{Baculoviral IAP...|[{BIRC5, uniprot}...|[{Baculoviral IAP...|[Multitasking pro...|[{Cytoplasm, unip...|[{0, Unclassified...|      [{API4, HGNC}]|[{apoptosis inhib...|[{syn, 0.271, 32....|NULL|[{O15392, uniprot...|[{593, HGNC}, {1E...|          NULL|[{9606, Human, ot...|[{SM, Approved Dr...|                NULL|[{R-HSA-2500257, ...|\n",
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# biodata_all_min: from uniprot in \"accession\" to ensembl id \n",
    "targets_path = \"data/targets\"\n",
    "targets = spark.read.parquet(targets_path)\n",
    "targets.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(id='P14209', source='uniprot_swissprot'), Row(id='A0A096LP69', source='uniprot_trembl'), Row(id='A6NGF6', source='uniprot_trembl'), Row(id='A6NJT9', source='uniprot_trembl'), Row(id='A8MQT7', source='uniprot_trembl'), Row(id='A6NIW1', source='uniprot_obsolete'), Row(id='O00518', source='uniprot_obsolete'), Row(id='Q6ICV7', source='uniprot_obsolete')]\n"
     ]
    }
   ],
   "source": [
    "# Just a check for format\n",
    "\n",
    "from pyspark.sql.functions import first\n",
    "\n",
    "# Retrieve the value from the first row and column named \"proteinIds\"\n",
    "value = targets.select(first(\"proteinIds\")).collect()[0][0]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+----------+\n",
      "|       targetID|approvedSymbol|       biotype|       transcriptIds| canonicalTranscript|      canonicalExons|     genomicLocation|alternativeGenes|        approvedName|                  go|hallmarks|            synonyms|      symbolSynonyms|        nameSynonyms|functionDescriptions|subcellularLocations|targetClass|     obsoleteSymbols|       obsoleteNames|          constraint| tep|          proteinIds|             dbXrefs|chemicalProbes|          homologues|        tractability|safetyLiabilities|            pathways|             uniprot| accession|\n",
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+----------+\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|     NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|       NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|             NULL|[{R-HSA-198933, I...|{P14209, uniprot_...|    P14209|\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|     NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|       NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|             NULL|[{R-HSA-198933, I...|{A0A096LP69, unip...|A0A096LP69|\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|     NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|       NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|             NULL|[{R-HSA-198933, I...|{A6NGF6, uniprot_...|    A6NGF6|\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|     NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|       NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|             NULL|[{R-HSA-198933, I...|{A6NJT9, uniprot_...|    A6NJT9|\n",
      "|ENSG00000002586|          CD99|protein_coding|[ENST00000482405,...|{ENST00000381192,...|[2738200, 2738256...|{X, 2691187, 2741...|            NULL|CD99 molecule (Xg...|[{GO:0005515, PMI...|     NULL|[{CD99 antigen, u...|[{CD99, uniprot},...|[{CD99 antigen, u...|[Involved in T-ce...|[{Membrane, unipr...|       NULL|[{MIC2, HGNC}, {M...|[{antigen identif...|[{syn, -0.16373, ...|NULL|[{P14209, uniprot...|[{7082, HGNC}, {7...|          NULL|[{9606, Human, wi...|[{SM, Approved Dr...|             NULL|[{R-HSA-198933, I...|{A8MQT7, uniprot_...|    A8MQT7|\n",
      "+---------------+--------------+--------------+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------------+----+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploding all uniprot types\n",
    "\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Explode the proteinIds column to 'uniprot'\n",
    "targets_exploded = targets.withColumn(\"uniprot\", explode(col(\"proteinIds\")))\n",
    "\n",
    "# Extract and rename 'id' from 'uniprot' to 'targetID'\n",
    "targets_extracted = targets_exploded.withColumn(\"accession\", col(\"uniprot.id\"))\n",
    "\n",
    "targets_extracted = targets_extracted.withColumnRenamed(\"id\", \"targetID\")\n",
    "\n",
    "targets_extracted.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639|\n",
      "|   Q12809|  CHEMBL1000|  111185|   CHEMBL954102|     1|    LITERATURE|     Bioorg Med Chem|1.8448342E7|10.1016/j.bmc.200...|   165|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|ENSG00000055118|\n",
      "|   Q99808|CHEMBL100259|  161181|  CHEMBL3528990|     1|    LITERATURE|   Drug Metab Dispos|2.3388705E7|10.1124/dmd.112.0...|   175|Equilibrative nuc...|      CHEMBL1997|Homo sapiens|       51000.0|            nM|                =|         4.29|ENSG00000112759|\n",
      "|   P03372| CHEMBL10041|    6341|  CHEMBL5121196|     1|    LITERATURE|      Eur J Med Chem|3.4710747E7|10.1016/j.ejmech....|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|          1.12|            nM|                =|         8.95|ENSG00000091831|\n",
      "|   P03372|CHEMBL100763|  163958|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|         3.304|            nM|                =|         8.48|ENSG00000091831|\n",
      "|   Q92731|CHEMBL100763|  163958|   CHEMBL831659|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         302.0|            nM|                =|         6.52|ENSG00000140009|\n",
      "|   Q13936|  CHEMBL1008|  112651|  CHEMBL3436051|     1|    LITERATURE|      J Appl Toxicol|   2.2761E7|    10.1002/jat.2784|   169|Voltage-gated L-t...|      CHEMBL1940|Homo sapiens|        1400.0|            nM|                =|         5.85|ENSG00000151067|\n",
      "|   Q12809|  CHEMBL1008|  112651|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|   165|                HERG|       CHEMBL240|Homo sapiens|         22.91|            nM|                =|         7.64|ENSG00000055118|\n",
      "|   P51589|  CHEMBL1008|  112651|  CHEMBL3541093|     1|    LITERATURE|   Drug Metab Dispos|2.3033255E7|10.1124/dmd.112.0...|100611| Cytochrome P450 2J2|      CHEMBL3491|Homo sapiens|       11500.0|            nM|                =|         4.94|ENSG00000134716|\n",
      "|   P06239|  CHEMBL1009|  112655|  CHEMBL1909206|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10140|Tyrosine-protein ...|       CHEMBL258|Homo sapiens|        3729.0|            nM|                =|         5.43|ENSG00000182866|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining with ensembl id by uniprot \n",
    "\n",
    "biodata_all_ensembl = biodata_all_min.join(targets_extracted.select(\"accession\", \"targetID\"), on=\"accession\", how=\"left\").drop(targets_extracted[\"accession\"])\n",
    "\n",
    "biodata_all_ensembl.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639| true|\n",
      "|   Q12809|  CHEMBL1000|  111185|   CHEMBL954102|     1|    LITERATURE|     Bioorg Med Chem|1.8448342E7|10.1016/j.bmc.200...|   165|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|ENSG00000055118|false|\n",
      "|   Q99808|CHEMBL100259|  161181|  CHEMBL3528990|     1|    LITERATURE|   Drug Metab Dispos|2.3388705E7|10.1124/dmd.112.0...|   175|Equilibrative nuc...|      CHEMBL1997|Homo sapiens|       51000.0|            nM|                =|         4.29|ENSG00000112759|false|\n",
      "|   P03372| CHEMBL10041|    6341|  CHEMBL5121196|     1|    LITERATURE|      Eur J Med Chem|3.4710747E7|10.1016/j.ejmech....|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|          1.12|            nM|                =|         8.95|ENSG00000091831|false|\n",
      "|   P03372|CHEMBL100763|  163958|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|         3.304|            nM|                =|         8.48|ENSG00000091831|false|\n",
      "|   Q92731|CHEMBL100763|  163958|   CHEMBL831659|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         302.0|            nM|                =|         6.52|ENSG00000140009|false|\n",
      "|   Q13936|  CHEMBL1008|  112651|  CHEMBL3436051|     1|    LITERATURE|      J Appl Toxicol|   2.2761E7|    10.1002/jat.2784|   169|Voltage-gated L-t...|      CHEMBL1940|Homo sapiens|        1400.0|            nM|                =|         5.85|ENSG00000151067| true|\n",
      "|   Q12809|  CHEMBL1008|  112651|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|   165|                HERG|       CHEMBL240|Homo sapiens|         22.91|            nM|                =|         7.64|ENSG00000055118|false|\n",
      "|   P51589|  CHEMBL1008|  112651|  CHEMBL3541093|     1|    LITERATURE|   Drug Metab Dispos|2.3033255E7|10.1124/dmd.112.0...|100611| Cytochrome P450 2J2|      CHEMBL3491|Homo sapiens|       11500.0|            nM|                =|         4.94|ENSG00000134716|false|\n",
      "|   O15439|  CHEMBL1010|  112665|  CHEMBL4028924|     1|    LITERATURE|         Toxicol Sci|2.3956101E7|10.1093/toxsci/kf...|104069|Multidrug resista...|   CHEMBL1743128|Homo sapiens|       24000.0|            nM|                =|         4.62|ENSG00000125257|false|\n",
      "|   P07333|CHEMBL101253|  165012|  CHEMBL1063702|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12840|Macrophage colony...|      CHEMBL1844|Homo sapiens|          18.0|            nM|                =|         7.75|ENSG00000182578| true|\n",
      "|   P10721|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|\n",
      "|   P00533|CHEMBL101253|  165012|   CHEMBL892951|     1|    LITERATURE|     Bioorg Med Chem|1.7416531E7|10.1016/j.bmc.200...|     9|Epidermal growth ...|       CHEMBL203|Homo sapiens|         457.7|            nM|                =|         6.34|ENSG00000146648|false|\n",
      "|   P07949|CHEMBL101253|  165012|  CHEMBL1051257|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|100079|Tyrosine-protein ...|      CHEMBL2041|Homo sapiens|        7600.0|            nM|                =|         5.12|ENSG00000165731|false|\n",
      "|   P42685|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|\n",
      "|   O14578|CHEMBL101253|  165012|  CHEMBL1908762|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101239|Citron Rho-intera...|      CHEMBL5579|Homo sapiens|        8800.0|            nM|                =|         5.06|ENSG00000122966|false|\n",
      "|   P03372|CHEMBL101382|  164146|   CHEMBL836357|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|104682|   Estrogen receptor|   CHEMBL2093866|Homo sapiens|          32.0|            nM|                =|          7.5|ENSG00000091831|false|\n",
      "|   P30556|  CHEMBL1016|  116848|  CHEMBL3791105|     1|    LITERATURE|          J Med Chem|2.6824643E7|10.1021/acs.jmedc...|   115|Type-1 angiotensi...|       CHEMBL227|Homo sapiens|          0.69|            nM|                =|         9.16|ENSG00000144891| true|\n",
      "|   P19793|CHEMBL101661|  163356|   CHEMBL798296|     1|    LITERATURE|          J Med Chem|  8071941.0| 10.1021/jm00044a014|   275|Retinoid X recept...|      CHEMBL2061|Homo sapiens|          28.0|            nM|                =|         7.55|ENSG00000186350|false|\n",
      "|   Q9NPD5|  CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29698"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding MoAs in molecule_exploded (id, linkedTargets)\n",
    "\n",
    "joined_df = biodata_all_ensembl.join(\n",
    "    molecule_exploded,\n",
    "    (biodata_all_ensembl.chembl_id == molecule_exploded.id) & \n",
    "    (biodata_all_ensembl.targetID == molecule_exploded.linkedTargets),\n",
    "    'left'\n",
    ")\n",
    "\n",
    "# Create isMoA column based on whether drugId (if) is not null after the join\n",
    "biodata_all_with_isMoA = joined_df.withColumn(\n",
    "    \"isMoA\",\n",
    "    F.when(F.col(\"id\").isNotNull(), True).otherwise(False)\n",
    ")\n",
    "\n",
    "# # Create unknownMoA column based on whether linkedTargets is null\n",
    "# biodata_all_with_unknownMoA = biodata_all_with_isMoA.withColumn(\n",
    "#     \"unknownMoA\",\n",
    "#     F.when(F.col(\"linkedTargets\").isNull(), True).otherwise(False)\n",
    "# )\n",
    "\n",
    "# Select only columns from biodata_all_ensembl and the new isMoA & unknownMoA columns\n",
    "final_biodata_all_min = biodata_all_with_isMoA.select(*biodata_all_ensembl.columns, \"isMoA\").dropDuplicates(subset=biodata_all_ensembl.columns)\n",
    "\n",
    "final_biodata_all_min.show()\n",
    "final_biodata_all_min.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|       linkedTargets|          id|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639| true|{[ENSG00000196639...|  CHEMBL1000|\n",
      "|   Q12809|  CHEMBL1000|  111185|   CHEMBL954102|     1|    LITERATURE|     Bioorg Med Chem|1.8448342E7|10.1016/j.bmc.200...|   165|                HERG|       CHEMBL240|Homo sapiens|      30199.52|            nM|                =|         4.52|ENSG00000055118|false|{[ENSG00000196639...|  CHEMBL1000|\n",
      "|   Q99808|CHEMBL100259|  161181|  CHEMBL3528990|     1|    LITERATURE|   Drug Metab Dispos|2.3388705E7|10.1124/dmd.112.0...|   175|Equilibrative nuc...|      CHEMBL1997|Homo sapiens|       51000.0|            nM|                =|         4.29|ENSG00000112759|false|                NULL|CHEMBL100259|\n",
      "|   P03372| CHEMBL10041|    6341|  CHEMBL5121196|     1|    LITERATURE|      Eur J Med Chem|3.4710747E7|10.1016/j.ejmech....|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|          1.12|            nM|                =|         8.95|ENSG00000091831|false|                NULL| CHEMBL10041|\n",
      "|   P03372|CHEMBL100763|  163958|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|         3.304|            nM|                =|         8.48|ENSG00000091831|false|                NULL|CHEMBL100763|\n",
      "|   Q92731|CHEMBL100763|  163958|   CHEMBL831659|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         302.0|            nM|                =|         6.52|ENSG00000140009|false|                NULL|CHEMBL100763|\n",
      "|   Q13936|  CHEMBL1008|  112651|  CHEMBL3436051|     1|    LITERATURE|      J Appl Toxicol|   2.2761E7|    10.1002/jat.2784|   169|Voltage-gated L-t...|      CHEMBL1940|Homo sapiens|        1400.0|            nM|                =|         5.85|ENSG00000151067| true|{[ENSG00000196557...|  CHEMBL1008|\n",
      "|   Q12809|  CHEMBL1008|  112651|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|   165|                HERG|       CHEMBL240|Homo sapiens|         22.91|            nM|                =|         7.64|ENSG00000055118|false|{[ENSG00000196557...|  CHEMBL1008|\n",
      "|   P51589|  CHEMBL1008|  112651|  CHEMBL3541093|     1|    LITERATURE|   Drug Metab Dispos|2.3033255E7|10.1124/dmd.112.0...|100611| Cytochrome P450 2J2|      CHEMBL3491|Homo sapiens|       11500.0|            nM|                =|         4.94|ENSG00000134716|false|{[ENSG00000196557...|  CHEMBL1008|\n",
      "|   O15439|  CHEMBL1010|  112665|  CHEMBL4028924|     1|    LITERATURE|         Toxicol Sci|2.3956101E7|10.1093/toxsci/kf...|104069|Multidrug resista...|   CHEMBL1743128|Homo sapiens|       24000.0|            nM|                =|         4.62|ENSG00000125257|false|             {[], 0}|  CHEMBL1010|\n",
      "|   P07333|CHEMBL101253|  165012|  CHEMBL1063702|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12840|Macrophage colony...|      CHEMBL1844|Homo sapiens|          18.0|            nM|                =|         7.75|ENSG00000182578| true|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   P10721|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   P00533|CHEMBL101253|  165012|   CHEMBL892951|     1|    LITERATURE|     Bioorg Med Chem|1.7416531E7|10.1016/j.bmc.200...|     9|Epidermal growth ...|       CHEMBL203|Homo sapiens|         457.7|            nM|                =|         6.34|ENSG00000146648|false|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   P07949|CHEMBL101253|  165012|  CHEMBL1051257|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|100079|Tyrosine-protein ...|      CHEMBL2041|Homo sapiens|        7600.0|            nM|                =|         5.12|ENSG00000165731|false|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   P42685|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   O14578|CHEMBL101253|  165012|  CHEMBL1908762|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101239|Citron Rho-intera...|      CHEMBL5579|Homo sapiens|        8800.0|            nM|                =|         5.06|ENSG00000122966|false|{[ENSG00000157404...|CHEMBL101253|\n",
      "|   P03372|CHEMBL101382|  164146|   CHEMBL836357|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|104682|   Estrogen receptor|   CHEMBL2093866|Homo sapiens|          32.0|            nM|                =|          7.5|ENSG00000091831|false|                NULL|CHEMBL101382|\n",
      "|   P30556|  CHEMBL1016|  116848|  CHEMBL3791105|     1|    LITERATURE|          J Med Chem|2.6824643E7|10.1021/acs.jmedc...|   115|Type-1 angiotensi...|       CHEMBL227|Homo sapiens|          0.69|            nM|                =|         9.16|ENSG00000144891| true|{[ENSG00000144891...|  CHEMBL1016|\n",
      "|   P19793|CHEMBL101661|  163356|   CHEMBL798296|     1|    LITERATURE|          J Med Chem|  8071941.0| 10.1021/jm00044a014|   275|Retinoid X recept...|      CHEMBL2061|Homo sapiens|          28.0|            nM|                =|         7.55|ENSG00000186350|false|                NULL|CHEMBL101661|\n",
      "|   Q9NPD5|  CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|{[ENSG00000144891...|  CHEMBL1017|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each drug add MoA profile\n",
    "joined_df = final_biodata_all_min.join(\n",
    "    molecule.select(\"linkedTargets\", \"id\"),\n",
    "    (final_biodata_all_min.chembl_id == molecule.id),\n",
    "    'left'\n",
    ")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biodata + GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|       linkedTargets|          id|      drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+\n",
      "|   P30968|  CHEMBL1007|  112560|   CHEMBL709251|     1|    LITERATURE|          J Med Chem|  9784092.0|   10.1021/jm9803673|   118|Gonadotropin-rele...|      CHEMBL1855|Homo sapiens|          10.0|            nM|                =|          8.0|ENSG00000109163| true|{[ENSG00000109163...|  CHEMBL1007|  CHEMBL1007|   P30968|[impc, eva, orpha...|             false|               true|\n",
      "|   P10721|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P10721|[uniprot_literatu...|             false|               true|\n",
      "|   P42685|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P42685|[ot_genetics_port...|             false|               true|\n",
      "|   P37231|  CHEMBL1014|  116349|  CHEMBL4768835|     1|    LITERATURE|      Eur J Med Chem| 3.227242E7|10.1016/j.ejmech....|   133|Peroxisome prolif...|       CHEMBL235|Homo sapiens|        4200.0|            nM|                =|         5.38|ENSG00000132170|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   P37231|[impc, eva, ot_ge...|             false|               true|\n",
      "|   Q9NPD5|  CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|{[ENSG00000144891...|  CHEMBL1017|  CHEMBL1017|   Q9NPD5|              [impc]|             false|              false|\n",
      "|   P05177| CHEMBL10188|    6760|  CHEMBL1763137|     1|    LITERATURE|Bioorg Med Chem Lett|2.1376585E7|10.1016/j.bmcl.20...| 12594| Cytochrome P450 1A2|      CHEMBL3356|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000140505|false|{[ENSG00000169836...| CHEMBL10188|        NULL|     NULL|                NULL|              NULL|               NULL|\n",
      "|   P48443|  CHEMBL1023|  119498|   CHEMBL800755|     1|    LITERATURE|          J Med Chem|  9435893.0|   10.1021/jm9704309|   266|Retinoid X recept...|      CHEMBL2004|Homo sapiens|           8.3|            nM|                =|         8.08|ENSG00000143171| true|{[ENSG00000204231...|  CHEMBL1023|  CHEMBL1023|   P48443|            [chembl]|             false|               true|\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639| true|{[ENSG00000196639...|  CHEMBL1000|  CHEMBL1000|   P35367|            [chembl]|             false|               true|\n",
      "|   P03372|CHEMBL100231|  164265|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|           5.2|            nM|                =|         8.28|ENSG00000091831|false|                NULL|CHEMBL100231|CHEMBL100231|   P03372|    [chemicalProbes]|             false|              false|\n",
      "|   P35498|  CHEMBL1008|  112651|   CHEMBL806152|     1|    LITERATURE|          J Med Chem|  2579237.0| 10.1021/jm00381a019|104837|Sodium channel al...|   CHEMBL2096682|Homo sapiens|         840.0|            nM|                =|         6.08|ENSG00000144285|false|{[ENSG00000196557...|  CHEMBL1008|  CHEMBL1008|   P35498|[uniprot_literatu...|             false|               true|\n",
      "|   P49336|CHEMBL101253|  165012|  CHEMBL1908526|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101300|Cell division pro...|      CHEMBL5719|Homo sapiens|        4500.0|            nM|                =|         5.35|ENSG00000132964|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P49336|[ot_genetics_port...|             false|               true|\n",
      "|   Q9UNQ0|  CHEMBL1014|  116349|  CHEMBL5128685|     1|    LITERATURE|      Eur J Med Chem|3.5483322E7|10.1016/j.ejmech....|100974|ATP-binding casse...|      CHEMBL5393|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000118777|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9UNQ0|[impc, ot_genetic...|             false|              false|\n",
      "|   Q9Y253|  CHEMBL1014|  116349|  CHEMBL3854643|     1|    LITERATURE|          J Med Chem|2.7362876E7|10.1021/acs.jmedc...|101013|  DNA polymerase eta|      CHEMBL5542|Homo sapiens|       11200.0|            nM|                =|         4.95|ENSG00000170734|false|{[ENSG00000144891...|  CHEMBL1014|        NULL|     NULL|                NULL|              NULL|               NULL|\n",
      "|   Q9Y6L6|  CHEMBL1014|  116349|  CHEMBL3039490|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|103947|Solute carrier or...|   CHEMBL1697668|Homo sapiens|         400.0|            nM|                =|          6.4|ENSG00000134538|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9Y6L6|[ot_genetics_portal]|             false|              false|\n",
      "|   Q9NPC1|  CHEMBL1016|  116848|  CHEMBL4839253|     1|    LITERATURE|   ACS Med Chem Lett|3.4413955E7|10.1021/acsmedche...| 10868|Leukotriene B4 re...|      CHEMBL3191|Homo sapiens|       15000.0|            nM|                =|         4.82|ENSG00000213906|false|{[ENSG00000144891...|  CHEMBL1016|  CHEMBL1016|   Q9NPC1|              [impc]|             false|              false|\n",
      "|   P21452| CHEMBL10188|    6760|   CHEMBL818108|     1|    LITERATURE|          J Med Chem|1.1356103E7|   10.1021/jm000501v| 10184|Neurokinin 2 rece...|      CHEMBL2327|Homo sapiens|         144.0|            nM|                =|         6.84|ENSG00000075073|false|{[ENSG00000169836...| CHEMBL10188| CHEMBL10188|   P21452|            [chembl]|             false|               true|\n",
      "|   P09619|CHEMBL101253|  165012|  CHEMBL1051304|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|   197|Platelet-derived ...|      CHEMBL1913|Homo sapiens|          25.0|            nM|                =|          7.6|ENSG00000113721| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P09619|[uniprot_literatu...|             false|               true|\n",
      "|   P16234|CHEMBL101253|  165012|  CHEMBL1062783|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12627|Platelet-derived ...|      CHEMBL2007|Homo sapiens|          96.0|            nM|                =|         7.02|ENSG00000134853| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P16234|[uniprot_literatu...|             false|               true|\n",
      "|   Q92731|CHEMBL101382|  164146|   CHEMBL832383|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         289.0|            nM|                =|         6.54|ENSG00000140009|false|                NULL|CHEMBL101382|        NULL|     NULL|                NULL|              NULL|               NULL|\n",
      "|   Q92731|CHEMBL100231|  164265|   CHEMBL678131|     1|    LITERATURE|          J Med Chem|1.2825935E7|   10.1021/jm030086h|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|        3687.0|            nM|                =|         5.43|ENSG00000140009|false|                NULL|CHEMBL100231|        NULL|     NULL|                NULL|              NULL|               NULL|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29708"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join biodata_all_min with GE+ dataset\n",
    "\n",
    "drug2target_parquet_dir = \"./data/drug_to_target\"\n",
    "drug2target_parquet = spark.read.parquet(drug2target_parquet_dir)\n",
    "\n",
    "columns_to_join = drug2target_parquet.select('drugId', 'uniprotId', 'sources', 'isHighQualityProbe', 'isTherapeuticTarget')\n",
    "\n",
    "biodata_all_join = joined_df.join(columns_to_join, \n",
    "                            (joined_df.chembl_id == columns_to_join.drugId) & \n",
    "                            (joined_df.accession == columns_to_join.uniprotId), \n",
    "                            how=\"left\")\n",
    "biodata_all_join.show()\n",
    "biodata_all_join.count()\n",
    "\n",
    "# num_biodata_all_join = biodata_all_join.count()\n",
    "# num_biodata_all_min = final_biodata_all_min.count()\n",
    "\n",
    "# print(\"Number of unique drug-target pairs with GE+ with pChEMBL:\", num_biodata_all_join)\n",
    "\n",
    "# print(\"Number of unique drug-target pairs with pChEMBL\", num_biodata_all_min)\n",
    "\n",
    "# print(\"For\", round(num_biodata_all_join/num_biodata_all_min*100), \"% of drug-target pairs with pChEMBL we have GE+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|       linkedTargets|          id|      drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|proteinClass|isActive|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|   P30968|  CHEMBL1007|  112560|   CHEMBL709251|     1|    LITERATURE|          J Med Chem|  9784092.0|   10.1021/jm9803673|   118|Gonadotropin-rele...|      CHEMBL1855|Homo sapiens|          10.0|            nM|                =|          8.0|ENSG00000109163| true|{[ENSG00000109163...|  CHEMBL1007|  CHEMBL1007|   P30968|[impc, eva, orpha...|             false|               true|        GPCR|    TRUE|\n",
      "|   P10721|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P10721|[uniprot_literatu...|             false|               true|      Kinase|    TRUE|\n",
      "|   P42685|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P42685|[ot_genetics_port...|             false|               true|      Kinase|   FALSE|\n",
      "|   P37231|  CHEMBL1014|  116349|  CHEMBL4768835|     1|    LITERATURE|      Eur J Med Chem| 3.227242E7|10.1016/j.ejmech....|   133|Peroxisome prolif...|       CHEMBL235|Homo sapiens|        4200.0|            nM|                =|         5.38|ENSG00000132170|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   P37231|[impc, eva, ot_ge...|             false|               true|          NR|   FALSE|\n",
      "|   Q9NPD5|  CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|{[ENSG00000144891...|  CHEMBL1017|  CHEMBL1017|   Q9NPD5|              [impc]|             false|              false| Transporter|   FALSE|\n",
      "|   P05177| CHEMBL10188|    6760|  CHEMBL1763137|     1|    LITERATURE|Bioorg Med Chem Lett|2.1376585E7|10.1016/j.bmcl.20...| 12594| Cytochrome P450 1A2|      CHEMBL3356|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000140505|false|{[ENSG00000169836...| CHEMBL10188|        NULL|     NULL|                NULL|              NULL|               NULL|        None|    TRUE|\n",
      "|   P48443|  CHEMBL1023|  119498|   CHEMBL800755|     1|    LITERATURE|          J Med Chem|  9435893.0|   10.1021/jm9704309|   266|Retinoid X recept...|      CHEMBL2004|Homo sapiens|           8.3|            nM|                =|         8.08|ENSG00000143171| true|{[ENSG00000204231...|  CHEMBL1023|  CHEMBL1023|   P48443|            [chembl]|             false|               true|          NR|    TRUE|\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639| true|{[ENSG00000196639...|  CHEMBL1000|  CHEMBL1000|   P35367|            [chembl]|             false|               true|        GPCR|    TRUE|\n",
      "|   P03372|CHEMBL100231|  164265|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|           5.2|            nM|                =|         8.28|ENSG00000091831|false|                NULL|CHEMBL100231|CHEMBL100231|   P03372|    [chemicalProbes]|             false|              false|          NR|    TRUE|\n",
      "|   P35498|  CHEMBL1008|  112651|   CHEMBL806152|     1|    LITERATURE|          J Med Chem|  2579237.0| 10.1021/jm00381a019|104837|Sodium channel al...|   CHEMBL2096682|Homo sapiens|         840.0|            nM|                =|         6.08|ENSG00000144285|false|{[ENSG00000196557...|  CHEMBL1008|  CHEMBL1008|   P35498|[uniprot_literatu...|             false|               true|          IC|    TRUE|\n",
      "|   P49336|CHEMBL101253|  165012|  CHEMBL1908526|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101300|Cell division pro...|      CHEMBL5719|Homo sapiens|        4500.0|            nM|                =|         5.35|ENSG00000132964|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P49336|[ot_genetics_port...|             false|               true|      Kinase|   FALSE|\n",
      "|   Q9UNQ0|  CHEMBL1014|  116349|  CHEMBL5128685|     1|    LITERATURE|      Eur J Med Chem|3.5483322E7|10.1016/j.ejmech....|100974|ATP-binding casse...|      CHEMBL5393|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000118777|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9UNQ0|[impc, ot_genetic...|             false|              false| Transporter|   FALSE|\n",
      "|   Q9Y253|  CHEMBL1014|  116349|  CHEMBL3854643|     1|    LITERATURE|          J Med Chem|2.7362876E7|10.1021/acs.jmedc...|101013|  DNA polymerase eta|      CHEMBL5542|Homo sapiens|       11200.0|            nM|                =|         4.95|ENSG00000170734|false|{[ENSG00000144891...|  CHEMBL1014|        NULL|     NULL|                NULL|              NULL|               NULL|      Enzyme|   FALSE|\n",
      "|   Q9Y6L6|  CHEMBL1014|  116349|  CHEMBL3039490|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|103947|Solute carrier or...|   CHEMBL1697668|Homo sapiens|         400.0|            nM|                =|          6.4|ENSG00000134538|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9Y6L6|[ot_genetics_portal]|             false|              false| Transporter|    TRUE|\n",
      "|   Q9NPC1|  CHEMBL1016|  116848|  CHEMBL4839253|     1|    LITERATURE|   ACS Med Chem Lett|3.4413955E7|10.1021/acsmedche...| 10868|Leukotriene B4 re...|      CHEMBL3191|Homo sapiens|       15000.0|            nM|                =|         4.82|ENSG00000213906|false|{[ENSG00000144891...|  CHEMBL1016|  CHEMBL1016|   Q9NPC1|              [impc]|             false|              false|        GPCR|   FALSE|\n",
      "|   P21452| CHEMBL10188|    6760|   CHEMBL818108|     1|    LITERATURE|          J Med Chem|1.1356103E7|   10.1021/jm000501v| 10184|Neurokinin 2 rece...|      CHEMBL2327|Homo sapiens|         144.0|            nM|                =|         6.84|ENSG00000075073|false|{[ENSG00000169836...| CHEMBL10188| CHEMBL10188|   P21452|            [chembl]|             false|               true|        GPCR|    TRUE|\n",
      "|   P09619|CHEMBL101253|  165012|  CHEMBL1051304|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|   197|Platelet-derived ...|      CHEMBL1913|Homo sapiens|          25.0|            nM|                =|          7.6|ENSG00000113721| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P09619|[uniprot_literatu...|             false|               true|      Kinase|   FALSE|\n",
      "|   P16234|CHEMBL101253|  165012|  CHEMBL1062783|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12627|Platelet-derived ...|      CHEMBL2007|Homo sapiens|          96.0|            nM|                =|         7.02|ENSG00000134853| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P16234|[uniprot_literatu...|             false|               true|      Kinase|   FALSE|\n",
      "|   Q92731|CHEMBL101382|  164146|   CHEMBL832383|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         289.0|            nM|                =|         6.54|ENSG00000140009|false|                NULL|CHEMBL101382|        NULL|     NULL|                NULL|              NULL|               NULL|          NR|    TRUE|\n",
      "|   Q92731|CHEMBL100231|  164265|   CHEMBL678131|     1|    LITERATURE|          J Med Chem|1.2825935E7|   10.1021/jm030086h|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|        3687.0|            nM|                =|         5.43|ENSG00000140009|false|                NULL|CHEMBL100231|        NULL|     NULL|                NULL|              NULL|               NULL|          NR|   FALSE|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29708"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column about activity using cutoff\n",
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "protein_class_in = \"./data/forPolina_uniprot2family.csv\"\n",
    "\n",
    "protein_class = spark.read.csv(protein_class_in, header=True, inferSchema=True)\n",
    "\n",
    "biodata_all_join_class = biodata_all_join.join(protein_class, \n",
    "                            (biodata_all_join.accession == protein_class.accession), \n",
    "                            how=\"left\").drop(protein_class.accession)\n",
    "\n",
    "# Custom cutoff\n",
    "biodata_all_join_class_active = biodata_all_join_class.withColumn(\n",
    "    \"isActive\",\n",
    "    when(\n",
    "        ((col(\"proteinClass\") == \"Kinase\") & (col(\"pchembl_value\") >= 7.7)) |\n",
    "        ((col(\"proteinClass\") == \"GPCR\") & (col(\"pchembl_value\") >= 6.5)) |\n",
    "        ((col(\"proteinClass\") == \"NR\") & (col(\"pchembl_value\") >= 6.1)) |\n",
    "        ((col(\"proteinClass\") == \"Transporter\") & (col(\"pchembl_value\") >= 6.1)) |\n",
    "        ((col(\"proteinClass\") == \"Enzyme\") & (col(\"pchembl_value\") >= 5.2)) |\n",
    "        ((col(\"proteinClass\") == \"IC\") & (col(\"pchembl_value\") >= 4.6)) |\n",
    "        ((col(\"proteinClass\") == \"Other\") & (col(\"pchembl_value\") >= 6.3)) |\n",
    "        (~(col(\"proteinClass\").isin([\"Kinase\", \"GPCR\", \"NR\", \"Transporter\", \"Enzyme\", \"IC\", \"Other\"])) & (col(\"pchembl_value\") >= 5)),\n",
    "        \"TRUE\"\n",
    "    ).otherwise(\"FALSE\")\n",
    ")\n",
    "biodata_all_join_class_active.show()\n",
    "biodata_all_join_class_active.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+-------------+-------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|accession|    chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|       linkedTargets|           id|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|proteinClass|isActive|\n",
      "+---------+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+-------------+-------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|   P35462|   CHEMBL1006|  112480|  CHEMBL1909141|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   130|Dopamine D3 receptor|       CHEMBL234|Homo sapiens|         655.0|            nM|                =|         6.18|ENSG00000151577|false|                NULL|   CHEMBL1006|   CHEMBL1006|   P35462|[impc, ot_genetic...|             false|               true|        GPCR|   false|\n",
      "|   P30968|   CHEMBL1007|  112560|   CHEMBL709251|     1|    LITERATURE|          J Med Chem|  9784092.0|   10.1021/jm9803673|   118|Gonadotropin-rele...|      CHEMBL1855|Homo sapiens|          10.0|            nM|                =|          8.0|ENSG00000109163| true|{[ENSG00000109163...|   CHEMBL1007|   CHEMBL1007|   P30968|[impc, eva, orpha...|             false|               true|        GPCR|    true|\n",
      "|   P10721| CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|{[ENSG00000157404...| CHEMBL101253| CHEMBL101253|   P10721|[uniprot_literatu...|             false|               true|      Kinase|    true|\n",
      "|   P42685| CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|{[ENSG00000157404...| CHEMBL101253| CHEMBL101253|   P42685|[ot_genetics_port...|             false|               true|      Kinase|   false|\n",
      "|   P49336| CHEMBL101253|  165012|  CHEMBL1908526|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101300|Cell division pro...|      CHEMBL5719|Homo sapiens|        4500.0|            nM|                =|         5.35|ENSG00000132964|false|{[ENSG00000157404...| CHEMBL101253| CHEMBL101253|   P49336|[ot_genetics_port...|             false|               true|      Kinase|   false|\n",
      "|   P37231|   CHEMBL1014|  116349|  CHEMBL4768835|     1|    LITERATURE|      Eur J Med Chem| 3.227242E7|10.1016/j.ejmech....|   133|Peroxisome prolif...|       CHEMBL235|Homo sapiens|        4200.0|            nM|                =|         5.38|ENSG00000132170|false|{[ENSG00000144891...|   CHEMBL1014|   CHEMBL1014|   P37231|[impc, eva, ot_ge...|             false|               true|          NR|   false|\n",
      "|   Q9NPC1|   CHEMBL1016|  116848|  CHEMBL4839253|     1|    LITERATURE|   ACS Med Chem Lett|3.4413955E7|10.1021/acsmedche...| 10868|Leukotriene B4 re...|      CHEMBL3191|Homo sapiens|       15000.0|            nM|                =|         4.82|ENSG00000213906|false|{[ENSG00000144891...|   CHEMBL1016|   CHEMBL1016|   Q9NPC1|              [impc]|             false|              false|        GPCR|   false|\n",
      "|   Q9NPD5|   CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|{[ENSG00000144891...|   CHEMBL1017|   CHEMBL1017|   Q9NPD5|              [impc]|             false|              false| Transporter|   false|\n",
      "|   Q9HCG7|   CHEMBL1029|  122901|  CHEMBL4395493|     1|    LITERATURE|      Eur J Med Chem|3.1075609E7|10.1016/j.ejmech....| 11815|    Beta-glucosidase|      CHEMBL3761|Homo sapiens|          14.0|            nM|                =|         7.85|ENSG00000070610|false|{[ENSG00000148154...|   CHEMBL1029|   CHEMBL1029|   Q9HCG7|[uniprot_literatu...|             false|              false|      Enzyme|    true|\n",
      "|   Q9UBE8| CHEMBL103667|  167995|  CHEMBL1063809|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|100931|Serine/threonine ...|      CHEMBL5364|Homo sapiens|        1000.0|            nM|                =|          6.0|ENSG00000087095|false|{[ENSG00000112062...| CHEMBL103667| CHEMBL103667|   Q9UBE8|[ot_genetics_portal]|             false|              false|      Kinase|   false|\n",
      "|   P61604|   CHEMBL1042|  125294|  CHEMBL4392933|     1|    LITERATURE|Bioorg Med Chem Lett|3.0852084E7|10.1016/j.bmcl.20...|117701|         HSP60/HSP10|   CHEMBL4106131|Homo sapiens|       11000.0|            nM|                =|         4.96|ENSG00000115541|false|{[ENSG00000111424...|   CHEMBL1042|   CHEMBL1042|   P61604|[ot_genetics_portal]|             false|              false|        None|   false|\n",
      "|   P35218|   CHEMBL1055|  134333|  CHEMBL1029733|     1|    LITERATURE|     Bioorg Med Chem|1.9119014E7|10.1016/j.bmc.200...| 11042|Carbonic anhydras...|      CHEMBL4789|Homo sapiens|         917.0|            nM|                =|         6.04|ENSG00000174990|false|{[ENSG00000070915...|   CHEMBL1055|   CHEMBL1055|   P35218|[ot_genetics_portal]|             false|              false|      Enzyme|    true|\n",
      "|   P04035|   CHEMBL1064|  138562|  CHEMBL4037104|     1|    LITERATURE|          J Med Chem|2.8850227E7|10.1021/acs.jmedc...|    24|   HMG-CoA reductase|       CHEMBL402|Homo sapiens|           0.9|            nM|                =|         9.05|ENSG00000113161| true|{[ENSG00000113161...|   CHEMBL1064|   CHEMBL1064|   P04035|[impc, ot_genetic...|             false|               true|      Enzyme|    true|\n",
      "|   P10632|   CHEMBL1064|  138562|  CHEMBL3530853|     1|    LITERATURE|   Drug Metab Dispos|2.2328583E7|10.1124/dmd.111.0...| 10163| Cytochrome P450 2C8|      CHEMBL3721|Homo sapiens|        3700.0|            nM|                =|         5.43|ENSG00000138115|false|{[ENSG00000113161...|   CHEMBL1064|   CHEMBL1064|   P10632|[cancer_gene_census]|             false|              false|        None|    true|\n",
      "|   P52333|CHEMBL1079593|  611731|  CHEMBL4416473|     1|    LITERATURE|          J Med Chem|3.1609613E7|10.1021/acs.jmedc...| 10849|Tyrosine-protein ...|      CHEMBL2148|Homo sapiens|           1.7|            nM|                =|         8.77|ENSG00000105639|false|{[ENSG00000145675...|CHEMBL1079593|CHEMBL1079593|   P52333|[impc, intogen, c...|             false|               true|      Kinase|    true|\n",
      "|   P07288|CHEMBL1082407|  630886|  CHEMBL4685677|     1|    LITERATURE|      Eur J Med Chem| 3.211436E7|10.1016/j.ejmech....| 10373|Prostate specific...|      CHEMBL2099|Homo sapiens|         130.0|            nM|                =|         6.89|ENSG00000142515|false|{[ENSG00000169083...|CHEMBL1082407|CHEMBL1082407|   P07288|[ot_genetics_portal]|             false|              false|      Enzyme|    true|\n",
      "|   P27487|   CHEMBL1090|  149095|  CHEMBL1045391|     1|    LITERATURE|          J Med Chem|2.0000418E7|   10.1021/jm901590f| 11140|Dipeptidyl peptid...|       CHEMBL284|Homo sapiens|          62.0|            nM|                =|         7.21|ENSG00000197635|false|             {[], 0}|   CHEMBL1090|   CHEMBL1090|   P27487|      [impc, chembl]|             false|               true|      Enzyme|    true|\n",
      "|   P11362|CHEMBL1090479|  622556|  CHEMBL1104803|     1|    LITERATURE|          J Med Chem|2.0420387E7|   10.1021/jm901870q| 10266|Fibroblast growth...|      CHEMBL3650|Homo sapiens|          76.0|            nM|                =|         7.12|ENSG00000077782|false|{[ENSG00000105146...|CHEMBL1090479|CHEMBL1090479|   P11362|[impc, eva, intog...|             false|               true|      Kinase|   false|\n",
      "|   P07900| CHEMBL109480|  183934|  CHEMBL1100282|     1|    LITERATURE|          J Med Chem|2.0055425E7|   10.1021/jm9004708| 11213|Heat shock protei...|      CHEMBL3880|Homo sapiens|           4.6|            nM|                =|         8.34|ENSG00000080824| true|{[ENSG00000080824...| CHEMBL109480| CHEMBL109480|   P07900|[impc, intogen, c...|             false|               true|        None|    true|\n",
      "|   O15244|     CHEMBL11|     605|  CHEMBL2154120|     1|    LITERATURE|          J Med Chem|2.1599003E7|   10.1021/jm2001629|104063|Solute carrier fa...|   CHEMBL1743122|Homo sapiens|         600.0|            nM|                =|         6.22|ENSG00000112499|false|{[ENSG00000103546...|     CHEMBL11|     CHEMBL11|   O15244|[ot_genetics_portal]|             false|              false| Transporter|    true|\n",
      "+---------+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+-------------+-------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 804:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29708 17487 9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# for OR calculation\n",
    "from pyspark.sql import functions as F\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "# Convert columns to boolean\n",
    "biodata_all = biodata_all_join_class_active.withColumn(\"isMoA\", biodata_all_join_class_active[\"isMoA\"].cast(\"boolean\"))\n",
    "biodata_all = biodata_all_join_class_active.withColumn(\"isActive\", biodata_all_join_class_active[\"isActive\"].cast(\"boolean\"))\n",
    "\n",
    "# Define a UDF to check if the sources list matches the undesired values\n",
    "def filter_sources(sources):\n",
    "    # Define the undesired lists\n",
    "    undesired_lists = [\n",
    "        ['chembl'],\n",
    "        ['chemicalProbes'],\n",
    "        ['chembl', 'chemicalProbes'],\n",
    "        ['chemicalProbes', 'chembl']\n",
    "    ]\n",
    "    \n",
    "    # Check if sources is one of the undesired lists\n",
    "    return sources not in undesired_lists\n",
    "\n",
    "# Register the UDF for Spark\n",
    "filter_sources_udf = F.udf(filter_sources, BooleanType())\n",
    "\n",
    "# First, filter out the NULL sources\n",
    "biodata_GE_plus = biodata_all.filter(F.col(\"sources\").isNotNull())\n",
    "\n",
    "# Now, filter out the undesired sources using the UDF\n",
    "biodata_GE = biodata_GE_plus.filter(filter_sources_udf(F.col(\"sources\")))\n",
    "\n",
    "\n",
    "biodata_GE.show()\n",
    "a = biodata_all.count()\n",
    "b = biodata_GE_plus.count()\n",
    "c = biodata_GE.count()\n",
    "\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 410:========>        (4 + 4) / 8][Stage 412:>                (0 + 4) / 4]\r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/polina/Documents/Bioactivity/bioactivity/data/analysis/biodata_all_v2 already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y224sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m biodata_all\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mparquet(\u001b[39m\"\u001b[39;49m\u001b[39mdata/analysis/biodata_all_v2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1720\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(compression\u001b[39m=\u001b[39mcompression)\n\u001b[0;32m-> 1721\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mparquet(path)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/Users/polina/Documents/Bioactivity/bioactivity/data/analysis/biodata_all_v2 already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "biodata_all.write.parquet(\"data/analysis/biodata_all_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 14:13:54 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/10/30 14:14:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_GE_plus.write.parquet(\"data/analysis/biodata_GE_plus_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biodata_GE.write.parquet(\"data/analysis/biodata_GE_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "biodata_GE_df = biodata_GE.withColumn(\"sources\", col(\"sources\").cast(\"string\"))\n",
    "biodata_GE_df_2 = biodata_GE_df.withColumn(\"linkedTargets\", col(\"linkedTargets\").cast(\"string\"))\n",
    "biodata_GE_df_2.repartition(1).write.mode(\"overwrite\").csv(\"data/biodata_GE_v3_csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR calculation for GE+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from scipy.stats import fisher_exact\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 14:27:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"drug-to_target_biodata_analysis\") \\\n",
    "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "biodata_all = spark.read.parquet(\"data/analysis/biodata_all_v2\")\n",
    "biodata_GE = spark.read.parquet(\"data/analysis/biodata_GE_v2\")\n",
    "biodata_GE_plus = spark.read.parquet(\"data/analysis/biodata_GE_plus_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|isActive|isMoA|count|\n",
      "+--------+-----+-----+\n",
      "|   false|false|14123|\n",
      "|   false| true|  426|\n",
      "|    true|false|12439|\n",
      "|    true| true| 2720|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create contingency table for biodata_all\n",
    "contingency_table_all = (\n",
    "    biodata_all\n",
    "    .groupBy(\"isActive\", \"isMoA\")\n",
    "    .agg(F.count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"isActive\", \"isMoA\")\n",
    ")\n",
    "\n",
    "contingency_table_all.show()\n",
    "contingency_table_all_list = contingency_table_all.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|isActive|isMoA|count|\n",
      "+--------+-----+-----+\n",
      "|   false|false| 6714|\n",
      "|   false| true|  425|\n",
      "|    true|false| 7630|\n",
      "|    true| true| 2718|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create contingency table for biodata_GE_plus\n",
    "contingency_table_GE_plus = (\n",
    "    biodata_GE_plus\n",
    "    .groupBy(\"isActive\", \"isMoA\")\n",
    "    .agg(F.count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"isActive\", \"isMoA\")\n",
    ")\n",
    "\n",
    "contingency_table_GE_plus.show()\n",
    "contingency_table_GE_plus_list = contingency_table_GE_plus.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|isActive|isMoA|count|\n",
      "+--------+-----+-----+\n",
      "|   false|false| 4667|\n",
      "|   false| true|  286|\n",
      "|    true|false| 2493|\n",
      "|    true| true| 1696|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create contingency table for biodata_GE\n",
    "contingency_table_GE = (\n",
    "    biodata_GE\n",
    "    .groupBy(\"isActive\", \"isMoA\")\n",
    "    .agg(F.count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"isActive\", \"isMoA\")\n",
    ")\n",
    "contingency_table_GE.show()\n",
    "contingency_table_GE_list = contingency_table_GE.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds Ratio for all biodata: 7.249378846706199\n",
      "95% CI: (6.527227620105087, 8.051426535394084)\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Extract counts for Fisher's test\n",
    "a = contingency_table_all_list[0]['count']  # isActive = False, isMoA = False\n",
    "b = contingency_table_all_list[1]['count']  # isActive = False, isMoA = True\n",
    "c = contingency_table_all_list[2]['count']  # isActive = True, isMoA = False\n",
    "d = contingency_table_all_list[3]['count']  # isActive = True, isMoA = True\n",
    "\n",
    "# Fisher's Exact Test\n",
    "_, p_value_all = fisher_exact([[a, b], [c, d]])\n",
    "\n",
    "# 3. Compute Odds Ratio and its Confidence Interval\n",
    "or_ratio_all = (a * d) / (b * c)\n",
    "or_lower_all = np.exp(np.log(or_ratio_all) - 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "or_upper_all = np.exp(np.log(or_ratio_all) + 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "print(f\"Odds Ratio for all biodata: {or_ratio_all}\")\n",
    "print(f\"95% CI: ({or_lower_all}, {or_upper_all})\")\n",
    "print(f\"P-value: {p_value_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds Ratio for biodata with GE: 11.101338292674033\n",
      "95% CI: (9.705309587428294, 12.698174208479498)\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Extract counts for Fisher's test\n",
    "a = contingency_table_GE_list[0]['count']  # isActive = False, isMoA = False\n",
    "b = contingency_table_GE_list[1]['count']  # isActive = False, isMoA = True\n",
    "c = contingency_table_GE_list[2]['count']  # isActive = True, isMoA = False\n",
    "d = contingency_table_GE_list[3]['count']  # isActive = True, isMoA = True\n",
    "\n",
    "# Fisher's Exact Test\n",
    "_, p_value_GE = fisher_exact([[a, b], [c, d]])\n",
    "\n",
    "# 3. Compute Odds Ratio and its Confidence Interval\n",
    "or_ratio_GE = (a * d) / (b * c)\n",
    "or_lower_GE = np.exp(np.log(or_ratio_GE) - 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "or_upper_GE = np.exp(np.log(or_ratio_GE) + 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "print(f\"Odds Ratio for biodata with GE: {or_ratio_GE}\")\n",
    "print(f\"95% CI: ({or_lower_GE}, {or_upper_GE})\")\n",
    "print(f\"P-value: {p_value_GE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds Ratio for biodata with GE+: 5.627523552540282\n",
      "95% CI: (5.054608594928669, 6.265375595287316)\n",
      "P-value: 1.8826845974391295e-291\n"
     ]
    }
   ],
   "source": [
    "# Extract counts for Fisher's test\n",
    "a = contingency_table_GE_plus_list[0]['count']  # isActive = False, isMoA = False\n",
    "b = contingency_table_GE_plus_list[1]['count']  # isActive = False, isMoA = True\n",
    "c = contingency_table_GE_plus_list[2]['count']  # isActive = True, isMoA = False\n",
    "d = contingency_table_GE_plus_list[3]['count']  # isActive = True, isMoA = True\n",
    "\n",
    "# Fisher's Exact Test\n",
    "_, p_value_GE_plus = fisher_exact([[a, b], [c, d]])\n",
    "\n",
    "# 3. Compute Odds Ratio and its Confidence Interval\n",
    "or_ratio_GE_plus = (a * d) / (b * c)\n",
    "or_lower_GE_plus = np.exp(np.log(or_ratio_GE_plus) - 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "or_upper_GE_plus = np.exp(np.log(or_ratio_GE_plus) + 1.96*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "print(f\"Odds Ratio for biodata with GE+: {or_ratio_GE_plus}\")\n",
    "print(f\"95% CI: ({or_lower_GE_plus}, {or_upper_GE_plus})\")\n",
    "print(f\"P-value: {p_value_GE_plus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    isActive  isMoA  count    Table\n",
      "0      False  False   6714  GE_plus\n",
      "1      False   True    425  GE_plus\n",
      "2       True  False   7630  GE_plus\n",
      "3       True   True   2718  GE_plus\n",
      "4      False  False   4667       GE\n",
      "5      False   True    286       GE\n",
      "6       True  False   2493       GE\n",
      "7       True   True   1696       GE\n",
      "8      False  False  14123      all\n",
      "9      False   True    426      all\n",
      "10      True  False  12439      all\n",
      "11      True   True   2720      all\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Spark DataFrame to pandas DataFrame\n",
    "df_GE_plus = contingency_table_GE_plus.toPandas()\n",
    "df_GE = contingency_table_GE.toPandas()\n",
    "df_all = contingency_table_all.toPandas()\n",
    "\n",
    "# Add an identifier column\n",
    "df_GE_plus['Table'] = 'GE_plus'\n",
    "df_GE['Table'] = 'GE'\n",
    "df_all['Table'] = 'all'\n",
    "\n",
    "# Concatenate all DataFrames vertically\n",
    "all_dfs = [df_GE_plus, df_GE, df_all]\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(combined_df)\n",
    "\n",
    "combined_df.to_csv(\"data/analysis/contin_tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def forest_plot(ORs, CIs, p_values, labels):\n",
    "    \"\"\"\n",
    "    Display a forest plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - ORs: List of odds ratios\n",
    "    - CIs: List of confidence intervals (as tuples of (lower, upper))\n",
    "    - p_values: List of p-values\n",
    "    - labels: List of names for each OR/CI/p-value\n",
    "    \"\"\"\n",
    "    y_pos = range(len(ORs), 0, -1)  # Position on the y axis\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.axvline(1, color='grey', linestyle='--')  # Line at OR=1\n",
    "\n",
    "    for i, (or_val, (l, u), p_val) in enumerate(zip(ORs, CIs, p_values)):\n",
    "        plt.plot([l, u], [y_pos[i]]*2, '-', color='black', linewidth=2)\n",
    "        plt.plot(l, y_pos[i], marker='|', color='black', markersize=15, mew=2)\n",
    "        plt.plot(u, y_pos[i], marker='|', color='black', markersize=15, mew=2)\n",
    "        \n",
    "# Display p-values\n",
    "        if p_val < 0.001:\n",
    "            plt.text(u + 0.3, y_pos[i], \"p < 0.001\", va='center', ha='left', fontsize=10)\n",
    "        else:\n",
    "            exponent = np.ceil(-np.log10(p_val)).astype(int)\n",
    "            plt.text(u + 0.1, y_pos[i], f\"p = $10^{{-{exponent}}}$\", va='center', ha='left', fontsize=10)\n",
    "        \n",
    "        \n",
    "        # Display OR and CI values above the intervals\n",
    "        plt.text(or_val, y_pos[i] + 0.2, f\"OR={or_val:.1f} ({l:.1f}, {u:.1f})\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.yticks(y_pos, labels, fontsize=12)\n",
    "    plt.xticks(range(2,16,4), range(2,16,4), fontsize=10)\n",
    "    plt.xlim(2,16)\n",
    "    plt.xlabel('Odds Ratio and 95% CI', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    # plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.ylim(0.5, len(ORs) + 0.5)\n",
    "    plt.savefig(\"data/analysis/ORs_v1\", dpi = 500)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample data\n",
    "ORs = [or_ratio_all, or_ratio_GE_plus, or_ratio_GE]\n",
    "CIs = [(or_lower_all, or_upper_all), (or_lower_GE_plus, or_upper_GE_plus), (or_lower_GE, or_upper_GE)]\n",
    "p_values = [p_value_all, p_value_GE_plus, p_value_GE]\n",
    "labels = ['All biodata', 'GE+', 'GE only']\n",
    "\n",
    "forest_plot(ORs, CIs, p_values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR calculation for GE only (without probes and chembl evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "                    isActive=True  isActive=False\n",
      "isTherapeuticTarget=True   3359             2957\n",
      "isTherapeuticTarget=False  824             1996\n",
      "\n",
      "The drug has significantly greater odds of being more active for therapeutic target (OR=2.752, 95% CI=(2.502, 3.026), p=7.161e-100).\n",
      "80% of active drugs modulate therapeutic targets\n",
      "60% of non-active drugs modulate therapeutic targets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create 2x2 contingency table\n",
    "table = (\n",
    "    filtered_df.groupBy(\"isTherapeuticTarget\")\n",
    "    .pivot(\"isActive\")\n",
    "    .count()\n",
    "    .fillna(0)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "a = table[0][2]  # isTherapeuticTarget=True, isActive=True\n",
    "b = table[0][1]  # isTherapeuticTarget=True, isActive=False\n",
    "c = table[1][2]  # isTherapeuticTarget=False, isActive=True\n",
    "d = table[1][1]  # isTherapeuticTarget=False, isActive=False\n",
    "\n",
    "AA_rate = round(a/(a+c)*100)\n",
    "II_rate = round(b/(d+b)*100)\n",
    "\n",
    "# Print Contingency Table\n",
    "print(\"Contingency Table:\")\n",
    "print(\"                    isActive=True  isActive=False\")\n",
    "print(f\"isTherapeuticTarget=True   {a}             {b}\")\n",
    "print(f\"isTherapeuticTarget=False  {c}             {d}\")\n",
    "print(\"\")\n",
    "\n",
    "# Calculate Odds Ratio\n",
    "OR = (a * d) / (b * c) if b*c != 0 else np.inf  # To avoid division by zero\n",
    "\n",
    "# Calculate 95% CI for OR\n",
    "lower_limit = OR * np.exp(-1.96 * np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "upper_limit = OR * np.exp(1.96 * np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "# Calculate p-value using chi-squared test\n",
    "_, p, _, _ = chi2_contingency([[a, b], [c, d]])\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    if OR > 1:\n",
    "        print(f\"The drug has significantly greater odds of being more active for therapeutic target (OR={OR:.3f}, 95% CI=({lower_limit:.3f}, {upper_limit:.3f}), p={p:.3e}).\")\n",
    "    else:\n",
    "        print(f\"The drug has significantly lower odds of being more active for therapeutic target (OR={OR:.3f}, 95% CI=({lower_limit:.3f}, {upper_limit:.3f}), p={p:.3e}).\")\n",
    "else:\n",
    "    print(f\"No significant association between drug's activity and  therapeutic target modulation (OR={OR:.3f}, 95% CI=({lower_limit:.3f}, {upper_limit:.3f}), p={p:.3e}).\")\n",
    "\n",
    "print(str(AA_rate) + \"% of active drugs modulate therapeutic targets\")\n",
    "print(str(II_rate) + \"% of non-active drugs modulate therapeutic targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 852:>                                                        (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|accession|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       targetID|isMoA|       linkedTargets|          id|      drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|proteinClass|isActive|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "|   P30968|  CHEMBL1007|  112560|   CHEMBL709251|     1|    LITERATURE|          J Med Chem|  9784092.0|   10.1021/jm9803673|   118|Gonadotropin-rele...|      CHEMBL1855|Homo sapiens|          10.0|            nM|                =|          8.0|ENSG00000109163| true|{[ENSG00000109163...|  CHEMBL1007|  CHEMBL1007|   P30968|[impc, eva, orpha...|             false|               true|        GPCR|    true|\n",
      "|   P10721|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|ENSG00000157404| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P10721|[uniprot_literatu...|             false|               true|      Kinase|    true|\n",
      "|   P42685|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|ENSG00000111816|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P42685|[ot_genetics_port...|             false|               true|      Kinase|   false|\n",
      "|   P37231|  CHEMBL1014|  116349|  CHEMBL4768835|     1|    LITERATURE|      Eur J Med Chem| 3.227242E7|10.1016/j.ejmech....|   133|Peroxisome prolif...|       CHEMBL235|Homo sapiens|        4200.0|            nM|                =|         5.38|ENSG00000132170|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   P37231|[impc, eva, ot_ge...|             false|               true|          NR|   false|\n",
      "|   Q9NPD5|  CHEMBL1017|  116949|  CHEMBL3039493|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|104062|Solute carrier or...|   CHEMBL1743121|Homo sapiens|         960.0|            nM|                =|         6.02|ENSG00000111700|false|{[ENSG00000144891...|  CHEMBL1017|  CHEMBL1017|   Q9NPD5|              [impc]|             false|              false| Transporter|   false|\n",
      "|   P05177| CHEMBL10188|    6760|  CHEMBL1763137|     1|    LITERATURE|Bioorg Med Chem Lett|2.1376585E7|10.1016/j.bmcl.20...| 12594| Cytochrome P450 1A2|      CHEMBL3356|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000140505|false|{[ENSG00000169836...| CHEMBL10188|        NULL|     NULL|                NULL|              NULL|               NULL|        None|    true|\n",
      "|   P48443|  CHEMBL1023|  119498|   CHEMBL800755|     1|    LITERATURE|          J Med Chem|  9435893.0|   10.1021/jm9704309|   266|Retinoid X recept...|      CHEMBL2004|Homo sapiens|           8.3|            nM|                =|         8.08|ENSG00000143171| true|{[ENSG00000204231...|  CHEMBL1023|  CHEMBL1023|   P48443|            [chembl]|             false|               true|          NR|    true|\n",
      "|   P35367|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|ENSG00000196639| true|{[ENSG00000196639...|  CHEMBL1000|  CHEMBL1000|   P35367|            [chembl]|             false|               true|        GPCR|    true|\n",
      "|   P03372|CHEMBL100231|  164265|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|Estrogen receptor...|       CHEMBL206|Homo sapiens|           5.2|            nM|                =|         8.28|ENSG00000091831|false|                NULL|CHEMBL100231|CHEMBL100231|   P03372|    [chemicalProbes]|             false|              false|          NR|    true|\n",
      "|   P35498|  CHEMBL1008|  112651|   CHEMBL806152|     1|    LITERATURE|          J Med Chem|  2579237.0| 10.1021/jm00381a019|104837|Sodium channel al...|   CHEMBL2096682|Homo sapiens|         840.0|            nM|                =|         6.08|ENSG00000144285|false|{[ENSG00000196557...|  CHEMBL1008|  CHEMBL1008|   P35498|[uniprot_literatu...|             false|               true|          IC|    true|\n",
      "|   P49336|CHEMBL101253|  165012|  CHEMBL1908526|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101300|Cell division pro...|      CHEMBL5719|Homo sapiens|        4500.0|            nM|                =|         5.35|ENSG00000132964|false|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P49336|[ot_genetics_port...|             false|               true|      Kinase|   false|\n",
      "|   Q9UNQ0|  CHEMBL1014|  116349|  CHEMBL5128685|     1|    LITERATURE|      Eur J Med Chem|3.5483322E7|10.1016/j.ejmech....|100974|ATP-binding casse...|      CHEMBL5393|Homo sapiens|        5000.0|            nM|                =|          5.3|ENSG00000118777|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9UNQ0|[impc, ot_genetic...|             false|              false| Transporter|   false|\n",
      "|   Q9Y253|  CHEMBL1014|  116349|  CHEMBL3854643|     1|    LITERATURE|          J Med Chem|2.7362876E7|10.1021/acs.jmedc...|101013|  DNA polymerase eta|      CHEMBL5542|Homo sapiens|       11200.0|            nM|                =|         4.95|ENSG00000170734|false|{[ENSG00000144891...|  CHEMBL1014|        NULL|     NULL|                NULL|              NULL|               NULL|      Enzyme|   false|\n",
      "|   Q9Y6L6|  CHEMBL1014|  116349|  CHEMBL3039490|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|103947|Solute carrier or...|   CHEMBL1697668|Homo sapiens|         400.0|            nM|                =|          6.4|ENSG00000134538|false|{[ENSG00000144891...|  CHEMBL1014|  CHEMBL1014|   Q9Y6L6|[ot_genetics_portal]|             false|              false| Transporter|    true|\n",
      "|   Q9NPC1|  CHEMBL1016|  116848|  CHEMBL4839253|     1|    LITERATURE|   ACS Med Chem Lett|3.4413955E7|10.1021/acsmedche...| 10868|Leukotriene B4 re...|      CHEMBL3191|Homo sapiens|       15000.0|            nM|                =|         4.82|ENSG00000213906|false|{[ENSG00000144891...|  CHEMBL1016|  CHEMBL1016|   Q9NPC1|              [impc]|             false|              false|        GPCR|   false|\n",
      "|   P21452| CHEMBL10188|    6760|   CHEMBL818108|     1|    LITERATURE|          J Med Chem|1.1356103E7|   10.1021/jm000501v| 10184|Neurokinin 2 rece...|      CHEMBL2327|Homo sapiens|         144.0|            nM|                =|         6.84|ENSG00000075073|false|{[ENSG00000169836...| CHEMBL10188| CHEMBL10188|   P21452|            [chembl]|             false|               true|        GPCR|    true|\n",
      "|   P09619|CHEMBL101253|  165012|  CHEMBL1051304|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|   197|Platelet-derived ...|      CHEMBL1913|Homo sapiens|          25.0|            nM|                =|          7.6|ENSG00000113721| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P09619|[uniprot_literatu...|             false|               true|      Kinase|   false|\n",
      "|   P16234|CHEMBL101253|  165012|  CHEMBL1062783|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12627|Platelet-derived ...|      CHEMBL2007|Homo sapiens|          96.0|            nM|                =|         7.02|ENSG00000134853| true|{[ENSG00000157404...|CHEMBL101253|CHEMBL101253|   P16234|[uniprot_literatu...|             false|               true|      Kinase|   false|\n",
      "|   Q92731|CHEMBL101382|  164146|   CHEMBL832383|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|         289.0|            nM|                =|         6.54|ENSG00000140009|false|                NULL|CHEMBL101382|        NULL|     NULL|                NULL|              NULL|               NULL|          NR|    true|\n",
      "|   Q92731|CHEMBL100231|  164265|   CHEMBL678131|     1|    LITERATURE|          J Med Chem|1.2825935E7|   10.1021/jm030086h|   174|Estrogen receptor...|       CHEMBL242|Homo sapiens|        3687.0|            nM|                =|         5.43|ENSG00000140009|false|                NULL|CHEMBL100231|        NULL|     NULL|                NULL|              NULL|               NULL|          NR|   false|\n",
      "+---------+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+---------------+-----+--------------------+------------+------------+---------+--------------------+------------------+-------------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "biodata_GE_df = biodata_GE.withColumn(\"sources\", col(\"sources\").cast(\"string\"))\n",
    "biodata_GE_df_2 = biodata_GE_df.withColumn(\"linkedTargets\", col(\"linkedTargets\").cast(\"string\"))\n",
    "biodata_GE_df_2.repartition(1).write.mode(\"overwrite\").csv(\"data/biodata_GE_v3_csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve, log regression, biodata + GE+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/30 22:10:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"log_reg_biodata\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "biodata_all = spark.read.parquet(\"data/analysis/biodata_all_v2\")\n",
    "\n",
    "# Convert columns to features and label format\n",
    "assembler = VectorAssembler(inputCols=[\"pchembl_value\"], outputCol=\"features\")\n",
    "df_copy = assembler.transform(biodata_all)\n",
    "\n",
    "# Convert boolean to numeric\n",
    "df_copy = df_copy.withColumn(\"label\", df_copy[\"isMoA\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 21:37:05 WARN TaskMemoryManager: Failed to allocate a page (134217728 bytes), try again.\n",
      "23/10/30 21:37:07 WARN TaskMemoryManager: Failed to allocate a page (134217728 bytes), try again.\n",
      "23/10/30 21:37:07 WARN TaskMemoryManager: Failed to allocate a page (134217728 bytes), try again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|features|\n",
      "+--------+\n",
      "|  [8.23]|\n",
      "|  [8.28]|\n",
      "|  [6.18]|\n",
      "|   [8.0]|\n",
      "|  [6.08]|\n",
      "|  [8.29]|\n",
      "|  [5.75]|\n",
      "|  [5.35]|\n",
      "|  [5.38]|\n",
      "|   [5.3]|\n",
      "|  [4.95]|\n",
      "|   [6.4]|\n",
      "|  [5.52]|\n",
      "|  [4.82]|\n",
      "|  [6.02]|\n",
      "|  [7.85]|\n",
      "|   [5.3]|\n",
      "|   [5.4]|\n",
      "|  [8.08]|\n",
      "|  [6.92]|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_copy[[\"features\"]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "train_data, test_data = df_copy.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Define the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7980933257414323\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Compute area under the ROC curve\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "biodata_all = spark.read.parquet(\"data/analysis/biodata_all_v2\")\n",
    "df_copy = biodata_all\n",
    "\n",
    "if 'proteinClassIndex' in df_copy.columns:\n",
    "    df_copy = df_copy.drop('proteinClassIndex')\n",
    "if 'proteinClassVec' in df_copy.columns:\n",
    "    df_copy = df_copy.drop('proteinClassVec')\n",
    "\n",
    "\n",
    "df_copy = df_copy.fillna({\"proteinClass\": \"Unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Indexing\n",
    "indexer = StringIndexer(inputCol=\"proteinClass\", outputCol=\"proteinClassIndex\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(inputCol=\"proteinClassIndex\", outputCol=\"proteinClassVec\")\n",
    "\n",
    "# Vector Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pchembl_value\", \"proteinClassVec\"],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler])\n",
    "\n",
    "# Transform the data\n",
    "df_transformed = pipeline.fit(df_copy).transform(df_copy)\n",
    "\n",
    "# Convert the target column to numeric (if it's boolean)\n",
    "df_transformed = df_transformed.withColumn(\"label\", df_transformed[\"isMoA\"].cast(\"double\"))\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.8124791976405804\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the AUC-ROC\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (protein class)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GE+ as a new feature\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BiodataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "biodata_all = spark.read.parquet(\"data/analysis/biodata_all_v2\")\n",
    "df_copy = biodata_all\n",
    "\n",
    "df_copy = df_copy.fillna({\"proteinClass\": \"Unknown\"})\n",
    "\n",
    "# Marking non-null values in sources as Important\n",
    "df_copy = df_copy.withColumn(\"sources_imp\", when(col(\"sources\").isNotNull(), \"Important\").otherwise(\"Not_Important\"))\n",
    "\n",
    "# Drop existing columns if they exist\n",
    "for col_name in ['proteinClassIndex', 'proteinClassVec', 'sourcesIndex', 'sourcesVec']:\n",
    "    if col_name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(col_name)\n",
    "\n",
    "# String Indexing\n",
    "protein_indexer = StringIndexer(inputCol=\"proteinClass\", outputCol=\"proteinClassIndex\")\n",
    "sources_indexer = StringIndexer(inputCol=\"sources_imp\", outputCol=\"sourcesIndex\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "protein_encoder = OneHotEncoder(inputCol=\"proteinClassIndex\", outputCol=\"proteinClassVec\")\n",
    "sources_encoder = OneHotEncoder(inputCol=\"sourcesIndex\", outputCol=\"sourcesVec\")\n",
    "\n",
    "# Vector Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pchembl_value\", \"proteinClassVec\", \"sourcesVec\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Pipeline Stages\n",
    "pipeline = Pipeline(stages=[protein_indexer, protein_encoder, sources_indexer, sources_encoder, assembler])\n",
    "\n",
    "# Transform the data\n",
    "df_transformed = pipeline.fit(df_copy).transform(df_copy)\n",
    "\n",
    "# Convert the target column to numeric (assuming it's boolean)\n",
    "df_transformed = df_transformed.withColumn(\"label\", df_transformed[\"isMoA\"].cast(\"double\"))\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 22:28:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/10/30 22:28:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.863647169736776\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the AUC-ROC\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (GE+)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make difference between GE and GE+\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# List of undesired patterns\n",
    "undesired_lists = [\n",
    "    ['chembl'],\n",
    "    ['chemicalProbes'],\n",
    "    ['chembl', 'chemicalProbes'],\n",
    "    ['chemicalProbes', 'chembl']\n",
    "]\n",
    "\n",
    "# Convert lists to strings to make it easier to search for them in the 'sources' column\n",
    "undesired_patterns = [\",\".join(lst) for lst in undesired_lists]\n",
    "\n",
    "# Define UDF to process the 'sources' column\n",
    "def process_sources(s):\n",
    "    if s is None:\n",
    "        return \"Not_Important\"\n",
    "    for pattern in undesired_patterns:\n",
    "        if pattern in s:\n",
    "            return \"LessImportant\"\n",
    "    return \"Important\"\n",
    "\n",
    "# Register UDF with Spark\n",
    "sources_udf = udf(process_sources, StringType())\n",
    "\n",
    "# Apply the UDF to the 'sources' column to create 'sources_imp' column\n",
    "df_copy = df_copy.withColumn(\"sources_imp\", sources_udf(df_copy[\"sources\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# String Indexing for 'sources_imp'\n",
    "sources_indexer = StringIndexer(inputCol=\"sources_imp\", outputCol=\"sourcesIndex\", handleInvalid=\"keep\")\n",
    "\n",
    "# One-Hot Encoding for 'sources_imp'\n",
    "sources_encoder = OneHotEncoder(inputCol=\"sourcesIndex\", outputCol=\"sourcesVec\")\n",
    "\n",
    "# Updating the Vector Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pchembl_value\", \"proteinClassVec\", \"sourcesVec\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Setting up the updated pipeline stages\n",
    "pipeline = Pipeline(stages=[protein_indexer, protein_encoder, sources_indexer, sources_encoder, assembler])\n",
    "\n",
    "# Transforming the data\n",
    "df_transformed = pipeline.fit(df_copy).transform(df_copy)\n",
    "\n",
    "# Converting the target column to numeric (assuming it's boolean)\n",
    "df_transformed = df_transformed.withColumn(\"label\", df_transformed[\"isMoA\"].cast(\"double\"))\n",
    "\n",
    "# Splitting the data\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Training the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.8720727908800572\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the AUC-ROC\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (GE)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BooleanType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 66\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y150sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sources \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m undesired_lists\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y150sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Register the UDF for Spark\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y150sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m filter_sources_udf \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mudf(filter_sources, BooleanType())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y150sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Filter the DataFrame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#Y150sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m filtered_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mfilter(filter_sources_udf(df[\u001b[39m'\u001b[39m\u001b[39msources\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BooleanType' is not defined"
     ]
    }
   ],
   "source": [
    "# Same but only for GE\n",
    "# Define a UDF to check if the sources list matches the undesired values\n",
    "def filter_sources(sources):\n",
    "    # Define the undesired lists\n",
    "    undesired_lists = [\n",
    "        ['chembl'],\n",
    "        ['chemicalProbes'],\n",
    "        ['chembl', 'chemicalProbes'],\n",
    "        ['chemicalProbes', 'chembl']\n",
    "    ]\n",
    "    \n",
    "    # Check if sources is one of the undesired lists\n",
    "    return sources not in undesired_lists\n",
    "\n",
    "# Register the UDF for Spark\n",
    "filter_sources_udf = F.udf(filter_sources, BooleanType())\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df.filter(filter_sources_udf(df['sources']))\n",
    "filtered_df.show()\n",
    "filtered_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1941:=====================>                                  (3 + 5) / 8]\r"
     ]
    }
   ],
   "source": [
    "# String Indexing\n",
    "indexer = StringIndexer(inputCol=\"proteinClass\", outputCol=\"proteinClassIndex\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder(inputCol=\"proteinClassIndex\", outputCol=\"proteinClassVec\")\n",
    "\n",
    "# Vector Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pchembl_value\", \"proteinClassVec\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Set up the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler])\n",
    "\n",
    "# Transform the data\n",
    "df_transformed = pipeline.fit(filtered_df).transform(filtered_df)\n",
    "\n",
    "# Convert the target column to numeric (if it's boolean)\n",
    "df_transformed = df_transformed.withColumn(\"label\", df_transformed[\"isTherapeuticTarget\"].cast(\"double\"))\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1985:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7521170247652198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the AUC-ROC\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (only GE)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, if it's better for only GE, let's add source as a feature to previous one\n",
    "# Rows containing only chembl or chemicalProbes or their combination are less valuable.\n",
    "# Rows with more data sources in the list are more valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3581:>                                                       (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.9089027143093105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import udf, size\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convert 'sources' from string to list if it's not already a list\n",
    "if isinstance(df.select(\"sources\").first()[0], str):\n",
    "    from pyspark.sql.functions import split\n",
    "    df = df.withColumn(\"sources\", split(df[\"sources\"], \",\"))\n",
    "\n",
    "# Feature engineering: Create value_score based on sources\n",
    "def compute_value_score(sources_list):\n",
    "    less_valuable_sources = set([\"chemicalProbes\"])\n",
    "    if set(sources_list).issubset(less_valuable_sources):\n",
    "        base_score = 0\n",
    "    else:\n",
    "        base_score = 1\n",
    "    score = base_score * len(sources_list)\n",
    "    return score\n",
    "\n",
    "value_score_udf = udf(compute_value_score, IntegerType())\n",
    "df = df.withColumn(\"value_score\", value_score_udf(df[\"sources\"]))\n",
    "\n",
    "# String Indexing for proteinClass\n",
    "indexer = StringIndexer(inputCol=\"proteinClass\", outputCol=\"proteinClassIndex\")\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "# One-Hot Encoding for proteinClass\n",
    "encoder = OneHotEncoder(inputCol=\"proteinClassIndex\", outputCol=\"proteinClassVec\")\n",
    "encoder_model = encoder.fit(df_indexed)\n",
    "df_encoded = encoder_model.transform(df_indexed)\n",
    "\n",
    "# Vector Assembler to assemble features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pchembl_value\", \"proteinClassVec\", \"value_score\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df_transformed = assembler.transform(df_encoded)\n",
    "\n",
    "# Convert the target column to numeric (if it's boolean)\n",
    "df_transformed = df_transformed.withColumn(\"label\", df_transformed[\"isTherapeuticTarget\"].cast(\"double\"))\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Area under ROC = {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "roc = lr_model.summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'], roc['TPR'], label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (GE+ ranked)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biodata from ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------+---------+--------------------+----------------+------------------+--------------+\n",
      "|   chembl_id|molregno|   tid|accession|           pref_name|target_chembl_id|min_standard_value|standard_units|\n",
      "+------------+--------+------+---------+--------------------+----------------+------------------+--------------+\n",
      "|  CHEMBL1000|  111185|104067|   Q96FL8|Multidrug and tox...|   CHEMBL1743126|               2.0|             %|\n",
      "|  CHEMBL1000|  111185| 17045|   P08684| Cytochrome P450 3A4|       CHEMBL340|              13.0|             %|\n",
      "|  CHEMBL1000|  111185|   165|   Q12809|                HERG|       CHEMBL240|          30199.52|            nM|\n",
      "|  CHEMBL1000|  111185|103947|   Q9Y6L6|Solute carrier or...|   CHEMBL1697668|              35.7|             %|\n",
      "|  CHEMBL1000|  111185|   127|   P35367|Histamine H1 rece...|       CHEMBL231|              5.89|            nM|\n",
      "|  CHEMBL1000|  111185| 12675|   P02763|Alpha-1-acid glyc...|      CHEMBL4285|              5.12|           M/M|\n",
      "|  CHEMBL1000|  111185| 10697|   P02768|       Serum albumin|      CHEMBL3253|              5.42|           M/M|\n",
      "|  CHEMBL1000|  111185| 12913|   Q02763|Tyrosine-protein ...|      CHEMBL4128|           90000.0|            nM|\n",
      "|  CHEMBL1000|  111185|104065|   O94956|Solute carrier or...|   CHEMBL1743124|              29.9|             %|\n",
      "|  CHEMBL1000|  111185|104062|   Q9NPD5|Solute carrier or...|   CHEMBL1743121|              40.3|             %|\n",
      "|  CHEMBL1000|  111185|101283|   O15245|Solute carrier fa...|      CHEMBL5685|              -4.8|             %|\n",
      "|  CHEMBL1002|  111482|    43|   P07550|Beta-2 adrenergic...|       CHEMBL210|              75.0|             %|\n",
      "|  CHEMBL1002|  111482|    43|   P07550|Beta-2 adrenergic...|       CHEMBL210|            144.54|            nM|\n",
      "|CHEMBL100231|  164265|    19|   P03372|Estrogen receptor...|       CHEMBL206|               5.2|            nM|\n",
      "|CHEMBL100231|  164265|   174|   Q92731|Estrogen receptor...|       CHEMBL242|            3687.0|            nM|\n",
      "|CHEMBL100259|  161181|102431|   Q9HA47|Uridine-cytidine ...|      CHEMBL5682|              0.51|            /s|\n",
      "|CHEMBL100259|  161181|102431|   Q9HA47|Uridine-cytidine ...|      CHEMBL5682|            0.0013|         /uM/s|\n",
      "|CHEMBL100259|  161181|101412|   O75762|Transient recepto...|      CHEMBL6007|              11.0|             %|\n",
      "|CHEMBL100259|  161181|102431|   Q9HA47|Uridine-cytidine ...|      CHEMBL5682|          407000.0|            nM|\n",
      "|CHEMBL100259|  161181|101328|   O43868|Sodium/nucleoside...|      CHEMBL5780|           31000.0|            nM|\n",
      "+------------+--------+------+---------+--------------------+----------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of rows: 64695\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m biodata\u001b[39m.\u001b[39mshow()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of rows:\u001b[39m\u001b[39m\"\u001b[39m, num_rows_biodata)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m biodata_uni \u001b[39m=\u001b[39m (biodata\u001b[39m.\u001b[39mgroupBy(\u001b[39m\"\u001b[39m\u001b[39mchembl_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maccession\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m           \u001b[39m.\u001b[39magg(F\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mcount_of_combinations\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m num_uni_rows_biodata \u001b[39m=\u001b[39m biodata_uni\u001b[39m.\u001b[39mcount()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of unique drug-target pairs:\u001b[39m\u001b[39m\"\u001b[39m, num_uni_rows_biodata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# Testset with only min_standard_value\n",
    "biodata_in = \"./data/drug2target_bioactivities_chembl_33_grouped.csv\"\n",
    "\n",
    "biodata = spark.read.csv(biodata_in, header=True, inferSchema=True)\n",
    "biodata = biodata.drop('_c0')\n",
    "num_rows_biodata = biodata.count()\n",
    "biodata.show()\n",
    "print(\"Number of rows:\", num_rows_biodata)\n",
    "\n",
    "biodata_uni = (biodata.groupBy(\"chembl_id\", \"accession\")\n",
    "          .agg(F.count(\"*\").alias(\"count_of_combinations\")))\n",
    "num_uni_rows_biodata = biodata_uni.count()\n",
    "print(\"Number of unique drug-target pairs:\", num_uni_rows_biodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with biodata: 2372\n"
     ]
    }
   ],
   "source": [
    "biodata_uni_t = biodata.dropDuplicates([\"target_chembl_id\"])\n",
    "num_uni_t_biodata = biodata_uni_t.count()\n",
    "print(\"Number of unique targets with biodata:\", num_uni_t_biodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target-Drug pairs from OpenTargets (GE, CT, probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+--------------------+------------------+-------------------+\n",
      "|    drugId|uniprotId|       targetId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+----------+---------+---------------+--------------------+------------------+-------------------+\n",
      "|CHEMBL1000|   O00167|ENSG00000064655|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   O00555|ENSG00000141837|[uniprot_literatu...|             false|              false|\n",
      "|CHEMBL1000|   O14633|ENSG00000159455|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   O60706|ENSG00000069431|            [chembl]|             false|               true|\n",
      "|CHEMBL1000|   P00352|ENSG00000165092|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   P01567|ENSG00000214042|            [chembl]|             false|               true|\n",
      "|CHEMBL1000|   P04155|ENSG00000160182|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   P20036|ENSG00000231389|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   P35908|ENSG00000172867|              [impc]|             false|              false|\n",
      "|CHEMBL1000|   P49840|ENSG00000105723|            [chembl]|             false|               true|\n",
      "|CHEMBL1000|   P51617|ENSG00000184216|              [impc]|             false|              false|\n",
      "|CHEMBL1000|   P56270|ENSG00000103495|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   P58511|ENSG00000205670|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   Q03431|ENSG00000160801|            [chembl]|             false|               true|\n",
      "|CHEMBL1000|   Q06124|ENSG00000179295|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   Q16552|ENSG00000112115|      [impc, chembl]|             false|               true|\n",
      "|CHEMBL1000|   Q7Z2W4|ENSG00000105939|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   Q86SJ6|ENSG00000175065|              [impc]|             false|              false|\n",
      "|CHEMBL1000|   Q8N1K5|ENSG00000172673|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1000|   Q8N8W4|ENSG00000180316|              [impc]|             false|              false|\n",
      "+----------+---------+---------------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of rows: 28921105\n"
     ]
    }
   ],
   "source": [
    "# gcloud storage rsync gs://ot-team/irene/drug_to_target data/drug_to_target\n",
    "\n",
    "drug2target_parquet_dir = \"./data/drug_to_target\"\n",
    "drug2target_parquet = spark.read.parquet(drug2target_parquet_dir)\n",
    "\n",
    "drug2target_parquet.show()\n",
    "\n",
    "num_rows_drug2target = drug2target_parquet.count()\n",
    "print(\"Number of rows:\", num_rows_drug2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------+--------------------+------------------+-------------------+\n",
      "|       drugId|uniprotId|       targetId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+-------------+---------+---------------+--------------------+------------------+-------------------+\n",
      "|    CHEMBL423|   Q9NSG2|ENSG00000000460|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1187417|   Q9Y6X5|ENSG00000001561|              [impc]|             false|              false|\n",
      "|   CHEMBL6995|   Q9Y6D9|ENSG00000002822|[impc, ot_genetic...|             false|              false|\n",
      "| CHEMBL193240|   Q9Y216|ENSG00000003987|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1088752|   P52569|ENSG00000003989|              [impc]|             false|              false|\n",
      "|CHEMBL2103959|   Q9Y2S7|ENSG00000004142|[impc, ot_genetic...|             false|              false|\n",
      "|  CHEMBL77622|   Q96JG6|ENSG00000004766|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1743016|   P30988|ENSG00000004948|      [impc, chembl]|             false|               true|\n",
      "|     CHEMBL86|   O14641|ENSG00000004975|              [impc]|             false|              false|\n",
      "|    CHEMBL796|   P31270|ENSG00000005073|[cancer_gene_census]|             false|              false|\n",
      "|CHEMBL3989959|   Q9UPZ6|ENSG00000005108|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL2108738|   Q9H6T3|ENSG00000005175|              [impc]|             false|              false|\n",
      "|  CHEMBL11359|   Q53FZ2|ENSG00000005187|           [intogen]|             false|              false|\n",
      "|CHEMBL4297948|   Q9P299|ENSG00000005243|[ot_genetics_portal]|             false|              false|\n",
      "|   CHEMBL1353|   P26006|ENSG00000005884|[uniprot_literatu...|             false|              false|\n",
      "|CHEMBL1201719|   Q96EN9|ENSG00000006015|              [impc]|             false|              false|\n",
      "|CHEMBL2110641|   Q9Y2T7|ENSG00000006047|[ot_genetics_portal]|             false|              false|\n",
      "|   CHEMBL1480|   Q09428|ENSG00000006071|[uniprot_literatu...|             false|               true|\n",
      "|    CHEMBL753|   O60359|ENSG00000006116|            [chembl]|             false|               true|\n",
      "|CHEMBL2103842|   P20366|ENSG00000006128|              [impc]|             false|              false|\n",
      "+-------------+---------+---------------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+: 16347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove rows that have duplicate drugId, targetId combinations\n",
    "drug2target_uni = drug2target_parquet.dropDuplicates([\"targetId\"])\n",
    "drug2target_uni.show()\n",
    "\n",
    "num_rows_uni_drug2target = drug2target_uni.count()\n",
    "print(\"Number of unique targets with GE+:\", num_rows_uni_drug2target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biodata and evidence data intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------+---------+--------------------+----------------+------------------+--------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "|    chembl_id|molregno|   tid|accession|           pref_name|target_chembl_id|min_standard_value|standard_units|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+-------------+--------+------+---------+--------------------+----------------+------------------+--------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "| CHEMBL103667|  167995| 11636|   P05771|Protein kinase C ...|      CHEMBL3045|            6900.0|            nM| CHEMBL103667|   P05771|[ot_genetics_port...|             false|               true|\n",
      "|    CHEMBL104|   13494|   130|   P35462|Dopamine D3 receptor|       CHEMBL234|             899.0|            nM|    CHEMBL104|   P35462|[ot_genetics_port...|             false|               true|\n",
      "|    CHEMBL114|   17169|104801|   O60840|Voltage-gated L-t...|   CHEMBL2095229|            1900.0|            nM|    CHEMBL114|   O60840|            [chembl]|             false|               true|\n",
      "|    CHEMBL114|   17169|   134|   P37288|Vasopressin V1a r...|      CHEMBL1889|            7030.0|            nM|    CHEMBL114|   P37288|            [chembl]|             false|               true|\n",
      "| CHEMBL116438|  190171|104681|   Q969S8| Histone deacetylase|   CHEMBL2093865|             539.0|            nM| CHEMBL116438|   Q969S8|[ot_genetics_port...|             false|               true|\n",
      "| CHEMBL116438|  190171|104681|   Q969S8| Histone deacetylase|   CHEMBL2093865|              52.0|             %| CHEMBL116438|   Q969S8|[ot_genetics_port...|             false|               true|\n",
      "| CHEMBL116438|  190171| 30043|   Q9P1W9|Serine/threonine-...|      CHEMBL4523|               2.9|     degrees C| CHEMBL116438|   Q9P1W9|            [chembl]|             false|               true|\n",
      "|CHEMBL1201012|  674963|104062|   Q9NPD5|Solute carrier or...|   CHEMBL1743121|             99.16|             %|CHEMBL1201012|   Q9NPD5|              [impc]|             false|              false|\n",
      "|CHEMBL1201286|  675237|101283|   O15245|Solute carrier fa...|      CHEMBL5685|             640.0|       pmol/mg|CHEMBL1201286|   O15245|              [impc]|             false|              false|\n",
      "|CHEMBL1230165|  692515| 12670|   P36888|Tyrosine-protein ...|      CHEMBL1974|              35.0|            nM|CHEMBL1230165|   P36888|[chembl, eva_soma...|             false|               true|\n",
      "|    CHEMBL126|   26280|    96|   P23219|    Cyclooxygenase-1|       CHEMBL221|            8190.0|            nM|    CHEMBL126|   P23219|      [impc, chembl]|             false|               true|\n",
      "|   CHEMBL1261|  240769|105661|   Q9C0B1|Alpha-ketoglutara...|   CHEMBL2331065|          300000.0|            nM|   CHEMBL1261|   Q9C0B1|[ot_genetics_portal]|             false|              false|\n",
      "|  CHEMBL12856|   11066|104707|   Q13370| Phosphodiesterase 3|   CHEMBL2094125|           16000.0|            nM|  CHEMBL12856|   Q13370|      [impc, chembl]|             false|               true|\n",
      "|  CHEMBL12856|   11066|104738|   Q13370|Phosphodiesterase...|   CHEMBL2095153|            4800.0|            nM|  CHEMBL12856|   Q13370|      [impc, chembl]|             false|               true|\n",
      "|CHEMBL1287853|  714243|100853|   Q9H422|Homeodomain-inter...|      CHEMBL4577|            1300.0|            nM|CHEMBL1287853|   Q9H422|              [impc]|             false|              false|\n",
      "|CHEMBL1289494|  715901| 12214|   P43403|Tyrosine-protein ...|      CHEMBL2803|             107.0|             %|CHEMBL1289494|   P43403|[impc, ot_genetic...|             false|              false|\n",
      "|CHEMBL1289494|  715901| 12261|   P45983|c-Jun N-terminal ...|      CHEMBL2276|             109.0|             %|CHEMBL1289494|   P45983|      [impc, chembl]|             false|               true|\n",
      "|   CHEMBL1336|  276734| 20020|   O14976|Serine/threonine-...|      CHEMBL4355|              90.0|             %|   CHEMBL1336|   O14976|[ot_genetics_portal]|             false|              false|\n",
      "|   CHEMBL1358|  304798|    36|   P06401|Progesterone rece...|       CHEMBL208|            0.2089|            nM|   CHEMBL1358|   P06401|      [impc, chembl]|             false|               true|\n",
      "|   CHEMBL1358|  304798|    36|   P06401|Progesterone rece...|       CHEMBL208|              48.0|             %|   CHEMBL1358|   P06401|      [impc, chembl]|             false|               true|\n",
      "+-------------+--------+------+---------+--------------------+----------------+------------------+--------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 197:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drug-target pairs with GE+ and bidata: 24880\n",
      "Number of unique drug-target pairs with bidata: 53991\n",
      "For 46 % of drug-target pairs with with bidata we have GE+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns_to_join = drug2target_parquet.select('drugId', 'uniprotId', 'sources', 'isHighQualityProbe', 'isTherapeuticTarget')\n",
    "\n",
    "biodata_join = biodata.join(columns_to_join, \n",
    "                            (biodata.chembl_id == columns_to_join.drugId) & \n",
    "                            (biodata.accession == columns_to_join.uniprotId), \n",
    "                            how=\"inner\")\n",
    "\n",
    "biodata_join.show()\n",
    "\n",
    "biodata_join_uni = (biodata_join.groupBy(\"chembl_id\", \"accession\")\n",
    "          .agg(F.count(\"*\").alias(\"count_of_combinations\")))\n",
    "\n",
    "num_uni_rows_biodata_join = biodata_join_uni.count()\n",
    "\n",
    "print(\"Number of unique drug-target pairs with GE+ and bidata:\", num_uni_rows_biodata_join)\n",
    "\n",
    "print(\"Number of unique drug-target pairs with bidata:\", num_uni_rows_biodata)\n",
    "\n",
    "print(\"For\", round(num_uni_rows_biodata_join/num_uni_rows_biodata*100), \"% of drug-target pairs with with bidata we have GE+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For how many drugs from GE+ supported list of D-T pairs we have biodata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drugs from GE+ list: 12835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 278:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drugs from biodata list: 6652\n",
      "For 52 % of drugs from GE+ list we have biodata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "drugs_uni = \"./data/drug_to_target_unique_drugs.csv\"\n",
    "\n",
    "drugs_uni = spark.read.csv(drugs_uni, header=True, inferSchema=True)\n",
    "num_rows_drugs_uni = drugs_uni.count()\n",
    "print(\"Number of unique drugs from GE+ list:\", num_rows_drugs_uni)\n",
    "\n",
    "biodata_drugs_uni = (biodata_join.groupBy(\"chembl_id\")\n",
    "          .agg(F.count(\"*\").alias(\"count_of_combinations\")))\n",
    "num_rows_drugs_uni_biodata = biodata_drugs_uni.count()\n",
    "print(\"Number of unique drugs from biodata list:\", num_rows_drugs_uni_biodata)\n",
    "\n",
    "print(\"For\", round(num_rows_drugs_uni_biodata/num_rows_drugs_uni*100), \"% of drugs from GE+ list we have biodata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many targets with GE+ and bioactivity data are not therapeutic targets (not in MoA)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & biodata: 1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 458:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & biodata & not therapeutic targets: 1422\n",
      "77 % of targets with GE+ & biodata are not therapeutic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_join_therapy = biodata_join.filter(biodata_join.isTherapeuticTarget == False)\n",
    "\n",
    "biodata_join_targets_uni = (biodata_join.groupBy(\"target_chembl_id\")\n",
    "          .agg(F.count(\"*\").alias(\"count_of_combinations\")))\n",
    "num_biodata_join_targets_uni = biodata_join_targets_uni.count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & biodata:\", num_biodata_join_targets_uni)\n",
    "\n",
    "biodata_join_therapy_uni = (biodata_join_therapy.groupBy(\"target_chembl_id\")\n",
    "          .agg(F.count(\"*\").alias(\"count_of_combinations\")))\n",
    "num_biodata_join_therapy_uni = biodata_join_therapy_uni.count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & biodata & not therapeutic targets:\", num_biodata_join_therapy_uni)\n",
    "\n",
    "print(round(num_biodata_join_therapy_uni/num_biodata_join_targets_uni*100), \"% of targets with GE+ & biodata are not therapeutic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the targets analysis with pChEMBL value cutoff (pChEMBL >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+---+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "| chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|\n",
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+---+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224926|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          63.1|            nM|                =|          7.2|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224922|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         31.62|            nM|                =|          7.5|\n",
      "|CHEMBL1000|  111185|   CHEMBL881222|     1|    LITERATURE|          J Med Chem|1.6220969E7|   10.1021/jm058225d|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|   CHEMBL880732|     1|    LITERATURE|Bioorg Med Chem Lett|1.5081022E7|10.1016/j.bmcl.20...|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224923|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         31.62|            nM|                =|          7.5|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224920|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         50.12|            nM|                =|          7.3|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224921|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         50.12|            nM|                =|          7.3|\n",
      "|CHEMBL1000|  111185|   CHEMBL830379|     1|    LITERATURE|Bioorg Med Chem Lett| 1.548293E7|10.1016/j.bmcl.20...|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          14.0|            nM|                =|         7.85|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224924|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|         79.43|            nM|                =|          7.1|\n",
      "|CHEMBL1000|  111185|  CHEMBL1224925|     1|    LITERATURE|       Nat Chem Biol|1.6408006E7| 10.1038/nchembio714|127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          63.1|            nM|                =|          7.2|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937183|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|        457.09|            nM|                =|         6.34|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937031|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|         145.0|            nM|                =|         6.84|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937183|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|         457.0|            nM|                =|         6.34|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937030|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|       5623.41|            nM|                =|         5.25|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937034|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|       3801.89|            nM|                =|         5.42|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937181|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|        275.42|            nM|                =|         6.56|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937182|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|       4677.35|            nM|                =|         5.33|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937034|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|        3802.0|            nM|                =|         5.42|\n",
      "|CHEMBL1002|  111482|  CHEMBL1937181|     1|    LITERATURE|     Bioorg Med Chem|2.2182578E7|10.1016/j.bmc.201...| 43|   P07550|Beta-2 adrenergic...|       CHEMBL210|Homo sapiens|         275.0|            nM|                =|         6.56|\n",
      "+----------+--------+---------------+------+--------------+--------------------+-----------+--------------------+---+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of all drug-target pairs with pChEMBL >= 5: 86487\n"
     ]
    }
   ],
   "source": [
    "# Testset with all biodata\n",
    "biodata_all_in = \"./data/drug2target_bioactivities_chembl_33.csv\"\n",
    "\n",
    "biodata_all = spark.read.csv(biodata_all_in, header=True, inferSchema=True)\n",
    "biodata_all = biodata_all.drop('_c0')\n",
    "\n",
    "# Filter rows where pChEMBL is less than or equal to 5\n",
    "biodata_all = biodata_all.filter(biodata_all['pchembl_value'] >= 5)\n",
    "biodata_all.show()\n",
    "\n",
    "biodata_all_count = biodata_all.count()\n",
    "print(\"Number of all drug-target pairs with pChEMBL >= 5:\", biodata_all_count)\n",
    "\n",
    "# biodata_all.repartition(1).write.csv(\"data/biodata_all_join_test\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|   chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|\n",
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "|  CHEMBL1000|  111185|   CHEMBL830377|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686917E7|10.1016/j.bmcl.20...|   127|   P35367|Histamine H1 rece...|       CHEMBL231|Homo sapiens|          5.89|            nM|                =|         8.23|\n",
      "| CHEMBL10041|    6341|  CHEMBL5121196|     1|    LITERATURE|      Eur J Med Chem|3.4710747E7|10.1016/j.ejmech....|    19|   P03372|Estrogen receptor...|       CHEMBL206|Homo sapiens|          1.12|            nM|                =|         8.95|\n",
      "|CHEMBL100763|  163958|   CHEMBL831663|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|    19|   P03372|Estrogen receptor...|       CHEMBL206|Homo sapiens|         3.304|            nM|                =|         8.48|\n",
      "|CHEMBL100763|  163958|   CHEMBL831659|     1|    LITERATURE|Bioorg Med Chem Lett|1.5686893E7|10.1016/j.bmcl.20...|   174|   Q92731|Estrogen receptor...|       CHEMBL242|Homo sapiens|         302.0|            nM|                =|         6.52|\n",
      "|  CHEMBL1008|  112651|  CHEMBL3436051|     1|    LITERATURE|      J Appl Toxicol|   2.2761E7|    10.1002/jat.2784|   169|   Q13936|Voltage-gated L-t...|      CHEMBL1940|Homo sapiens|        1400.0|            nM|                =|         5.85|\n",
      "|  CHEMBL1008|  112651|  CHEMBL3430571|     1|    LITERATURE|      Cardiovasc Res|2.1300721E7|  10.1093/cvr/cvr044| 11480|   Q14524|Sodium channel pr...|      CHEMBL1980|Homo sapiens|        3700.0|            nM|                =|         5.43|\n",
      "|  CHEMBL1008|  112651|   CHEMBL806152|     1|    LITERATURE|          J Med Chem|  2579237.0| 10.1021/jm00381a019|104837|   P35498|Sodium channel al...|   CHEMBL2096682|Homo sapiens|         840.0|            nM|                =|         6.08|\n",
      "|  CHEMBL1008|  112651|  CHEMBL1676103|     1|    LITERATURE|      Eur J Med Chem|2.1185626E7|10.1016/j.ejmech....|   165|   Q12809|                HERG|       CHEMBL240|Homo sapiens|         22.91|            nM|                =|         7.64|\n",
      "|  CHEMBL1009|  112655|  CHEMBL1909206|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10140|   P06239|Tyrosine-protein ...|       CHEMBL258|Homo sapiens|        3729.0|            nM|                =|         5.43|\n",
      "|CHEMBL101253|  165012|  CHEMBL1063702|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 12840|   P07333|Macrophage colony...|      CHEMBL1844|Homo sapiens|          18.0|            nM|                =|         7.75|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908483|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|   238|   P10721|Stem cell growth ...|      CHEMBL1936|Homo sapiens|           5.1|            nM|                =|         8.29|\n",
      "|CHEMBL101253|  165012|   CHEMBL892951|     1|    LITERATURE|     Bioorg Med Chem|1.7416531E7|10.1016/j.bmc.200...|     9|   P00533|Epidermal growth ...|       CHEMBL203|Homo sapiens|         457.7|            nM|                =|         6.34|\n",
      "|CHEMBL101253|  165012|  CHEMBL1051257|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358|100079|   P07949|Tyrosine-protein ...|      CHEMBL2041|Homo sapiens|        7600.0|            nM|                =|         5.12|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|   P42685|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        1800.0|            nM|                =|         5.75|\n",
      "|CHEMBL101253|  165012|  CHEMBL1908762|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|101239|   O14578|Citron Rho-intera...|      CHEMBL5579|Homo sapiens|        8800.0|            nM|                =|         5.06|\n",
      "|CHEMBL101382|  164146|   CHEMBL836357|     1|    LITERATURE|          J Med Chem|1.5658851E7|   10.1021/jm040858p|104682|   P03372|   Estrogen receptor|   CHEMBL2093866|Homo sapiens|          32.0|            nM|                =|          7.5|\n",
      "|  CHEMBL1014|  116349|  CHEMBL3039490|     1|    LITERATURE|       Mol Pharmacol|2.3571415E7|10.1124/mol.112.0...|103947|   Q9Y6L6|Solute carrier or...|   CHEMBL1697668|Homo sapiens|         400.0|            nM|                =|          6.4|\n",
      "|  CHEMBL1016|  116848|  CHEMBL1909205|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   188|   P04626|Receptor protein-...|      CHEMBL1824|Homo sapiens|        5947.2|            nM|                =|         5.23|\n",
      "|  CHEMBL1016|  116848|  CHEMBL1909094|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|        3039.8|            nM|                =|         5.52|\n",
      "|  CHEMBL1016|  116848|  CHEMBL3791105|     1|    LITERATURE|          J Med Chem|2.6824643E7|10.1021/acs.jmedc...|   115|   P30556|Type-1 angiotensi...|       CHEMBL227|Homo sapiens|          0.69|            nM|                =|         9.16|\n",
      "+------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of unique drug-target pairs with pChEMBL >= 5: 26698\n"
     ]
    }
   ],
   "source": [
    "# !!! Should apply min values but not random!!\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, concat_ws\n",
    "\n",
    "# Define window specification\n",
    "windowSpec = Window.partitionBy(\"chembl_id\", \"target_chembl_id\").orderBy(biodata_all[\"pchembl_value\"].desc())\n",
    "\n",
    "# Assign row number\n",
    "biodata_all_sort = biodata_all.withColumn(\"row_num\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to keep only rows with maximum pchembl_value for each chembl_id within each target_chembl_id\n",
    "biodata_all_min = biodata_all_sort.filter(biodata_all_sort.row_num == 1).drop(\"row_num\")\n",
    "\n",
    "\n",
    "biodata_all_min.show()\n",
    "\n",
    "print(\"Number of unique drug-target pairs with pChEMBL >= 5:\", biodata_all_min.count())\n",
    "\n",
    "\n",
    "# biodata_all_join_min = biodata_all_join_sort.withColumn(\"sources\", concat_ws(\",\", biodata_all_join[\"sources\"]))\n",
    "# biodata_all_join_min.repartition(1).write.csv(\"data/biodata_all_join_test\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "|    chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "| CHEMBL259084|  428508|  CHEMBL1061174|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 10979|   P17948|Vascular endothel...|      CHEMBL1868|Homo sapiens|        1000.0|            nM|                =|          6.0| CHEMBL259084|   P17948|            [chembl]|             false|               true|\n",
      "|CHEMBL3301610| 1763572|  CHEMBL4180588|     1|    LITERATURE|Bioorg Med Chem Lett|2.9074254E7|10.1016/j.bmcl.20...| 10480|   Q00534|Cyclin-dependent ...|      CHEMBL2508|Homo sapiens|           1.9|            nM|                =|         8.72|CHEMBL3301610|   Q00534|[impc, ot_genetic...|             false|               true|\n",
      "|    CHEMBL535|   13048|  CHEMBL1244837|     1|    LITERATURE|               Blood|1.9654408E7|10.1182/blood-200...|100069|   P07332|Tyrosine-protein ...|      CHEMBL5455|Homo sapiens|         960.0|            nM|                =|         6.02|    CHEMBL535|   P07332|[impc, cancer_gen...|             false|              false|\n",
      "| CHEMBL495084|  468993|  CHEMBL1035784|     1|    LITERATURE|          J Med Chem|1.8817364E7|   10.1021/jm8005405| 10188|   Q16539|MAP kinase p38 alpha|       CHEMBL260|Homo sapiens|           0.4|            nM|                =|          9.4| CHEMBL495084|   Q16539|    [chemicalProbes]|             false|              false|\n",
      "| CHEMBL397990|  391022|   CHEMBL891324|     1|    LITERATURE|     Bioorg Med Chem| 1.712707E7|10.1016/j.bmc.200...| 11624|   P29466|           Caspase-1|      CHEMBL4801|Homo sapiens|          11.0|            nM|                =|         7.96| CHEMBL397990|   P29466|    [chemicalProbes]|             false|              false|\n",
      "|    CHEMBL633|   27185|  CHEMBL1909088|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|    52|   P08913|Alpha-2a adrenerg...|      CHEMBL1867|Homo sapiens|         117.0|            nM|                =|         6.93|    CHEMBL633|   P08913|      [impc, chembl]|             false|               true|\n",
      "|CHEMBL3609305| 1960167|  CHEMBL3610437|     1|    LITERATURE|   ACS Med Chem Lett|2.6191363E7|10.1021/acsmedche...| 10907|   P53350|Serine/threonine-...|      CHEMBL3024|Homo sapiens|          0.42|            nM|                =|         9.38|CHEMBL3609305|   P53350|    [chemicalProbes]|             false|              false|\n",
      "| CHEMBL255863|  426660|  CHEMBL1908434|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30019|   P54756|Ephrin type-A rec...|      CHEMBL3987|Homo sapiens|        1900.0|            nM|                =|         5.72| CHEMBL255863|   P54756|[chembl, eva_soma...|             false|               true|\n",
      "| CHEMBL284616|   46995|  CHEMBL4813851|     1|    LITERATURE|     Bioorg Med Chem| 3.424692E7|10.1016/j.bmc.202...| 13061|   P18031|Protein-tyrosine ...|       CHEMBL335|Homo sapiens|         100.0|            nM|                =|          7.0| CHEMBL284616|   P18031|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1615025| 1038036|  CHEMBL3266112|     1|    LITERATURE|Bioorg Med Chem Lett|2.4755426E7|10.1016/j.bmcl.20...| 11409|   Q02750|Dual specificity ...|      CHEMBL3587|Homo sapiens|          1.79|            nM|                =|         8.75|CHEMBL1615025|   Q02750|[intogen, ot_gene...|             false|               true|\n",
      "| CHEMBL502835|  522730|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|   P42685|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        2700.0|            nM|                =|         5.57| CHEMBL502835|   P42685|            [chembl]|             false|               true|\n",
      "|     CHEMBL71|    6216|  CHEMBL1909094|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|          19.0|            nM|                =|         7.72|     CHEMBL71|   P23975|      [impc, chembl]|             false|               true|\n",
      "|  CHEMBL75094|  120195|   CHEMBL715231|     1|    LITERATURE|          J Med Chem|1.1754593E7|   10.1021/jm0103920| 12592|   P14780|Matrix metallopro...|       CHEMBL321|Homo sapiens|         0.048|            nM|                =|        10.32|  CHEMBL75094|   P14780|            [chembl]|             false|               true|\n",
      "|CHEMBL2058833| 1354598|  CHEMBL4378090|     1|    LITERATURE|          J Med Chem|3.1385706E7|10.1021/acs.jmedc...| 17045|   P08684| Cytochrome P450 3A4|       CHEMBL340|Homo sapiens|         156.0|            nM|                =|         6.81|CHEMBL2058833|   P08684|            [chembl]|             false|               true|\n",
      "|    CHEMBL964|   94571|  CHEMBL1909128|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10773|   P25025|Interleukin-8 rec...|      CHEMBL2434|Homo sapiens|        4209.0|            nM|                =|         5.38|    CHEMBL964|   P25025|[impc, ot_genetic...|             false|               true|\n",
      "| CHEMBL271941|  436723|   CHEMBL949197|     1|    LITERATURE|Bioorg Med Chem Lett|1.8221875E7|10.1016/j.bmcl.20...| 10980|   P35968|Vascular endothel...|       CHEMBL279|Homo sapiens|          32.0|            nM|                =|          7.5| CHEMBL271941|   P35968|    [chemicalProbes]|             false|              false|\n",
      "|CHEMBL2063443| 1356841|  CHEMBL2064921|     1|    LITERATURE|Bioorg Med Chem Lett|2.2727637E7|10.1016/j.bmcl.20...| 10781|   Q96GD4|Serine/threonine-...|      CHEMBL2185|Homo sapiens|           4.0|            nM|                =|          8.4|CHEMBL2063443|   Q96GD4|    [chemicalProbes]|             false|              false|\n",
      "|  CHEMBL24828|   33576|  CHEMBL1908641|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|100417|   Q9UM73|ALK tyrosine kina...|      CHEMBL4247|Homo sapiens|        2100.0|            nM|                =|         5.68|  CHEMBL24828|   Q9UM73|[impc, eva, intog...|             false|               true|\n",
      "|CHEMBL5095224| 2739655|  CHEMBL5118400|     1|    LITERATURE|      Eur J Med Chem|3.5849939E7|10.1016/j.ejmech....| 11904|   P56373|  P2X purinoceptor 3|      CHEMBL2998|Homo sapiens|           8.0|            nM|                =|          8.1|CHEMBL5095224|   P56373|            [chembl]|             false|               true|\n",
      "|CHEMBL1684984| 1075318|  CHEMBL1686449|     1|    LITERATURE|Bioorg Med Chem Lett|2.1316229E7|10.1016/j.bmcl.20...|101233|   O00750|Phosphatidylinosi...|      CHEMBL5554|Homo sapiens|        5300.0|            nM|                =|         5.28|CHEMBL1684984|   O00750|[ot_genetics_portal]|             false|              false|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drug-target pairs with GE+ with pChEMBL >= 5: 16138\n",
      "Number of unique drug-target pairs with pChEMBL >= 5: 26698\n",
      "For 60 % of drug-target pairs with pChEMBL >= 5 we have GE+\n"
     ]
    }
   ],
   "source": [
    "drug2target_parquet_dir = \"./data/drug_to_target\"\n",
    "drug2target_parquet = spark.read.parquet(drug2target_parquet_dir)\n",
    "\n",
    "columns_to_join = drug2target_parquet.select('drugId', 'uniprotId', 'sources', 'isHighQualityProbe', 'isTherapeuticTarget')\n",
    "\n",
    "biodata_all_join = biodata_all_min.join(columns_to_join, \n",
    "                            (biodata_all_min.chembl_id == columns_to_join.drugId) & \n",
    "                            (biodata_all_min.accession == columns_to_join.uniprotId), \n",
    "                            how=\"inner\")\n",
    "biodata_all_join.show()\n",
    "\n",
    "num_biodata_all_join = biodata_all_join.count()\n",
    "num_biodata_all_min = biodata_all_min.count()\n",
    "\n",
    "print(\"Number of unique drug-target pairs with GE+ with pChEMBL >= 5:\", num_biodata_all_join)\n",
    "\n",
    "print(\"Number of unique drug-target pairs with pChEMBL >= 5:\", num_biodata_all_min)\n",
    "\n",
    "print(\"For\", round(num_biodata_all_join/num_biodata_all_min*100), \"% of drug-target pairs with pChEMBL >= 5 we have GE+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_all_join_save = biodata_all_join.withColumn(\"sources\", concat_ws(\",\", biodata_all_join[\"sources\"]))\n",
    "biodata_all_join_save.repartition(1).write.mode(\"overwrite\").csv(\"data/biodata_all_join_test\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & pChEMBL >= 5: 1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_all_join_targets = biodata_all_join.groupBy(\"target_chembl_id\")\n",
    "num_biodata_all_join_targets = biodata_all_join_targets.count().count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & pChEMBL >= 5:\", num_biodata_all_join_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & pChEMBL >= 5 & not therapeutic targets: 1090\n",
      "73 % of targets with GE+ & pChEMBL >= 5 are not therapeutic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biodata_all_join_therapy = biodata_all_join.filter(biodata_all_join.isTherapeuticTarget == False)\n",
    "\n",
    "biodata_all_join_therapy_uni = biodata_all_join_therapy.groupBy(\"target_chembl_id\").count()\n",
    "num_biodata_all_join_therapy_uni = biodata_all_join_therapy_uni.count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & pChEMBL >= 5 & not therapeutic targets:\", num_biodata_all_join_therapy_uni)\n",
    "\n",
    "print(round(num_biodata_all_join_therapy_uni/num_biodata_all_join_targets*100), \"% of targets with GE+ & pChEMBL >= 5 are not therapeutic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns_to_aggregate = [\n",
    "    \"chembl_id\", \"molregno\", \"assay_chembl_id\", \"src_id\", \"src_short_name\", \n",
    "    \"journal\", \"pubmed_id\", \"doi\", \"tid\", \"accession\", \"pref_name\", \n",
    "    \"organism\", \"standard_value\", \"standard_units\", \"standard_relation\", \"pchembl_value\",\n",
    "    \"isHighQualityProbe\", \"isTherapeuticTarget\"\n",
    "]\n",
    "\n",
    "# Create aggregation expressions for unique values for standard columns\n",
    "aggregations = [F.concat_ws(\",\", F.collect_set(col)).alias(f\"{col}\") for col in columns_to_aggregate]\n",
    "\n",
    "# Handle the \"sources\" column specifically\n",
    "sources_aggregation = F.concat_ws(\",\", F.flatten(F.collect_set(\"sources\"))).alias(\"concatenated_sources\")\n",
    "\n",
    "# Add the sources aggregation to the list\n",
    "aggregations.append(sources_aggregation)\n",
    "\n",
    "# Group by 'target_chembl_id' and aggregate\n",
    "grouped_data = biodata_all_join.groupBy(\"target_chembl_id\").agg(*aggregations)\n",
    "\n",
    "# Save to CSV\n",
    "grouped_data.repartition(1).write.mode(\"overwrite\").csv(\"data/biodata_all_join_v2\", header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "|    chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "| CHEMBL259084|  428508|  CHEMBL1061174|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 10979|   P17948|Vascular endothel...|      CHEMBL1868|Homo sapiens|        1000.0|            nM|                =|          6.0| CHEMBL259084|   P17948|            [chembl]|             false|               true|\n",
      "|CHEMBL3301610| 1763572|  CHEMBL4180588|     1|    LITERATURE|Bioorg Med Chem Lett|2.9074254E7|10.1016/j.bmcl.20...| 10480|   Q00534|Cyclin-dependent ...|      CHEMBL2508|Homo sapiens|           1.9|            nM|                =|         8.72|CHEMBL3301610|   Q00534|[impc, ot_genetic...|             false|               true|\n",
      "|    CHEMBL535|   13048|  CHEMBL1244837|     1|    LITERATURE|               Blood|1.9654408E7|10.1182/blood-200...|100069|   P07332|Tyrosine-protein ...|      CHEMBL5455|Homo sapiens|         960.0|            nM|                =|         6.02|    CHEMBL535|   P07332|[impc, cancer_gen...|             false|              false|\n",
      "| CHEMBL495084|  468993|  CHEMBL1035784|     1|    LITERATURE|          J Med Chem|1.8817364E7|   10.1021/jm8005405| 10188|   Q16539|MAP kinase p38 alpha|       CHEMBL260|Homo sapiens|           0.4|            nM|                =|          9.4| CHEMBL495084|   Q16539|    [chemicalProbes]|             false|              false|\n",
      "| CHEMBL397990|  391022|   CHEMBL891324|     1|    LITERATURE|     Bioorg Med Chem| 1.712707E7|10.1016/j.bmc.200...| 11624|   P29466|           Caspase-1|      CHEMBL4801|Homo sapiens|          11.0|            nM|                =|         7.96| CHEMBL397990|   P29466|    [chemicalProbes]|             false|              false|\n",
      "|    CHEMBL633|   27185|  CHEMBL1909088|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|    52|   P08913|Alpha-2a adrenerg...|      CHEMBL1867|Homo sapiens|         117.0|            nM|                =|         6.93|    CHEMBL633|   P08913|      [impc, chembl]|             false|               true|\n",
      "|CHEMBL3609305| 1960167|  CHEMBL3610437|     1|    LITERATURE|   ACS Med Chem Lett|2.6191363E7|10.1021/acsmedche...| 10907|   P53350|Serine/threonine-...|      CHEMBL3024|Homo sapiens|          0.42|            nM|                =|         9.38|CHEMBL3609305|   P53350|    [chemicalProbes]|             false|              false|\n",
      "| CHEMBL255863|  426660|  CHEMBL1908434|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30019|   P54756|Ephrin type-A rec...|      CHEMBL3987|Homo sapiens|        1900.0|            nM|                =|         5.72| CHEMBL255863|   P54756|[chembl, eva_soma...|             false|               true|\n",
      "| CHEMBL284616|   46995|  CHEMBL4813851|     1|    LITERATURE|     Bioorg Med Chem| 3.424692E7|10.1016/j.bmc.202...| 13061|   P18031|Protein-tyrosine ...|       CHEMBL335|Homo sapiens|         100.0|            nM|                =|          7.0| CHEMBL284616|   P18031|[ot_genetics_portal]|             false|              false|\n",
      "|CHEMBL1615025| 1038036|  CHEMBL3266112|     1|    LITERATURE|Bioorg Med Chem Lett|2.4755426E7|10.1016/j.bmcl.20...| 11409|   Q02750|Dual specificity ...|      CHEMBL3587|Homo sapiens|          1.79|            nM|                =|         8.75|CHEMBL1615025|   Q02750|[intogen, ot_gene...|             false|               true|\n",
      "| CHEMBL502835|  522730|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|   P42685|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        2700.0|            nM|                =|         5.57| CHEMBL502835|   P42685|            [chembl]|             false|               true|\n",
      "|     CHEMBL71|    6216|  CHEMBL1909094|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|          19.0|            nM|                =|         7.72|     CHEMBL71|   P23975|      [impc, chembl]|             false|               true|\n",
      "|  CHEMBL75094|  120195|   CHEMBL715231|     1|    LITERATURE|          J Med Chem|1.1754593E7|   10.1021/jm0103920| 12592|   P14780|Matrix metallopro...|       CHEMBL321|Homo sapiens|         0.048|            nM|                =|        10.32|  CHEMBL75094|   P14780|            [chembl]|             false|               true|\n",
      "|CHEMBL2058833| 1354598|  CHEMBL4378090|     1|    LITERATURE|          J Med Chem|3.1385706E7|10.1021/acs.jmedc...| 17045|   P08684| Cytochrome P450 3A4|       CHEMBL340|Homo sapiens|         156.0|            nM|                =|         6.81|CHEMBL2058833|   P08684|            [chembl]|             false|               true|\n",
      "|    CHEMBL964|   94571|  CHEMBL1909128|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10773|   P25025|Interleukin-8 rec...|      CHEMBL2434|Homo sapiens|        4209.0|            nM|                =|         5.38|    CHEMBL964|   P25025|[impc, ot_genetic...|             false|               true|\n",
      "| CHEMBL271941|  436723|   CHEMBL949197|     1|    LITERATURE|Bioorg Med Chem Lett|1.8221875E7|10.1016/j.bmcl.20...| 10980|   P35968|Vascular endothel...|       CHEMBL279|Homo sapiens|          32.0|            nM|                =|          7.5| CHEMBL271941|   P35968|    [chemicalProbes]|             false|              false|\n",
      "|CHEMBL2063443| 1356841|  CHEMBL2064921|     1|    LITERATURE|Bioorg Med Chem Lett|2.2727637E7|10.1016/j.bmcl.20...| 10781|   Q96GD4|Serine/threonine-...|      CHEMBL2185|Homo sapiens|           4.0|            nM|                =|          8.4|CHEMBL2063443|   Q96GD4|    [chemicalProbes]|             false|              false|\n",
      "|  CHEMBL24828|   33576|  CHEMBL1908641|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|100417|   Q9UM73|ALK tyrosine kina...|      CHEMBL4247|Homo sapiens|        2100.0|            nM|                =|         5.68|  CHEMBL24828|   Q9UM73|[impc, eva, intog...|             false|               true|\n",
      "|CHEMBL5095224| 2739655|  CHEMBL5118400|     1|    LITERATURE|      Eur J Med Chem|3.5849939E7|10.1016/j.ejmech....| 11904|   P56373|  P2X purinoceptor 3|      CHEMBL2998|Homo sapiens|           8.0|            nM|                =|          8.1|CHEMBL5095224|   P56373|            [chembl]|             false|               true|\n",
      "|CHEMBL1684984| 1075318|  CHEMBL1686449|     1|    LITERATURE|Bioorg Med Chem Lett|2.1316229E7|10.1016/j.bmcl.20...|101233|   O00750|Phosphatidylinosi...|      CHEMBL5554|Homo sapiens|        5300.0|            nM|                =|         5.28|CHEMBL1684984|   O00750|[ot_genetics_portal]|             false|              false|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "biodata_all_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|accession|proteinClass|\n",
      "+---------+------------+\n",
      "|   P32929|      Enzyme|\n",
      "|   A4D0Y5|        None|\n",
      "|   Q49A92|        None|\n",
      "|   Q9UFW8|        None|\n",
      "|   Q96K31|        None|\n",
      "|   O14646|  Epigenetic|\n",
      "|   Q8IWX8|        None|\n",
      "|   Q99653|        None|\n",
      "|   O94983|          TF|\n",
      "|   Q8NA66|        None|\n",
      "|   Q96M20|        None|\n",
      "|   Q86VU5|      Enzyme|\n",
      "|   P42695|        None|\n",
      "|   Q8IYT2|      Enzyme|\n",
      "|   Q9NSA3|        None|\n",
      "|   Q96KP4|      Enzyme|\n",
      "|   Q13956|      Enzyme|\n",
      "|   O95476|      Enzyme|\n",
      "|   Q9BYD5|        None|\n",
      "|   Q969H4|      Enzyme|\n",
      "+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protein_class_in = \"./data/forPolina_uniprot2family.csv\"\n",
    "\n",
    "protein_class = spark.read.csv(protein_class_in, header=True, inferSchema=True)\n",
    "\n",
    "protein_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "|    chembl_id|molregno|assay_chembl_id|src_id|src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|accession|proteinClass|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "| CHEMBL259084|  428508|  CHEMBL1061174|     1|    LITERATURE|      Nat Biotechnol|1.8183025E7|     10.1038/nbt1358| 10979|   P17948|Vascular endothel...|      CHEMBL1868|Homo sapiens|        1000.0|            nM|                =|          6.0| CHEMBL259084|   P17948|            [chembl]|             false|               true|   P17948|      Kinase|\n",
      "|CHEMBL3301610| 1763572|  CHEMBL4180588|     1|    LITERATURE|Bioorg Med Chem Lett|2.9074254E7|10.1016/j.bmcl.20...| 10480|   Q00534|Cyclin-dependent ...|      CHEMBL2508|Homo sapiens|           1.9|            nM|                =|         8.72|CHEMBL3301610|   Q00534|[impc, ot_genetic...|             false|               true|   Q00534|      Kinase|\n",
      "|    CHEMBL535|   13048|  CHEMBL1244837|     1|    LITERATURE|               Blood|1.9654408E7|10.1182/blood-200...|100069|   P07332|Tyrosine-protein ...|      CHEMBL5455|Homo sapiens|         960.0|            nM|                =|         6.02|    CHEMBL535|   P07332|[impc, cancer_gen...|             false|              false|   P07332|      Kinase|\n",
      "| CHEMBL495084|  468993|  CHEMBL1035784|     1|    LITERATURE|          J Med Chem|1.8817364E7|   10.1021/jm8005405| 10188|   Q16539|MAP kinase p38 alpha|       CHEMBL260|Homo sapiens|           0.4|            nM|                =|          9.4| CHEMBL495084|   Q16539|    [chemicalProbes]|             false|              false|   Q16539|      Kinase|\n",
      "| CHEMBL397990|  391022|   CHEMBL891324|     1|    LITERATURE|     Bioorg Med Chem| 1.712707E7|10.1016/j.bmc.200...| 11624|   P29466|           Caspase-1|      CHEMBL4801|Homo sapiens|          11.0|            nM|                =|         7.96| CHEMBL397990|   P29466|    [chemicalProbes]|             false|              false|   P29466|      Enzyme|\n",
      "|    CHEMBL633|   27185|  CHEMBL1909088|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|    52|   P08913|Alpha-2a adrenerg...|      CHEMBL1867|Homo sapiens|         117.0|            nM|                =|         6.93|    CHEMBL633|   P08913|      [impc, chembl]|             false|               true|   P08913|        GPCR|\n",
      "|CHEMBL3609305| 1960167|  CHEMBL3610437|     1|    LITERATURE|   ACS Med Chem Lett|2.6191363E7|10.1021/acsmedche...| 10907|   P53350|Serine/threonine-...|      CHEMBL3024|Homo sapiens|          0.42|            nM|                =|         9.38|CHEMBL3609305|   P53350|    [chemicalProbes]|             false|              false|   P53350|      Kinase|\n",
      "| CHEMBL255863|  426660|  CHEMBL1908434|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30019|   P54756|Ephrin type-A rec...|      CHEMBL3987|Homo sapiens|        1900.0|            nM|                =|         5.72| CHEMBL255863|   P54756|[chembl, eva_soma...|             false|               true|   P54756|      Kinase|\n",
      "| CHEMBL284616|   46995|  CHEMBL4813851|     1|    LITERATURE|     Bioorg Med Chem| 3.424692E7|10.1016/j.bmc.202...| 13061|   P18031|Protein-tyrosine ...|       CHEMBL335|Homo sapiens|         100.0|            nM|                =|          7.0| CHEMBL284616|   P18031|[ot_genetics_portal]|             false|              false|   P18031|      Enzyme|\n",
      "|CHEMBL1615025| 1038036|  CHEMBL3266112|     1|    LITERATURE|Bioorg Med Chem Lett|2.4755426E7|10.1016/j.bmcl.20...| 11409|   Q02750|Dual specificity ...|      CHEMBL3587|Homo sapiens|          1.79|            nM|                =|         8.75|CHEMBL1615025|   Q02750|[intogen, ot_gene...|             false|               true|   Q02750|      Kinase|\n",
      "| CHEMBL502835|  522730|  CHEMBL1908552|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990| 30012|   P42685|Tyrosine-protein ...|      CHEMBL4223|Homo sapiens|        2700.0|            nM|                =|         5.57| CHEMBL502835|   P42685|            [chembl]|             false|               true|   P42685|      Kinase|\n",
      "|     CHEMBL71|    6216|  CHEMBL1909094|    15|    DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|          19.0|            nM|                =|         7.72|     CHEMBL71|   P23975|      [impc, chembl]|             false|               true|   P23975| Transporter|\n",
      "|  CHEMBL75094|  120195|   CHEMBL715231|     1|    LITERATURE|          J Med Chem|1.1754593E7|   10.1021/jm0103920| 12592|   P14780|Matrix metallopro...|       CHEMBL321|Homo sapiens|         0.048|            nM|                =|        10.32|  CHEMBL75094|   P14780|            [chembl]|             false|               true|   P14780|      Enzyme|\n",
      "|CHEMBL2058833| 1354598|  CHEMBL4378090|     1|    LITERATURE|          J Med Chem|3.1385706E7|10.1021/acs.jmedc...| 17045|   P08684| Cytochrome P450 3A4|       CHEMBL340|Homo sapiens|         156.0|            nM|                =|         6.81|CHEMBL2058833|   P08684|            [chembl]|             false|               true|   P08684|      Enzyme|\n",
      "|    CHEMBL964|   94571|  CHEMBL1909128|    15|    DRUGMATRIX|                NULL|       NULL|                NULL| 10773|   P25025|Interleukin-8 rec...|      CHEMBL2434|Homo sapiens|        4209.0|            nM|                =|         5.38|    CHEMBL964|   P25025|[impc, ot_genetic...|             false|               true|   P25025|        GPCR|\n",
      "| CHEMBL271941|  436723|   CHEMBL949197|     1|    LITERATURE|Bioorg Med Chem Lett|1.8221875E7|10.1016/j.bmcl.20...| 10980|   P35968|Vascular endothel...|       CHEMBL279|Homo sapiens|          32.0|            nM|                =|          7.5| CHEMBL271941|   P35968|    [chemicalProbes]|             false|              false|   P35968|      Kinase|\n",
      "|CHEMBL2063443| 1356841|  CHEMBL2064921|     1|    LITERATURE|Bioorg Med Chem Lett|2.2727637E7|10.1016/j.bmcl.20...| 10781|   Q96GD4|Serine/threonine-...|      CHEMBL2185|Homo sapiens|           4.0|            nM|                =|          8.4|CHEMBL2063443|   Q96GD4|    [chemicalProbes]|             false|              false|   Q96GD4|      Kinase|\n",
      "|  CHEMBL24828|   33576|  CHEMBL1908641|     1|    LITERATURE|      Nat Biotechnol|2.2037378E7|    10.1038/nbt.1990|100417|   Q9UM73|ALK tyrosine kina...|      CHEMBL4247|Homo sapiens|        2100.0|            nM|                =|         5.68|  CHEMBL24828|   Q9UM73|[impc, eva, intog...|             false|               true|   Q9UM73|      Kinase|\n",
      "|CHEMBL5095224| 2739655|  CHEMBL5118400|     1|    LITERATURE|      Eur J Med Chem|3.5849939E7|10.1016/j.ejmech....| 11904|   P56373|  P2X purinoceptor 3|      CHEMBL2998|Homo sapiens|           8.0|            nM|                =|          8.1|CHEMBL5095224|   P56373|            [chembl]|             false|               true|   P56373|          IC|\n",
      "|CHEMBL1684984| 1075318|  CHEMBL1686449|     1|    LITERATURE|Bioorg Med Chem Lett|2.1316229E7|10.1016/j.bmcl.20...|101233|   O00750|Phosphatidylinosi...|      CHEMBL5554|Homo sapiens|        5300.0|            nM|                =|         5.28|CHEMBL1684984|   O00750|[ot_genetics_portal]|             false|              false|   O00750|      Kinase|\n",
      "+-------------+--------+---------------+------+--------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biodata_all_join_class = biodata_all_join.join(protein_class, \n",
    "                            (biodata_all_join.accession == protein_class.accession), \n",
    "                            how=\"left\")\n",
    "biodata_all_join_class.show()\n",
    "biodata_all_join_class.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate targets by datasources with custom cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------------+------+---------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "|    chembl_id|molregno|assay_chembl_id|src_id| src_short_name|             journal|  pubmed_id|                 doi|   tid|accession|           pref_name|target_chembl_id|    organism|standard_value|standard_units|standard_relation|pchembl_value|       drugId|uniprotId|             sources|isHighQualityProbe|isTherapeuticTarget|accession|proteinClass|\n",
      "+-------------+--------+---------------+------+---------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "|CHEMBL3301610| 1763572|  CHEMBL4180588|     1|     LITERATURE|Bioorg Med Chem Lett|2.9074254E7|10.1016/j.bmcl.20...| 10480|   Q00534|Cyclin-dependent ...|      CHEMBL2508|Homo sapiens|           1.9|            nM|                =|         8.72|CHEMBL3301610|   Q00534|[impc, ot_genetic...|             false|               true|   Q00534|      Kinase|\n",
      "| CHEMBL495084|  468993|  CHEMBL1035784|     1|     LITERATURE|          J Med Chem|1.8817364E7|   10.1021/jm8005405| 10188|   Q16539|MAP kinase p38 alpha|       CHEMBL260|Homo sapiens|           0.4|            nM|                =|          9.4| CHEMBL495084|   Q16539|    [chemicalProbes]|             false|              false|   Q16539|      Kinase|\n",
      "| CHEMBL397990|  391022|   CHEMBL891324|     1|     LITERATURE|     Bioorg Med Chem| 1.712707E7|10.1016/j.bmc.200...| 11624|   P29466|           Caspase-1|      CHEMBL4801|Homo sapiens|          11.0|            nM|                =|         7.96| CHEMBL397990|   P29466|    [chemicalProbes]|             false|              false|   P29466|      Enzyme|\n",
      "|    CHEMBL633|   27185|  CHEMBL1909088|    15|     DRUGMATRIX|                NULL|       NULL|                NULL|    52|   P08913|Alpha-2a adrenerg...|      CHEMBL1867|Homo sapiens|         117.0|            nM|                =|         6.93|    CHEMBL633|   P08913|      [impc, chembl]|             false|               true|   P08913|        GPCR|\n",
      "|CHEMBL3609305| 1960167|  CHEMBL3610437|     1|     LITERATURE|   ACS Med Chem Lett|2.6191363E7|10.1021/acsmedche...| 10907|   P53350|Serine/threonine-...|      CHEMBL3024|Homo sapiens|          0.42|            nM|                =|         9.38|CHEMBL3609305|   P53350|    [chemicalProbes]|             false|              false|   P53350|      Kinase|\n",
      "| CHEMBL284616|   46995|  CHEMBL4813851|     1|     LITERATURE|     Bioorg Med Chem| 3.424692E7|10.1016/j.bmc.202...| 13061|   P18031|Protein-tyrosine ...|       CHEMBL335|Homo sapiens|         100.0|            nM|                =|          7.0| CHEMBL284616|   P18031|[ot_genetics_portal]|             false|              false|   P18031|      Enzyme|\n",
      "|CHEMBL1615025| 1038036|  CHEMBL3266112|     1|     LITERATURE|Bioorg Med Chem Lett|2.4755426E7|10.1016/j.bmcl.20...| 11409|   Q02750|Dual specificity ...|      CHEMBL3587|Homo sapiens|          1.79|            nM|                =|         8.75|CHEMBL1615025|   Q02750|[intogen, ot_gene...|             false|               true|   Q02750|      Kinase|\n",
      "|     CHEMBL71|    6216|  CHEMBL1909094|    15|     DRUGMATRIX|                NULL|       NULL|                NULL|   100|   P23975|Norepinephrine tr...|       CHEMBL222|Homo sapiens|          19.0|            nM|                =|         7.72|     CHEMBL71|   P23975|      [impc, chembl]|             false|               true|   P23975| Transporter|\n",
      "|  CHEMBL75094|  120195|   CHEMBL715231|     1|     LITERATURE|          J Med Chem|1.1754593E7|   10.1021/jm0103920| 12592|   P14780|Matrix metallopro...|       CHEMBL321|Homo sapiens|         0.048|            nM|                =|        10.32|  CHEMBL75094|   P14780|            [chembl]|             false|               true|   P14780|      Enzyme|\n",
      "|CHEMBL2058833| 1354598|  CHEMBL4378090|     1|     LITERATURE|          J Med Chem|3.1385706E7|10.1021/acs.jmedc...| 17045|   P08684| Cytochrome P450 3A4|       CHEMBL340|Homo sapiens|         156.0|            nM|                =|         6.81|CHEMBL2058833|   P08684|            [chembl]|             false|               true|   P08684|      Enzyme|\n",
      "|CHEMBL2063443| 1356841|  CHEMBL2064921|     1|     LITERATURE|Bioorg Med Chem Lett|2.2727637E7|10.1016/j.bmcl.20...| 10781|   Q96GD4|Serine/threonine-...|      CHEMBL2185|Homo sapiens|           4.0|            nM|                =|          8.4|CHEMBL2063443|   Q96GD4|    [chemicalProbes]|             false|              false|   Q96GD4|      Kinase|\n",
      "|CHEMBL5095224| 2739655|  CHEMBL5118400|     1|     LITERATURE|      Eur J Med Chem|3.5849939E7|10.1016/j.ejmech....| 11904|   P56373|  P2X purinoceptor 3|      CHEMBL2998|Homo sapiens|           8.0|            nM|                =|          8.1|CHEMBL5095224|   P56373|            [chembl]|             false|               true|   P56373|          IC|\n",
      "| CHEMBL253969|  424611|   CHEMBL929872|     1|     LITERATURE|Bioorg Med Chem Lett|1.8308565E7|10.1016/j.bmcl.20...| 12913|   Q02763|Tyrosine-protein ...|      CHEMBL4128|Homo sapiens|          18.0|            nM|                =|         7.75| CHEMBL253969|   Q02763|            [chembl]|             false|               true|   Q02763|      Kinase|\n",
      "|CHEMBL3707218| 2039189|  CHEMBL4321997|     1|     LITERATURE|          J Med Chem|3.1012583E7|10.1021/acs.jmedc...| 18080|   Q9Y5Y9|Sodium channel pr...|      CHEMBL5451|Homo sapiens|        4800.0|            nM|                =|         5.32|CHEMBL3707218|   Q9Y5Y9|            [chembl]|             false|               true|   Q9Y5Y9|          IC|\n",
      "|CHEMBL3329660| 1788648|  CHEMBL3380433|     1|     LITERATURE|      Eur J Med Chem| 2.508981E7|10.1016/j.ejmech....| 10781|   Q96GD4|Serine/threonine-...|      CHEMBL2185|Homo sapiens|          15.0|            nM|                =|         7.82|CHEMBL3329660|   Q96GD4|    [chemicalProbes]|             false|              false|   Q96GD4|      Kinase|\n",
      "|CHEMBL3577885| 1946198|  CHEMBL5214521|    65|LIT_EUBOPEN_CGL|                NULL|       NULL|10.6019/CHEMBL521...|103167|   Q7Z2W7|Transient recepto...|   CHEMBL1075319|Homo sapiens|          13.8|            nM|                =|         7.86|CHEMBL3577885|   Q7Z2W7|    [chemicalProbes]|              true|              false|   Q7Z2W7|          IC|\n",
      "|CHEMBL2110596| 1383036|   CHEMBL772607|     1|     LITERATURE|          J Med Chem|  6142954.0| 10.1021/jm00370a011|104723|   P25100|Adrenergic recept...|   CHEMBL2094251|Homo sapiens|        109.65|            nM|                =|         6.96|CHEMBL2110596|   P25100|[impc, ot_genetic...|             false|               true|   P25100|        GPCR|\n",
      "| CHEMBL262747|  237299|   CHEMBL853239|     1|     LITERATURE|          J Med Chem|1.6759096E7|   10.1021/jm060240a|   118|   P30968|Gonadotropin-rele...|      CHEMBL1855|Homo sapiens|        0.6918|            nM|                =|         9.16| CHEMBL262747|   P30968|[impc, eva, orpha...|             false|               true|   P30968|        GPCR|\n",
      "|CHEMBL3715310| 2040900|  CHEMBL3721218|    38|         PATENT|                NULL|       NULL|                NULL| 10711|   P25098|G-protein coupled...|      CHEMBL4079|Homo sapiens|           4.6|            nM|                =|         8.34|CHEMBL3715310|   P25098|    [chemicalProbes]|             false|              false|   P25098|      Kinase|\n",
      "| CHEMBL209712|  348905|   CHEMBL866345|     1|     LITERATURE|          J Med Chem|1.6759094E7|   10.1021/jm0512544| 11085|   P49286|Melatonin recepto...|      CHEMBL1946|Homo sapiens|           7.5|            nM|                =|         8.12| CHEMBL209712|   P49286|    [chemicalProbes]|             false|              false|   P49286|        GPCR|\n",
      "+-------------+--------+---------------+------+---------------+--------------------+-----------+--------------------+------+---------+--------------------+----------------+------------+--------------+--------------+-----------------+-------------+-------------+---------+--------------------+------------------+-------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10246"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom cutoff\n",
    "biodata_all_join_class_filter = biodata_all_join_class.filter(\n",
    "    ((F.col(\"proteinClass\") == \"Kinase\") & (F.col(\"pchembl_value\") >= 7.7)) |\n",
    "    ((F.col(\"proteinClass\") == \"GPCR\") & (F.col(\"pchembl_value\") >= 6.5)) |\n",
    "    ((F.col(\"proteinClass\") == \"NR\") & (F.col(\"pchembl_value\") >= 6.1)) |\n",
    "    ((F.col(\"proteinClass\") == \"Transporter\") & (F.col(\"pchembl_value\") >= 6.1)) |\n",
    "    ((F.col(\"proteinClass\") == \"Enzyme\") & (F.col(\"pchembl_value\") >= 5.2)) |\n",
    "    ((F.col(\"proteinClass\") == \"IC\") & (F.col(\"pchembl_value\") >= 4.6)) |\n",
    "    ((F.col(\"proteinClass\") == \"Other\") & (F.col(\"pchembl_value\") >= 6.3)) |\n",
    "    (~(F.col(\"proteinClass\").isin([\"Kinase\", \"GPCR\", \"NR\", \"Transporter\", \"Enzyme\", \"IC\", \"Other\"])) & (F.col(\"pchembl_value\") >= 5))\n",
    ")\n",
    "biodata_all_join_class_filter.show()\n",
    "biodata_all_join_class_filter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & pChEMBL cutoff: 1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "custom_cutoff_targets = biodata_all_join_class_filter.groupBy(\"target_chembl_id\")\n",
    "num_custom_cutoff_targets = custom_cutoff_targets.count().count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & pChEMBL cutoff:\", num_custom_cutoff_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique targets with GE+ & cutoff & not therapeutic targets: 939\n",
      "70 % of targets with GE+ & cutoff are not therapeutic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "custom_cutoff_therapy = biodata_all_join_class_filter.filter(biodata_all_join.isTherapeuticTarget == False)\n",
    "\n",
    "custom_cutoff_therapy_uni = custom_cutoff_therapy.groupBy(\"target_chembl_id\").count()\n",
    "num_custom_cutoff_therapy_uni = custom_cutoff_therapy_uni.count()\n",
    "\n",
    "print(\"Number of unique targets with GE+ & cutoff & not therapeutic targets:\", num_custom_cutoff_therapy_uni)\n",
    "\n",
    "print(round(num_custom_cutoff_therapy_uni/num_custom_cutoff_targets*100), \"% of targets with GE+ & cutoff are not therapeutic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 32\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m columns_to_aggregate \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mchembl_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmolregno\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39massay_chembl_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msrc_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msrc_short_name\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mjournal\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpubmed_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muniprotId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpref_name\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39morganism\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_value\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_units\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_relation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpchembl_value\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39misHighQualityProbe\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39misTherapeuticTarget\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mproteinClass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Create aggregation expressions for unique values for standard columns\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m aggregations \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mconcat_ws(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, F\u001b[39m.\u001b[39mcollect_set(col))\u001b[39m.\u001b[39malias(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_to_aggregate]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Handle the \"sources\" column specifically\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m sources_aggregation \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mconcat_ws(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, F\u001b[39m.\u001b[39mflatten(F\u001b[39m.\u001b[39mcollect_set(\u001b[39m\"\u001b[39m\u001b[39msources\u001b[39m\u001b[39m\"\u001b[39m)))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mconcatenated_sources\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb Cell 32\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m columns_to_aggregate \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mchembl_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmolregno\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39massay_chembl_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msrc_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msrc_short_name\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mjournal\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpubmed_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muniprotId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpref_name\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39morganism\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_value\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_units\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstandard_relation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpchembl_value\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39misHighQualityProbe\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39misTherapeuticTarget\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mproteinClass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Create aggregation expressions for unique values for standard columns\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m aggregations \u001b[39m=\u001b[39m [F\u001b[39m.\u001b[39mconcat_ws(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, F\u001b[39m.\u001b[39mcollect_set(col))\u001b[39m.\u001b[39malias(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_to_aggregate]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Handle the \"sources\" column specifically\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/Target2Bioactivity.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m sources_aggregation \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mconcat_ws(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, F\u001b[39m.\u001b[39mflatten(F\u001b[39m.\u001b[39mcollect_set(\u001b[39m\"\u001b[39m\u001b[39msources\u001b[39m\u001b[39m\"\u001b[39m)))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mconcatenated_sources\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "columns_to_aggregate = [\n",
    "    \"chembl_id\", \"molregno\", \"assay_chembl_id\", \"src_id\", \"src_short_name\", \n",
    "    \"journal\", \"pubmed_id\", \"doi\", \"tid\", \"uniprotId\", \"pref_name\", \n",
    "    \"organism\", \"standard_value\", \"standard_units\", \"standard_relation\", \"pchembl_value\",\n",
    "    \"isHighQualityProbe\", \"isTherapeuticTarget\", \"proteinClass\"\n",
    "]\n",
    "\n",
    "# Create aggregation expressions for unique values for standard columns\n",
    "aggregations = [F.concat_ws(\",\", F.collect_set(col)).alias(f\"{col}\") for col in columns_to_aggregate]\n",
    "\n",
    "# Handle the \"sources\" column specifically\n",
    "sources_aggregation = F.concat_ws(\",\", F.flatten(F.collect_set(\"sources\"))).alias(\"concatenated_sources\")\n",
    "\n",
    "# Add the sources aggregation to the list\n",
    "aggregations.append(sources_aggregation)\n",
    "\n",
    "# Group by 'target_chembl_id' and aggregate\n",
    "custom_cutoff_grouped_data = biodata_all_join_class_filter.groupBy(\"target_chembl_id\").agg(*aggregations)\n",
    "\n",
    "# Save to CSV\n",
    "custom_cutoff_grouped_data.repartition(1).write.mode(\"overwrite\").csv(\"data/biodata_all_join_v3\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split\n",
    "custom_cutoff_grouped_data = custom_cutoff_grouped_data.withColumn(\"concatenated_sources\", split(custom_cutoff_grouped_data[\"concatenated_sources\"], \",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pdf = custom_cutoff_grouped_data.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[\"concatenated_sources_rem\"] = pdf[\"concatenated_sources\"].apply({lambda x: set(x) - set([\"chembl\", \"chemicalProbes\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lambda>    896\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/10 18:10:45 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1097261 ms exceeds timeout 120000 ms\n",
      "23/10/10 18:10:45 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/10/10 18:10:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 18:10:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 18:10:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 18:10:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 18:46:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 18:46:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:00:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:00:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:01:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:01:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:01:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:01:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:02:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:02:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:02:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:03:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:03:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:04:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:04:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:05:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:06:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:06:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:06:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:07:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:07:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:07:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:07:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/10 19:08:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:08:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:09:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:10:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:10:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:10:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:10:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.23.50.45:53753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/10 19:10:18 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "pdf[\"concatenated_sources_rem\"].apply({lambda x: len(x) > 0}).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_chembl_id</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>molregno</th>\n",
       "      <th>assay_chembl_id</th>\n",
       "      <th>src_id</th>\n",
       "      <th>src_short_name</th>\n",
       "      <th>journal</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>tid</th>\n",
       "      <th>...</th>\n",
       "      <th>organism</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>standard_units</th>\n",
       "      <th>standard_relation</th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>isHighQualityProbe</th>\n",
       "      <th>isTherapeuticTarget</th>\n",
       "      <th>proteinClass</th>\n",
       "      <th>concatenated_sources</th>\n",
       "      <th>concatenated_sources_rem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1075094</td>\n",
       "      <td>CHEMBL116438,CHEMBL165,CHEMBL48802,CHEMBL1762621</td>\n",
       "      <td>1139916,75869,103658,190171</td>\n",
       "      <td>CHEMBL3879610,CHEMBL4307109,CHEMBL3295141,CHEM...</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>ACS Med Chem Lett,Bioorg Med Chem,J Med Chem,J...</td>\n",
       "      <td>2.812644E7,2.4920381E7,2.8753294E7,3.1312409E7</td>\n",
       "      <td>10.1016/j.bmc.2017.01.005,10.1021/acs.jnatprod...</td>\n",
       "      <td>103144</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>580.0,9900.0,5400.0,60.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>5.0,5.27,7.22,6.24</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>TF</td>\n",
       "      <td>[impc, intogen, chembl, eva_somatic, cancer_ge...</td>\n",
       "      <td>{cancer_gene_census, intogen, eva_somatic, impc}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL1075167</td>\n",
       "      <td>CHEMBL1336,CHEMBL1230609</td>\n",
       "      <td>692959,276734</td>\n",
       "      <td>CHEMBL1244865,CHEMBL1908417</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Blood,Nat Biotechnol</td>\n",
       "      <td>1.9654408E7,2.2037378E7</td>\n",
       "      <td>10.1038/nbt.1990,10.1182/blood-2009-05-222034</td>\n",
       "      <td>103106</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>0.51,2.7</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>8.57,9.29</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Kinase</td>\n",
       "      <td>[impc]</td>\n",
       "      <td>{impc}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1075319</td>\n",
       "      <td>CHEMBL207433,CHEMBL2443061,CHEMBL3577885,CHEMB...</td>\n",
       "      <td>1817707,349135,1589591,1946198,425650</td>\n",
       "      <td>CHEMBL5161310,CHEMBL3383300,CHEMBL5214521,CHEM...</td>\n",
       "      <td>1,65</td>\n",
       "      <td>LIT_EUBOPEN_CGL,LITERATURE</td>\n",
       "      <td>Bioorg Med Chem,Bioorg Med Chem Lett,Eur J Med...</td>\n",
       "      <td>2.5455182E7,2.408046E7,2.4055075E7,3.5263708E7</td>\n",
       "      <td>10.1016/j.bmc.2013.08.031,10.6019/CHEMBL521274...</td>\n",
       "      <td>103167</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>8.3,13.8,3000.0,8.9,1600.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>5.52,8.08,5.8,7.86,8.05</td>\n",
       "      <td>false,true</td>\n",
       "      <td>false,true</td>\n",
       "      <td>IC</td>\n",
       "      <td>[ot_genetics_portal, ot_genetics_portal, chemb...</td>\n",
       "      <td>{ot_genetics_portal}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL1163106</td>\n",
       "      <td>CHEMBL384304</td>\n",
       "      <td>361203</td>\n",
       "      <td>CHEMBL1908722</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Nat Biotechnol</td>\n",
       "      <td>2.2037378E7</td>\n",
       "      <td>10.1038/nbt.1990</td>\n",
       "      <td>103435</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>11.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>7.96</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Kinase</td>\n",
       "      <td>[ot_genetics_portal]</td>\n",
       "      <td>{ot_genetics_portal}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL1163126</td>\n",
       "      <td>CHEMBL384304,CHEMBL428690,CHEMBL445813</td>\n",
       "      <td>361203,511261,14366</td>\n",
       "      <td>CHEMBL1908787</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Nat Biotechnol</td>\n",
       "      <td>2.2037378E7</td>\n",
       "      <td>10.1038/nbt.1990</td>\n",
       "      <td>103455</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>8.3,0.69,2.2</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>9.16,8.08,8.66</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Kinase</td>\n",
       "      <td>[impc]</td>\n",
       "      <td>{impc}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>CHEMBL6120</td>\n",
       "      <td>CHEMBL3746329,CHEMBL388590,CHEMBL3707347,CHEMB...</td>\n",
       "      <td>2039318,2464877,2056491,374182</td>\n",
       "      <td>CHEMBL4731283,CHEMBL4015171,CHEMBL3853546</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>ACS Med Chem Lett,Bioorg Med Chem Lett,Medchem...</td>\n",
       "      <td>2.8351592E7,3.3062187E7</td>\n",
       "      <td>10.1039/C6MD00190D,10.1021/acsmedchemlett.0c00...</td>\n",
       "      <td>102767</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>23.0,22.0,37.2,33.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>7.48,7.43,7.64,7.66</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>Transporter</td>\n",
       "      <td>[ot_genetics_portal, gene_burden, chembl]</td>\n",
       "      <td>{gene_burden, ot_genetics_portal}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>CHEMBL6149</td>\n",
       "      <td>CHEMBL1421</td>\n",
       "      <td>361469</td>\n",
       "      <td>CHEMBL4807589</td>\n",
       "      <td>38</td>\n",
       "      <td>PATENT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>102770</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>8.3</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Kinase</td>\n",
       "      <td>[impc, ot_genetics_portal]</td>\n",
       "      <td>{ot_genetics_portal, impc}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>CHEMBL6152</td>\n",
       "      <td>CHEMBL531,CHEMBL972,CHEMBL374478,CHEMBL161,CHE...</td>\n",
       "      <td>2208,365189,96021,83724,4584,12494</td>\n",
       "      <td>CHEMBL4700553,CHEMBL4700552,CHEMBL4700572</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Eur J Med Chem</td>\n",
       "      <td>3.0743095E7</td>\n",
       "      <td>10.1016/j.ejmech.2019.01.045</td>\n",
       "      <td>102780</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>7900.0,3000.0,270.0,530.0,7100.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>6.28,5.1,6.57,5.15,5.52</td>\n",
       "      <td>false</td>\n",
       "      <td>false,true</td>\n",
       "      <td>None</td>\n",
       "      <td>[impc, uniprot_literature, impc, eva, orphanet...</td>\n",
       "      <td>{eva, uniprot_variants, ot_genetics_portal, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>CHEMBL6174</td>\n",
       "      <td>CHEMBL6,CHEMBL118</td>\n",
       "      <td>18694,173</td>\n",
       "      <td>CHEMBL4722423</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Eur J Med Chem</td>\n",
       "      <td>3.174005E7</td>\n",
       "      <td>10.1016/j.ejmech.2019.111863</td>\n",
       "      <td>101472</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>70.0,280.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>6.55,7.16</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>[eva, orphanet, eva_somatic, eva, eva_somatic]</td>\n",
       "      <td>{orphanet, eva, eva_somatic}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>CHEMBL6195</td>\n",
       "      <td>CHEMBL372764</td>\n",
       "      <td>328891</td>\n",
       "      <td>CHEMBL5127104</td>\n",
       "      <td>1</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>Eur J Med Chem</td>\n",
       "      <td>3.4752952E7</td>\n",
       "      <td>10.1016/j.ejmech.2021.113970</td>\n",
       "      <td>102793</td>\n",
       "      <td>...</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>50.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>=</td>\n",
       "      <td>7.3</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>[ot_genetics_portal]</td>\n",
       "      <td>{ot_genetics_portal}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_chembl_id                                          chembl_id  \\\n",
       "0       CHEMBL1075094   CHEMBL116438,CHEMBL165,CHEMBL48802,CHEMBL1762621   \n",
       "1       CHEMBL1075167                           CHEMBL1336,CHEMBL1230609   \n",
       "2       CHEMBL1075319  CHEMBL207433,CHEMBL2443061,CHEMBL3577885,CHEMB...   \n",
       "3       CHEMBL1163106                                       CHEMBL384304   \n",
       "4       CHEMBL1163126             CHEMBL384304,CHEMBL428690,CHEMBL445813   \n",
       "...               ...                                                ...   \n",
       "1332       CHEMBL6120  CHEMBL3746329,CHEMBL388590,CHEMBL3707347,CHEMB...   \n",
       "1334       CHEMBL6149                                         CHEMBL1421   \n",
       "1335       CHEMBL6152  CHEMBL531,CHEMBL972,CHEMBL374478,CHEMBL161,CHE...   \n",
       "1337       CHEMBL6174                                  CHEMBL6,CHEMBL118   \n",
       "1338       CHEMBL6195                                       CHEMBL372764   \n",
       "\n",
       "                                   molregno  \\\n",
       "0               1139916,75869,103658,190171   \n",
       "1                             692959,276734   \n",
       "2     1817707,349135,1589591,1946198,425650   \n",
       "3                                    361203   \n",
       "4                       361203,511261,14366   \n",
       "...                                     ...   \n",
       "1332         2039318,2464877,2056491,374182   \n",
       "1334                                 361469   \n",
       "1335     2208,365189,96021,83724,4584,12494   \n",
       "1337                              18694,173   \n",
       "1338                                 328891   \n",
       "\n",
       "                                        assay_chembl_id src_id  \\\n",
       "0     CHEMBL3879610,CHEMBL4307109,CHEMBL3295141,CHEM...      1   \n",
       "1                           CHEMBL1244865,CHEMBL1908417      1   \n",
       "2     CHEMBL5161310,CHEMBL3383300,CHEMBL5214521,CHEM...   1,65   \n",
       "3                                         CHEMBL1908722      1   \n",
       "4                                         CHEMBL1908787      1   \n",
       "...                                                 ...    ...   \n",
       "1332          CHEMBL4731283,CHEMBL4015171,CHEMBL3853546      1   \n",
       "1334                                      CHEMBL4807589     38   \n",
       "1335          CHEMBL4700553,CHEMBL4700552,CHEMBL4700572      1   \n",
       "1337                                      CHEMBL4722423      1   \n",
       "1338                                      CHEMBL5127104      1   \n",
       "\n",
       "                  src_short_name  \\\n",
       "0                     LITERATURE   \n",
       "1                     LITERATURE   \n",
       "2     LIT_EUBOPEN_CGL,LITERATURE   \n",
       "3                     LITERATURE   \n",
       "4                     LITERATURE   \n",
       "...                          ...   \n",
       "1332                  LITERATURE   \n",
       "1334                      PATENT   \n",
       "1335                  LITERATURE   \n",
       "1337                  LITERATURE   \n",
       "1338                  LITERATURE   \n",
       "\n",
       "                                                journal  \\\n",
       "0     ACS Med Chem Lett,Bioorg Med Chem,J Med Chem,J...   \n",
       "1                                  Blood,Nat Biotechnol   \n",
       "2     Bioorg Med Chem,Bioorg Med Chem Lett,Eur J Med...   \n",
       "3                                        Nat Biotechnol   \n",
       "4                                        Nat Biotechnol   \n",
       "...                                                 ...   \n",
       "1332  ACS Med Chem Lett,Bioorg Med Chem Lett,Medchem...   \n",
       "1334                                                      \n",
       "1335                                     Eur J Med Chem   \n",
       "1337                                     Eur J Med Chem   \n",
       "1338                                     Eur J Med Chem   \n",
       "\n",
       "                                           pubmed_id  \\\n",
       "0     2.812644E7,2.4920381E7,2.8753294E7,3.1312409E7   \n",
       "1                            1.9654408E7,2.2037378E7   \n",
       "2     2.5455182E7,2.408046E7,2.4055075E7,3.5263708E7   \n",
       "3                                        2.2037378E7   \n",
       "4                                        2.2037378E7   \n",
       "...                                              ...   \n",
       "1332                         2.8351592E7,3.3062187E7   \n",
       "1334                                                   \n",
       "1335                                     3.0743095E7   \n",
       "1337                                      3.174005E7   \n",
       "1338                                     3.4752952E7   \n",
       "\n",
       "                                                    doi     tid  ...  \\\n",
       "0     10.1016/j.bmc.2017.01.005,10.1021/acs.jnatprod...  103144  ...   \n",
       "1         10.1038/nbt.1990,10.1182/blood-2009-05-222034  103106  ...   \n",
       "2     10.1016/j.bmc.2013.08.031,10.6019/CHEMBL521274...  103167  ...   \n",
       "3                                      10.1038/nbt.1990  103435  ...   \n",
       "4                                      10.1038/nbt.1990  103455  ...   \n",
       "...                                                 ...     ...  ...   \n",
       "1332  10.1039/C6MD00190D,10.1021/acsmedchemlett.0c00...  102767  ...   \n",
       "1334                                                     102770  ...   \n",
       "1335                       10.1016/j.ejmech.2019.01.045  102780  ...   \n",
       "1337                       10.1016/j.ejmech.2019.111863  101472  ...   \n",
       "1338                       10.1016/j.ejmech.2021.113970  102793  ...   \n",
       "\n",
       "          organism                    standard_value standard_units  \\\n",
       "0     Homo sapiens          580.0,9900.0,5400.0,60.0             nM   \n",
       "1     Homo sapiens                          0.51,2.7             nM   \n",
       "2     Homo sapiens        8.3,13.8,3000.0,8.9,1600.0             nM   \n",
       "3     Homo sapiens                              11.0             nM   \n",
       "4     Homo sapiens                      8.3,0.69,2.2             nM   \n",
       "...            ...                               ...            ...   \n",
       "1332  Homo sapiens               23.0,22.0,37.2,33.0             nM   \n",
       "1334  Homo sapiens                               5.0             nM   \n",
       "1335  Homo sapiens  7900.0,3000.0,270.0,530.0,7100.0             nM   \n",
       "1337  Homo sapiens                        70.0,280.0             nM   \n",
       "1338  Homo sapiens                              50.0             nM   \n",
       "\n",
       "     standard_relation            pchembl_value isHighQualityProbe  \\\n",
       "0                    =       5.0,5.27,7.22,6.24              false   \n",
       "1                    =                8.57,9.29              false   \n",
       "2                    =  5.52,8.08,5.8,7.86,8.05         false,true   \n",
       "3                    =                     7.96              false   \n",
       "4                    =           9.16,8.08,8.66              false   \n",
       "...                ...                      ...                ...   \n",
       "1332                 =      7.48,7.43,7.64,7.66              false   \n",
       "1334                 =                      8.3              false   \n",
       "1335                 =  6.28,5.1,6.57,5.15,5.52              false   \n",
       "1337                 =                6.55,7.16              false   \n",
       "1338                 =                      7.3              false   \n",
       "\n",
       "     isTherapeuticTarget proteinClass  \\\n",
       "0                   true           TF   \n",
       "1                  false       Kinase   \n",
       "2             false,true           IC   \n",
       "3                  false       Kinase   \n",
       "4                  false       Kinase   \n",
       "...                  ...          ...   \n",
       "1332                true  Transporter   \n",
       "1334               false       Kinase   \n",
       "1335          false,true         None   \n",
       "1337               false       Enzyme   \n",
       "1338               false       Enzyme   \n",
       "\n",
       "                                   concatenated_sources  \\\n",
       "0     [impc, intogen, chembl, eva_somatic, cancer_ge...   \n",
       "1                                                [impc]   \n",
       "2     [ot_genetics_portal, ot_genetics_portal, chemb...   \n",
       "3                                  [ot_genetics_portal]   \n",
       "4                                                [impc]   \n",
       "...                                                 ...   \n",
       "1332          [ot_genetics_portal, gene_burden, chembl]   \n",
       "1334                         [impc, ot_genetics_portal]   \n",
       "1335  [impc, uniprot_literature, impc, eva, orphanet...   \n",
       "1337     [eva, orphanet, eva_somatic, eva, eva_somatic]   \n",
       "1338                               [ot_genetics_portal]   \n",
       "\n",
       "                               concatenated_sources_rem  \n",
       "0      {cancer_gene_census, intogen, eva_somatic, impc}  \n",
       "1                                                {impc}  \n",
       "2                                  {ot_genetics_portal}  \n",
       "3                                  {ot_genetics_portal}  \n",
       "4                                                {impc}  \n",
       "...                                                 ...  \n",
       "1332                  {gene_burden, ot_genetics_portal}  \n",
       "1334                         {ot_genetics_portal, impc}  \n",
       "1335  {eva, uniprot_variants, ot_genetics_portal, im...  \n",
       "1337                       {orphanet, eva, eva_somatic}  \n",
       "1338                               {ot_genetics_portal}  \n",
       "\n",
       "[896 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[pdf[\"concatenated_sources_rem\"].apply({lambda x: len(x) > 0}).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_chembl_id</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>molregno</th>\n",
       "      <th>assay_chembl_id</th>\n",
       "      <th>src_id</th>\n",
       "      <th>src_short_name</th>\n",
       "      <th>journal</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>tid</th>\n",
       "      <th>...</th>\n",
       "      <th>organism</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>standard_units</th>\n",
       "      <th>standard_relation</th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>isHighQualityProbe</th>\n",
       "      <th>isTherapeuticTarget</th>\n",
       "      <th>proteinClass</th>\n",
       "      <th>concatenated_sources</th>\n",
       "      <th>concatenated_sources_rem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_chembl_id chembl_id molregno assay_chembl_id src_id  \\\n",
       "0                 NaN       NaN      NaN             NaN    NaN   \n",
       "1                 NaN       NaN      NaN             NaN    NaN   \n",
       "2                 NaN       NaN      NaN             NaN    NaN   \n",
       "3                 NaN       NaN      NaN             NaN    NaN   \n",
       "4                 NaN       NaN      NaN             NaN    NaN   \n",
       "...               ...       ...      ...             ...    ...   \n",
       "1334              NaN       NaN      NaN             NaN    NaN   \n",
       "1335              NaN       NaN      NaN             NaN    NaN   \n",
       "1336              NaN       NaN      NaN             NaN    NaN   \n",
       "1337              NaN       NaN      NaN             NaN    NaN   \n",
       "1338              NaN       NaN      NaN             NaN    NaN   \n",
       "\n",
       "     src_short_name journal pubmed_id  doi  tid  ... organism standard_value  \\\n",
       "0               NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "1               NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "2               NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "3               NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "4               NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "...             ...     ...       ...  ...  ...  ...      ...            ...   \n",
       "1334            NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "1335            NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "1336            NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "1337            NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "1338            NaN     NaN       NaN  NaN  NaN  ...      NaN            NaN   \n",
       "\n",
       "     standard_units standard_relation pchembl_value isHighQualityProbe  \\\n",
       "0               NaN               NaN           NaN                NaN   \n",
       "1               NaN               NaN           NaN                NaN   \n",
       "2               NaN               NaN           NaN                NaN   \n",
       "3               NaN               NaN           NaN                NaN   \n",
       "4               NaN               NaN           NaN                NaN   \n",
       "...             ...               ...           ...                ...   \n",
       "1334            NaN               NaN           NaN                NaN   \n",
       "1335            NaN               NaN           NaN                NaN   \n",
       "1336            NaN               NaN           NaN                NaN   \n",
       "1337            NaN               NaN           NaN                NaN   \n",
       "1338            NaN               NaN           NaN                NaN   \n",
       "\n",
       "     isTherapeuticTarget proteinClass concatenated_sources  \\\n",
       "0                    NaN          NaN                  NaN   \n",
       "1                    NaN          NaN                  NaN   \n",
       "2                    NaN          NaN                  NaN   \n",
       "3                    NaN          NaN                  NaN   \n",
       "4                    NaN          NaN                  NaN   \n",
       "...                  ...          ...                  ...   \n",
       "1334                 NaN          NaN                  NaN   \n",
       "1335                 NaN          NaN                  NaN   \n",
       "1336                 NaN          NaN                  NaN   \n",
       "1337                 NaN          NaN                  NaN   \n",
       "1338                 NaN          NaN                  NaN   \n",
       "\n",
       "     concatenated_sources_rem  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "...                       ...  \n",
       "1334                      NaN  \n",
       "1335                      NaN  \n",
       "1336                      NaN  \n",
       "1337                      NaN  \n",
       "1338                      NaN  \n",
       "\n",
       "[1339 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trusted_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
