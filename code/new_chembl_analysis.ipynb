{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, broadcast, when, max, expr, collect_list, concat_ws, array_contains, split\n",
    "from pyspark.sql.types import BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/18 11:31:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_values(df: DataFrame, column_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Count unique values in a specific column of a PySpark DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The PySpark DataFrame.\n",
    "    column_name (str): The name of the column to analyze.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of unique values in the column.\n",
    "    \"\"\"\n",
    "    # Get distinct values in the column and count them\n",
    "    unique_count = df.select(column_name).distinct().count()\n",
    "\n",
    "    return unique_count\n",
    "\n",
    "# Example usage\n",
    "# unique_count = count_unique_values(your_dataframe, 'your_column_name')\n",
    "# print(f\"Number of unique values: {unique_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Bioactivity data from ChEMBL filtered (exact protein/homolog, assay type != P or U, human targets)\n",
    "input_path = \"gs://ot-team/polina/target_evidence_bool\"\n",
    "input = spark.read.parquet(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4656"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 11:34:04 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[target_chembl_id: string, drugId: string, target_chembl_id_moa_aggr: string, pchembl_value_aggr: string, max_pchembl_value: string, median_pchembl_value: double, drugType: string, maximumClinicalTrialPhase: double, isApproved: boolean, linkedTargets: struct<count:bigint,rows:array<string>>, linkedDiseases: struct<count:bigint,rows:array<string>>, assay_chembl_id: string, assay_type: string, action_type: struct<action_type:string,description:string,parent_type:string>, target_organism: string, target_pref_name: string, data_validity_comment: string, data_validity_description: string, confidence_score: bigint, confidence_description: string, assay_category: string, target_components: array<struct<accession:string,component_description:string,component_id:bigint,component_type:string,relationship:string,target_component_synonyms:array<struct<component_synonym:string,syn_type:string>>,target_component_xrefs:array<struct<xref_id:string,xref_name:string,xref_src_db:string,xref_src_url:string,xref_url:string>>>>, target_type: string, accession: string, proteinClass: string, isActive_max: string, isActive_med: string, action_type_moa: string, isInMoA: boolean, targetId: string, sources: array<string>, isHighQualityProbe: boolean, isTherapeuticTarget: boolean, isGE: boolean, isGE_clinical: boolean, isProbe: boolean]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many targets:\n",
    "#   have assays for active drugs (pchembl median)\n",
    "#   not in MoA of these drugs\n",
    "#   supported by GE or clinical evidence\n",
    "\n",
    "med_notmoa_ge_clin = input\\\n",
    "                        .filter(input[\"IsActive_med\"] == True)\\\n",
    "                        .filter(input[\"isInMoA\"].isNull())\\\n",
    "                        .filter(input[\"isGE_clinical\"] == True)\\\n",
    "\n",
    "count_unique_values(med_notmoa_ge_clin.drop_duplicates([\"target_chembl_id\"]), \"target_chembl_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many targets:\n",
    "#   have assays for active drugs (pchembl median)\n",
    "#   not in MoA of these drugs\n",
    "#   supported by GE\n",
    "\n",
    "med_notmoa_ge = input\\\n",
    "                        .filter(input[\"IsActive_med\"] == True)\\\n",
    "                        .filter(input[\"isInMoA\"].isNull())\\\n",
    "                        .filter(input[\"isGE\"] == True)\\\n",
    "\n",
    "count_unique_values(med_notmoa_ge.drop_duplicates([\"target_chembl_id\"]), \"target_chembl_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- target_chembl_id: string (nullable = true)\n",
      " |-- drugId: string (nullable = true)\n",
      " |-- target_chembl_id_moa_aggr: string (nullable = true)\n",
      " |-- pchembl_value_aggr: string (nullable = true)\n",
      " |-- max_pchembl_value: string (nullable = true)\n",
      " |-- median_pchembl_value: double (nullable = true)\n",
      " |-- drugType: string (nullable = true)\n",
      " |-- maximumClinicalTrialPhase: double (nullable = true)\n",
      " |-- isApproved: boolean (nullable = true)\n",
      " |-- linkedTargets: struct (nullable = true)\n",
      " |    |-- count: long (nullable = true)\n",
      " |    |-- rows: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- linkedDiseases: struct (nullable = true)\n",
      " |    |-- count: long (nullable = true)\n",
      " |    |-- rows: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- assay_chembl_id: string (nullable = true)\n",
      " |-- assay_type: string (nullable = true)\n",
      " |-- action_type: struct (nullable = true)\n",
      " |    |-- action_type: string (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- parent_type: string (nullable = true)\n",
      " |-- target_organism: string (nullable = true)\n",
      " |-- target_pref_name: string (nullable = true)\n",
      " |-- data_validity_comment: string (nullable = true)\n",
      " |-- data_validity_description: string (nullable = true)\n",
      " |-- confidence_score: long (nullable = true)\n",
      " |-- confidence_description: string (nullable = true)\n",
      " |-- assay_category: string (nullable = true)\n",
      " |-- target_components: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- accession: string (nullable = true)\n",
      " |    |    |-- component_description: string (nullable = true)\n",
      " |    |    |-- component_id: long (nullable = true)\n",
      " |    |    |-- component_type: string (nullable = true)\n",
      " |    |    |-- relationship: string (nullable = true)\n",
      " |    |    |-- target_component_synonyms: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- component_synonym: string (nullable = true)\n",
      " |    |    |    |    |-- syn_type: string (nullable = true)\n",
      " |    |    |-- target_component_xrefs: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- xref_id: string (nullable = true)\n",
      " |    |    |    |    |-- xref_name: string (nullable = true)\n",
      " |    |    |    |    |-- xref_src_db: string (nullable = true)\n",
      " |    |    |    |    |-- xref_src_url: string (nullable = true)\n",
      " |    |    |    |    |-- xref_url: string (nullable = true)\n",
      " |-- target_type: string (nullable = true)\n",
      " |-- accession: string (nullable = true)\n",
      " |-- proteinClass: string (nullable = true)\n",
      " |-- isActive_max: string (nullable = true)\n",
      " |-- isActive_med: string (nullable = true)\n",
      " |-- action_type_moa: string (nullable = true)\n",
      " |-- isInMoA: boolean (nullable = true)\n",
      " |-- targetId: string (nullable = true)\n",
      " |-- sources: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- isHighQualityProbe: boolean (nullable = true)\n",
      " |-- isTherapeuticTarget: boolean (nullable = true)\n",
      " |-- isGE: boolean (nullable = true)\n",
      " |-- isGE_clinical: boolean (nullable = true)\n",
      " |-- isProbe: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "med_notmoa_ge.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the structure\n",
    "med_notmoa_ge_flattened = med_notmoa_ge.withColumn(\"linkedTargets_count\", col(\"linkedTargets.count\"))\\\n",
    "                .withColumn(\"linkedTargets_rows\", col(\"linkedTargets.rows\"))\\\n",
    "                .withColumn(\"linkedDiseases_count\", col(\"linkedDiseases.count\"))\\\n",
    "                .withColumn(\"linkedDiseases_rows\", col(\"linkedDiseases.rows\"))\\\n",
    "                .withColumn(\"action_type_action_type\", col(\"action_type.action_type\"))\\\n",
    "                .withColumn(\"action_type_description\", col(\"action_type.description\"))\\\n",
    "                .withColumn(\"action_type_parent_type\", col(\"action_type.parent_type\"))\\\n",
    "                .withColumn(\"sources_concated\", concat_ws(\", \", \"sources\"))\\\n",
    "                .drop(\"sources\")\\\n",
    "                .withColumn(\"linkedTargets_rows_concated\", concat_ws(\", \", \"linkedTargets_rows\"))\\\n",
    "                .drop(\"linkedTargets_rows\")\\\n",
    "                .withColumn(\"linkedDiseases_rows_concated\", concat_ws(\", \", \"linkedDiseases_rows\"))\\\n",
    "                .drop(\"linkedDiseases_rows\")\\\n",
    "                .drop(\"linkedTargets\")\\\n",
    "                .drop(\"linkedDiseases\")\\\n",
    "                .drop(\"action_type\")\\\n",
    "                .drop(\"target_components\")\n",
    "\n",
    "# med_notmoa_ge_flattened.printSchema()\n",
    "med_notmoa_ge_flattened.coalesce(1).write.csv(\"files/med_notmoa_ge_v1.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_notmoa_ge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_notmoa_ge_flattened.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dataframes(initial_df: DataFrame, \n",
    "                    second_df: DataFrame, \n",
    "                    initial_key_column: str, \n",
    "                    second_key_column: str,\n",
    "                    columns_to_join: list) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Joins two PySpark DataFrames on specified key columns.\n",
    "\n",
    "    Args:\n",
    "    initial_df (DataFrame): The initial PySpark DataFrame.\n",
    "    second_df (DataFrame): The second PySpark DataFrame to join with.\n",
    "    initial_key_column (str): The key column name in the initial DataFrame.\n",
    "    second_key_column (str): The key column name in the second DataFrame.\n",
    "    columns_to_join (list): List of column names from the second DataFrame to include in the join.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The resulting DataFrame after the join.\n",
    "    \"\"\"\n",
    "\n",
    "    # Selecting specified columns from the second DataFrame, including its key column\n",
    "    second_df_selected = second_df.select([second_key_column] + columns_to_join)\n",
    "\n",
    "    # Performing the left join\n",
    "    joined_df = initial_df.join(second_df_selected, \n",
    "                                initial_df[initial_key_column] == second_df_selected[second_key_column], \n",
    "                                how='left')\n",
    "\n",
    "    # Drop the second key column if not needed\n",
    "    joined_df = joined_df.drop(second_df_selected[second_key_column])\n",
    "\n",
    "    return joined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_values_and_counts(df: DataFrame, column_name: str):\n",
    "    \"\"\"\n",
    "    Shows unique values and their counts for a specified column in a Spark DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The Spark DataFrame to analyze.\n",
    "    column_name (str): The name of the column for which to count unique values.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column {column_name} not found in DataFrame\")\n",
    "\n",
    "    unique_values_counts = df.groupBy(column_name).count()\n",
    "    unique_values_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
