{"cells":[{"cell_type":"code","execution_count":2,"id":"a1d0ec40","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n","  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425348 sha256=d803ebd59e26909b9bf84843d4c640e1e470bb69ab6c98194b46d940d4f3b065\n","  Stored in directory: /Users/polina/Library/Caches/pip/wheels/57/bd/14/ce9e21f2649298678d011fb8f71ed38ee70b42b94fef0be142\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.7 pyspark-3.5.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":1,"id":"3f7cfc5e-0a18-49d3-b5d6-e53401cd8b42","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/09/27 13:03:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.functions as f\n","\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","id":"9d5859a4-87cd-4d94-abc2-31167ff7f628","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# Disease to target relationships based on genetics"]},{"cell_type":"code","execution_count":2,"id":"a5d98661-86f4-4b52-842d-cea9c789f676","metadata":{},"outputs":[],"source":["CLINVAR_VALIDS = [\n","    # ClinVar evidence we are interested\n","    \"affects\",\n","    \"risk factor\",\n","    \"pathogenic\",\n","    \"likely pathogenic\",\n","    \"protective\",\n","    \"drug response\",\n","]\n","\n","SOURCES_OF_INTEREST = [\n","    # Genetic evidence\n","    \"uniprot_variants\",\n","    \"uniprot_literature\",\n","    \"gene_burden\",\n","    \"orphanet\",\n","    \"clingen\",\n","    \"eva\",\n","    \"gene2phenotype\",\n","    \"ot_genetics_portal\",\n","    # somatic\n","    \"cancer_gene_census\",\n","    \"eva_somatic\",\n","    \"intogen\",\n","    # mouse models\n","    \"impc\",\n","    # we include chembl as a benchmark\n","    \"chembl\"\n","]\n","\n","def expand_disease_index(disease):\n","    \"\"\"Expand disease index to include ancestors to account for differences in granularity in the mapping.\"\"\"\n","    return (\n","        disease.select(\n","            f.col(\"id\").alias(\"diseaseId\"),\n","            f.explode(\"ancestors\").alias(\"propagatedDiseaseId\"),\n","        )\n","        .union(\n","            disease.select(\n","                f.col(\"id\").alias(\"diseaseId\"), f.col(\"id\").alias(\"propagatedDiseaseId\")\n","            )\n","        )\n","        .distinct()\n","    )\n","\n","def prepare_genetic_associations(evidence, disease_ancestors):\n","    \"\"\"Prepare a pseudo-associations dataset that consists of propagating the ontology across the evidence dataset and extract the maximum score per data source.\"\"\"\n","    return (\n","        \n","        # Cleaned evidence (exclude \"benign\" clinvar genetic evidence)\n","        evidence.withColumn(\"evaValids\", f.array([f.lit(x) for x in CLINVAR_VALIDS]))\n","        .withColumn(\"evaFilter\", f.arrays_overlap(\"evaValids\", \"clinicalSignificances\"))\n","        .filter((f.col(\"evaFilter\").isNull()) | (f.col(\"evaFilter\")))\n","        \n","        # Restrict the evidence set to those of genetic origin\n","        .filter(f.col(\"datasourceId\").isin(SOURCES_OF_INTEREST))\n","        \n","        # pseudo-associations: ontology propagation + max datasource score\n","        .join(disease_ancestors, on=\"diseaseId\", how=\"left\")\n","        .drop(\"diseaseId\")\n","        .withColumnRenamed(\"propagatedDiseaseId\", \"diseaseId\")\n","        .select(\"targetId\", \"diseaseId\", \"datasourceId\")\n","        .distinct()\n","    )\n","\n","def prepare_probes_data(target):\n","    \"\"\"Prepare a dataset of drug/target relationships established by probes data.\"\"\"\n","    return (\n","        target.filter(f.col(\"chemicalProbes\").isNotNull())\n","        .select(f.col(\"id\").alias(\"targetId\"), f.explode(f.col(\"chemicalProbes.drugId\")).alias(\"drugId\"))\n","    )"]},{"cell_type":"code","execution_count":3,"id":"1ea8f907-fb0a-4f9e-a8ad-4a629a7538c2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/09/27 13:03:57 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: gs://open-targets-pre-data-releases/23.09/output/etl/parquet/evidence/.\n","org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n","\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n","\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n","\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n","\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n","\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n","\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n","\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n","\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:53)\n","\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n","\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n","\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n","\tat scala.Option.getOrElse(Option.scala:189)\n","\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n","\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n","\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n","\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n","\tat py4j.Gateway.invoke(Gateway.java:282)\n","\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n","\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n","\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n","\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n","\tat java.base/java.lang.Thread.run(Thread.java:833)\n"]},{"ename":"Py4JJavaError","evalue":"An error occurred while calling o24.parquet.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32m/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m disease_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgs://open-targets-pre-data-releases/23.09/output/etl/parquet/diseases\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m target_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgs://open-targets-pre-data-releases/23.09/output/etl/parquet/targets\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m evidence \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mparquet(evidence_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m disease \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mparquet(disease_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/polina/Documents/Bioactivity/bioactivity/scr/Drug2Target.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m disease_ancestors \u001b[39m=\u001b[39m expand_disease_index(disease)\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/sql/readwriter.py:544\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    533\u001b[0m int96RebaseMode \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mint96RebaseMode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m    535\u001b[0m     mergeSchema\u001b[39m=\u001b[39mmergeSchema,\n\u001b[1;32m    536\u001b[0m     pathGlobFilter\u001b[39m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     int96RebaseMode\u001b[39m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 544\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mparquet(_to_seq(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc, paths)))\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n","File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o24.parquet.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:563)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"]}],"source":["evidence_path = \"gs://open-targets-pre-data-releases/23.09/output/etl/parquet/evidence/\"\n","disease_path = \"gs://open-targets-pre-data-releases/23.09/output/etl/parquet/diseases\"\n","target_path = \"gs://open-targets-pre-data-releases/23.09/output/etl/parquet/targets\"\n","\n","evidence = spark.read.parquet(evidence_path)\n","disease = spark.read.parquet(disease_path)\n","\n","disease_ancestors = expand_disease_index(disease)\n","associations = prepare_genetic_associations(evidence, disease_ancestors).persist()\n","\n","total_number_assocs = associations.select(\"targetId\", \"diseaseId\").count()\n","\n","assert associations.select(\"datasourceId\").distinct().count() == len(SOURCES_OF_INTEREST), \"Sources are missing from the associations set\"\n","\n","associations.show()\n","\n","print(\"TOTAL NUMBER OF ASSOCIATIONS:\", total_number_assocs)"]},{"cell_type":"markdown","id":"aa4be694-d694-47e6-89fd-6e0c007709a9","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["# Drug to disease relationships based on clinics"]},{"cell_type":"code","execution_count":92,"id":"312002e8-71fb-4c5e-9056-dd7a76ea1b49","metadata":{"tags":[]},"outputs":[],"source":["def prepare_indications(indications):\n","    \"Prepares a dataset of drug to disease relationships\"\n","    return (\n","        indications\n","        .select(f.col(\"id\").alias(\"drugId\"), f.explode(\"indications.disease\").alias(\"diseaseId\"))\n","        .distinct()\n","    )"]},{"cell_type":"code","execution_count":93,"id":"81450e6d-3715-42fb-bade-d669202ade0e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total drug/disease relationships: 55249\n","+------------+-----------+\n","|      drugId|  diseaseId|\n","+------------+-----------+\n","|    CHEMBL88|EFO_0003840|\n","|    CHEMBL88|EFO_0003833|\n","|    CHEMBL88|EFO_0006738|\n","|CHEMBL360328|EFO_0005611|\n","|CHEMBL360328|EFO_0000319|\n","+------------+-----------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["23/09/20 14:00:01 WARN CacheManager: Asked to cache already cached data.\n"]}],"source":["indications_path = \"gs://open-targets-pre-data-releases/23.09/output/etl/parquet/indication\"\n","\n","indications = spark.read.parquet(indications_path)\n","custom_indications = prepare_indications(indications).persist()\n","\n","print(f\"Total drug/disease relationships: {custom_indications.count()}\")\n","\n","custom_indications.show(5)"]},{"cell_type":"markdown","id":"dc118114-b223-4768-a264-fe31bb004cf5","metadata":{},"source":["# Building target to drug relationships to study their activity data\n","\n","2 main sources:\n","- The result of combining the dataset of genetic evidence + clinical data\n","- Using chemical probes relationships"]},{"cell_type":"code","execution_count":94,"id":"2ebd1920-c5f9-4915-80e8-71d396dd5680","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+-------------+------------------+--------------+\n","|       targetId|       drugId|isHighQualityProbe|  datasourceId|\n","+---------------+-------------+------------------+--------------+\n","|ENSG00000130758|CHEMBL2436978|             false|chemicalProbes|\n","|ENSG00000112742|CHEMBL3109933|             false|chemicalProbes|\n","|ENSG00000112742|CHEMBL3422083|             false|chemicalProbes|\n","|ENSG00000178999|CHEMBL4206831|              true|chemicalProbes|\n","|ENSG00000122025|CHEMBL3290626|             false|chemicalProbes|\n","+---------------+-------------+------------------+--------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 436:===>                                                   (1 + 15) / 16]\r"]},{"name":"stdout","output_type":"stream","text":["Number of target/drug relationships from probes: 4714\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["def prepare_probes_data(target):\n","    \"\"\"Prepare a dataset of drug/target relationships established by probes data.\"\"\"\n","    return (\n","        target\n","        .withColumn(\"probe\", f.explode(\"chemicalProbes\"))\n","        .select(\n","            f.col(\"id\").alias(\"targetId\"),\n","            f.col(\"probe.drugId\"),\n","            f.col(\"probe.isHighQuality\").alias(\"isHighQualityProbe\"),\n","            f.lit(\"chemicalProbes\").alias(\"datasourceId\")\n","        )\n","        .filter(f.col(\"drugId\").isNotNull())\n","        .distinct()\n","    )\n","\n","def ens_to_uniprot(target):\n","    return (\n","        target\n","        .withColumn(\"proteinId\", f.explode(\"proteinIds\"))\n","        .filter(f.col(\"proteinId.source\") == \"uniprot_swissprot\") \n","        .select(f.col(\"id\").alias(\"targetId\"), f.col(\"proteinId.id\").alias(\"uniprotId\"))\n","        .distinct()\n","    )\n","\n","target = spark.read.parquet(target_path)\n","\n","probes = prepare_probes_data(target)\n","uniprot_lut = ens_to_uniprot(target)\n","\n","probes.show(5)\n","\n","print(f\"Number of target/drug relationships from probes: {probes.count()}\")\n","\n"]},{"cell_type":"code","execution_count":95,"id":"1134db94-4ca8-4b7b-8f57-9e0c77f355a4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------------+---------+---------------+--------------------+------------------+-------------------+\n","|      drugId|uniprotId|       targetId|             sources|isHighQualityProbe|isTherapeuticTarget|\n","+------------+---------+---------------+--------------------+------------------+-------------------+\n","|  CHEMBL1000|   A6NM76|ENSG00000185821|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   P01225|ENSG00000131808|[impc, ot_genetic...|             false|              false|\n","|  CHEMBL1000|   P05113|ENSG00000113525|[impc, ot_genetic...|             false|               true|\n","|  CHEMBL1000|   P49715|ENSG00000245848|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q02447|ENSG00000172845|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q14164|ENSG00000263528|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q92989|ENSG00000172409|              [impc]|             false|              false|\n","|  CHEMBL1000|   Q9BYE3|ENSG00000163202|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q9BYG4|ENSG00000178184|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q9BZR9|ENSG00000171206|[ot_genetics_portal]|             false|              false|\n","|  CHEMBL1000|   Q9NP56|ENSG00000171408|            [chembl]|             false|               true|\n","|CHEMBL100014|   O60858|ENSG00000204977|[ot_genetics_portal]|             false|              false|\n","|CHEMBL100014|   O95182|ENSG00000267855|            [chembl]|             false|               true|\n","|CHEMBL100014|   O95199|ENSG00000136161|              [impc]|             false|              false|\n","|CHEMBL100014|   P14210|ENSG00000019991|            [chembl]|             false|               true|\n","|CHEMBL100014|   P21912|ENSG00000117118|[cancer_gene_census]|             false|              false|\n","|CHEMBL100014|   Q02543|ENSG00000105640|            [chembl]|             false|               true|\n","|CHEMBL100014|   Q13772|ENSG00000266412|[cancer_gene_census]|             false|              false|\n","|CHEMBL100014|   Q7Z406|ENSG00000105357|              [impc]|             false|              false|\n","|CHEMBL100014|   Q8NFD5|ENSG00000049618|[cancer_gene_census]|             false|              false|\n","+------------+---------+---------------+--------------------+------------------+-------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 453:====================================================>(199 + 1) / 200]\r"]},{"name":"stdout","output_type":"stream","text":["Number of drug/target relationships: 28921105\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Joining everything\n","\n","drug_to_target = (\n","    associations.join(custom_indications, on=\"diseaseId\", how=\"inner\")\n","    .unionByName(probes, allowMissingColumns=True)\n","    # get uniprots\n","    .join(uniprot_lut, on=\"targetId\")\n","    .select(\n","        \"drugId\",\n","        \"uniprotId\",\n","        \"targetId\",\n","        # metadata of the source of the relationship\n","        \"diseaseId\",\n","        \"datasourceId\",\n","        \"isHighQualityProbe\"\n","    )\n","    .groupBy(\n","        \"drugId\",\n","        \"uniprotId\",\n","        \"targetId\"\n","    )\n","    .agg(\n","        f.collect_set(\"datasourceId\").alias(\"sources\"),\n","        f.collect_set(\"isHighQualityProbe\").alias(\"isHighQualityProbe\")\n","    )\n","    .withColumn(\"isTherapeuticTarget\", f.when(f.array_contains(f.col(\"sources\"), \"chembl\"), f.lit(True)).otherwise(f.lit(False)))\n","    .withColumn(\"isHighQualityProbe\", f.when(f.array_contains(f.col(\"isHighQualityProbe\"), True), f.lit(True)).otherwise(f.lit(False)))\n","    .persist()\n",")\n","\n","\n","drug_to_target.show()\n","\n","print(f\"Number of drug/target relationships: {drug_to_target.count()}\")"]},{"cell_type":"code","execution_count":97,"id":"c4ada06b-8756-4a26-abd4-1ffc1845345c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["drug_to_target.write.parquet(\"gs://ot-team/irene/drug_to_target\")"]},{"cell_type":"code","execution_count":null,"id":"b1668af5-8914-463f-818e-26127848d842","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
